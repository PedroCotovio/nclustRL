{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52a1161c",
   "metadata": {},
   "source": [
    "## Test Observation Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "original-contact",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers import TransformObservation\n",
    "from nclustRL.utils.helper import transform_obs\n",
    "import nclustenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "treated-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = nclustenv.make('BiclusterEnv-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "earlier-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "env2 = TransformObservation(env, transform_obs)\n",
    "obs = env.reset()['state']\n",
    "obs_flat = env2.reset()['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31854a39-4b22-438b-ab97-5ac407330352",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.ndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a943ca11-269f-478c-8a67-4ae2d18a791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_flat.ndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "206ec23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "\n",
    "def transform_obs(n, obs):\n",
    "\n",
    "    nclusters = n\n",
    "\n",
    "    state = obs.clone()\n",
    "    ntypes = state.ntypes\n",
    "\n",
    "    for n, axis in enumerate(ntypes):\n",
    "        for i in range(nclusters):\n",
    "            state.nodes[axis].data[i] = torch.randint(0, 2, (len(state.nodes(axis)),), dtype=torch.bool).to('cuda:0')\n",
    "\n",
    "    keys = sorted(list(state.nodes[ntypes[0]].data.keys()))\n",
    "    ndata = {}\n",
    "\n",
    "    for ntype in ntypes:\n",
    "        ndata[ntype] = torch.vstack(\n",
    "            [state.ndata[key][ntype].float() for key in keys]\n",
    "        ).transpose(0, 1).to('cuda:0')\n",
    "\n",
    "        state.nodes[ntype].data.clear()\n",
    "    state.ndata['feat'] = ndata\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63116c0",
   "metadata": {},
   "source": [
    "## Test Embedings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a8f2d2",
   "metadata": {},
   "source": [
    "### Explicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7efd0ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import dgl.nn.pytorch as dglnn\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from nclustRL.utils.helper import pairwise\n",
    "\n",
    "class HeteroRelu(nn.ReLU):\n",
    "\n",
    "    def __init__(self, inplace:bool = False):\n",
    "        super(HeteroRelu, self).__init__(inplace=inplace)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        return {k: super(HeteroRelu, self).forward(v) for k, v in inputs.items()}\n",
    "\n",
    "class GraphSequential(nn.Sequential):\n",
    "\n",
    "    def __init__(self, *args):\n",
    "        super(GraphSequential, self).__init__(*args)\n",
    "\n",
    "    def forward(self, graph, feat, edge_weight=None):\n",
    "        for module in self:\n",
    "\n",
    "            if isinstance(module, dglnn.HeteroGraphConv):\n",
    "\n",
    "                rel_names = zip(module.mods.keys(), graph.canonical_etypes)\n",
    "                feat = module(\n",
    "                    g=graph, \n",
    "                    inputs=feat, \n",
    "                    mod_kwargs={\n",
    "                        rel: dict(edge_weight=graph.edges[canonical].data[edge_weight]) \n",
    "                        for rel, canonical in rel_names})\n",
    "\n",
    "            else:\n",
    "                feat = module(inputs=feat)\n",
    "\n",
    "        return feat\n",
    "\n",
    "\n",
    "class RGCN(nn.Module):\n",
    "    def __init__(self, layers, rel_names):\n",
    "        super().__init__()\n",
    "\n",
    "        _layers = []\n",
    "\n",
    "        for in_feats, out_feats in pairwise(layers): \n",
    "\n",
    "            _layers.append(dglnn.HeteroGraphConv({\n",
    "                rel: dglnn.GraphConv(in_feats, out_feats)\n",
    "                for rel in rel_names}, aggregate='sum'))\n",
    "\n",
    "            _layers.append(HeteroRelu())\n",
    "\n",
    "        self._hidden_layers = GraphSequential(*_layers)\n",
    "\n",
    "            \n",
    "\n",
    "    def forward(self, graph, feat, edge_weight=None):\n",
    "\n",
    "        return self._hidden_layers(graph, feat, edge_weight)\n",
    "\n",
    "\n",
    "class GraphEncoder(nn.Module):\n",
    "    def __init__(self, n, conv_feats, n_classes, rel_names):\n",
    "        super().__init__()\n",
    "\n",
    "        conv_feats.insert(0, n)\n",
    "        self.rgcn = RGCN(conv_feats, rel_names)\n",
    "\n",
    "    def forward(self, g):\n",
    "        h = g.ndata['feat']\n",
    "        h = self.rgcn(g, h, 'w')\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            hg = 0\n",
    "            for ntype in h.keys():\n",
    "                hg = hg + dgl.mean_nodes(g, 'h', ntype=ntype)\n",
    "            \n",
    "            return hg\n",
    "\n",
    "\n",
    "class HeteroClassifier(nn.Module):\n",
    "    def __init__(self, n, conv_feats, n_classes, rel_names):\n",
    "        super().__init__()\n",
    "\n",
    "        conv_feats.insert(0, n)\n",
    "\n",
    "        self.rgcn = RGCN(conv_feats, rel_names)\n",
    "        self.classify = nn.Linear(conv_feats[-1], n_classes)\n",
    "\n",
    "    def forward(self, g):\n",
    "        h = g.ndata['feat']\n",
    "        h = self.rgcn(g, h, 'w')\n",
    "        print(h['col'])\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            hg = 0\n",
    "            for ntype in h.keys():\n",
    "                hg = hg + dgl.mean_nodes(g, 'h', ntype=ntype)\n",
    "\n",
    "            return self.classify(hg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f557fb1-c31e-4a7f-b621-900f3638899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "\n",
    "dgl.seed(5)\n",
    "\n",
    "def test_embedings(graphs):\n",
    "\n",
    "    batch_size=1\n",
    "    shuffle=True\n",
    "    nclasses = 5\n",
    "    n = 5\n",
    "\n",
    "    # dataloader = GraphDataLoader(\n",
    "    #     base,\n",
    "    #     batch_size=batch_size,\n",
    "    #     drop_last=False,\n",
    "    #     shuffle=shuffle)\n",
    "\n",
    "    etypes = graphs[0].etypes\n",
    "\n",
    "    model = HeteroClassifier(n, [n*2], nclasses, etypes)\n",
    "    model = model.cuda()\n",
    "    opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "    for epoch in range(20):\n",
    "        with tqdm(graphs, unit=\"batch\") as tepoch:\n",
    "            for batched_graph in tepoch:\n",
    "\n",
    "                tepoch.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "                # batched_graph = transform_obs(n, batched_graph)\n",
    "                labels = torch.randint(0, 4, (batch_size,)).to('cuda:0')\n",
    "\n",
    "                logits = model(batched_graph)\n",
    "                loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "                predictions = logits.argmax(dim=1, keepdim=True).squeeze()\n",
    "                correct = (logits == labels).sum().item()\n",
    "\n",
    "                opt.zero_grad()\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "\n",
    "                accuracy = correct / batch_size\n",
    "                tepoch.set_postfix(loss=loss.item(), accuracy=100. * accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bca980",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embedings(graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecab64c",
   "metadata": {},
   "source": [
    "### Built-In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f557fb1-c31e-4a7f-b621-900f3638899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from nclustRL.models import HeteroClassifier\n",
    "\n",
    "dgl.seed(5)\n",
    "\n",
    "def test_embedings(graphs):\n",
    "\n",
    "    batch_size=1\n",
    "    shuffle=True\n",
    "    nclasses = 5\n",
    "    n = 5\n",
    "\n",
    "    # dataloader = GraphDataLoader(\n",
    "    #     base,\n",
    "    #     batch_size=batch_size,\n",
    "    #     drop_last=False,\n",
    "    #     shuffle=shuffle)\n",
    "\n",
    "    etypes = graphs[0].etypes\n",
    "\n",
    "    model = HeteroClassifier(n, [n*2], nclasses, etypes)\n",
    "    model = model.cuda()\n",
    "    opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "    for epoch in range(20):\n",
    "        with tqdm(graphs, unit=\"batch\") as tepoch:\n",
    "            for batched_graph in tepoch:\n",
    "\n",
    "                tepoch.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "                # batched_graph = transform_obs(n, batched_graph)\n",
    "                labels = torch.randint(0, 4, (batch_size,)).to('cuda:0')\n",
    "\n",
    "                logits = model(batched_graph)\n",
    "                loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "                predictions = logits.argmax(dim=1, keepdim=True).squeeze()\n",
    "                correct = (logits == labels).sum().item()\n",
    "\n",
    "                opt.zero_grad()\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "\n",
    "                accuracy = correct / batch_size\n",
    "                tepoch.set_postfix(loss=loss.item(), accuracy=100. * accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb78483c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|███████| 10/10 [00:00<00:00, 155.50batch/s, accuracy=0, loss=1.48]\n",
      "Epoch 1: 100%|███████| 10/10 [00:00<00:00, 192.21batch/s, accuracy=0, loss=1.48]\n",
      "Epoch 2: 100%|███████| 10/10 [00:00<00:00, 203.02batch/s, accuracy=0, loss=1.47]\n",
      "Epoch 3: 100%|███████| 10/10 [00:00<00:00, 160.07batch/s, accuracy=0, loss=1.47]\n",
      "Epoch 4: 100%|███████| 10/10 [00:00<00:00, 169.52batch/s, accuracy=0, loss=1.97]\n",
      "Epoch 5: 100%|███████| 10/10 [00:00<00:00, 195.97batch/s, accuracy=0, loss=1.96]\n",
      "Epoch 6: 100%|███████| 10/10 [00:00<00:00, 227.20batch/s, accuracy=0, loss=1.85]\n",
      "Epoch 7: 100%|███████| 10/10 [00:00<00:00, 229.85batch/s, accuracy=0, loss=1.95]\n",
      "Epoch 8: 100%|███████| 10/10 [00:00<00:00, 233.45batch/s, accuracy=0, loss=1.94]\n",
      "Epoch 9: 100%|███████| 10/10 [00:00<00:00, 202.54batch/s, accuracy=0, loss=1.46]\n",
      "Epoch 10: 100%|██████| 10/10 [00:00<00:00, 208.05batch/s, accuracy=0, loss=1.84]\n",
      "Epoch 11: 100%|██████| 10/10 [00:00<00:00, 183.09batch/s, accuracy=0, loss=1.46]\n",
      "Epoch 12: 100%|██████| 10/10 [00:00<00:00, 181.49batch/s, accuracy=0, loss=1.46]\n",
      "Epoch 13: 100%|██████| 10/10 [00:00<00:00, 183.71batch/s, accuracy=0, loss=1.93]\n",
      "Epoch 14: 100%|██████| 10/10 [00:00<00:00, 205.83batch/s, accuracy=0, loss=1.46]\n",
      "Epoch 15: 100%|██████| 10/10 [00:00<00:00, 167.86batch/s, accuracy=0, loss=1.92]\n",
      "Epoch 16: 100%|██████| 10/10 [00:00<00:00, 159.14batch/s, accuracy=0, loss=1.81]\n",
      "Epoch 17: 100%|██████| 10/10 [00:00<00:00, 152.74batch/s, accuracy=0, loss=1.91]\n",
      "Epoch 18: 100%|██████| 10/10 [00:00<00:00, 157.59batch/s, accuracy=0, loss=1.81]\n",
      "Epoch 19: 100%|██████| 10/10 [00:00<00:00, 172.55batch/s, accuracy=0, loss=1.44]\n"
     ]
    }
   ],
   "source": [
    "test_embedings(graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c204db",
   "metadata": {},
   "source": [
    "## Generate Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97af2ac0",
   "metadata": {},
   "source": [
    "### Explicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7223bf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    import torch as th\n",
    "    import dgl\n",
    "    def loader(cls, module=None):\n",
    "\n",
    "        return getattr(module, cls) if isinstance(cls, str) else cls\n",
    "    \n",
    "    def dense_to_dgl(x, device, cuda=0, nclusters=1, clust_init='zeros', duplicate=True):\n",
    "\n",
    "        # set (u,v)\n",
    "        clust_init = loader(th, clust_init)\n",
    "\n",
    "        tensor = th.tensor([[i, j, elem] for i, row in enumerate(x) for j, elem in enumerate(row)]).T\n",
    "\n",
    "        if duplicate:\n",
    "\n",
    "            graph_data = {\n",
    "                ('row', 'elem', 'col'): (tensor[0].int(), tensor[1].int()),\n",
    "                ('col', 'elem', 'row'): (tensor[1].int().detach().clone(), tensor[2].int().detach().clone()),\n",
    "                }\n",
    "\n",
    "            # create graph\n",
    "            G = dgl.heterograph(graph_data)\n",
    "\n",
    "            # set weights\n",
    "            G.edges[('row', 'elem', 'col')].data['w'] = tensor[2].to(th.float64)\n",
    "            G.edges[('col', 'elem', 'row')].data['w'] = tensor[2].to(th.float64)\n",
    "\n",
    "        else:\n",
    "\n",
    "            graph_data = {\n",
    "                ('row', 'elem', 'col'): (tensor[0].int(), tensor[1].int()),\n",
    "                }\n",
    "\n",
    "            # create graph\n",
    "            G = dgl.heterograph(graph_data)\n",
    "\n",
    "            # set weights\n",
    "            # G.edges[('row', 'elem', 'col')].data['w'] = tensor[2].float()\n",
    "\n",
    "            G.edata['w'] = tensor[2].to(th.float64)\n",
    "\n",
    "        # set cluster members\n",
    "\n",
    "        for n, axis in enumerate(['row', 'col']):\n",
    "            for i in range(nclusters):\n",
    "                G.nodes[axis].data[i] = th.randint(0, 2, (x.shape[n],), dtype=torch.bool)\n",
    "\n",
    "        ndata = {}\n",
    "        ntypes = G.ntypes\n",
    "        keys = sorted(list(G.nodes[ntypes[0]].data.keys()))\n",
    "\n",
    "        for ntype in ntypes:\n",
    "            ndata[ntype] = torch.vstack(\n",
    "                [G.ndata[key][ntype].to(th.float64) for key in keys]\n",
    "            ).transpose(0, 1)\n",
    "\n",
    "            G.nodes[ntype].data.clear()\n",
    "\n",
    "        G.ndata['feat'] = ndata\n",
    "\n",
    "        if device == 'gpu':\n",
    "            G = G.to('cuda:{}'.format(cuda))\n",
    "\n",
    "        return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5db59c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nclustenv\n",
    "import torch\n",
    "env = nclustenv.make('BiclusterEnv-v0', **dict(shape=[[100, 10], [110, 15]], clusters=[5,5]))\n",
    "\n",
    "graphs_dup = []\n",
    "graphs2 = []\n",
    "for i in range(10):\n",
    "    env.reset()\n",
    "    X = env.state._generator.X\n",
    "    graphs_dup.append(dense_to_dgl(X, device='gpu', nclusters=5))\n",
    "    graphs2.append(dense_to_dgl(X, device='gpu', nclusters=5, duplicate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51139c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes={'col': 13, 'row': 102},\n",
       "      num_edges={('col', 'elem', 'row'): 1326, ('row', 'elem', 'col'): 1326},\n",
       "      metagraph=[('col', 'row', 'elem'), ('row', 'col', 'elem')])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs_dup[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "418c0273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes={'col': 13, 'row': 102},\n",
       "      num_edges={('row', 'elem', 'col'): 1326},\n",
       "      metagraph=[('row', 'col', 'elem')])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "885297ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.1700,  4.7800,  2.2900,  ...,  4.4100,  8.2300, -9.9300],\n",
       "       device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs2[0].edges[('row', 'elem', 'col')].data['w']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5724bf0a",
   "metadata": {},
   "source": [
    "### Bult-In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "393119ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import nclustenv\n",
    "import torch\n",
    "from gym.wrappers import TransformObservation\n",
    "from nclustRL.utils.helper import transform_obs\n",
    "\n",
    "env = nclustenv.make('BiclusterEnv-v0', **dict(n=5, shape=[[100, 10], [110, 15]], clusters=[5,5]))\n",
    "env = TransformObservation(env, transform_obs)\n",
    "\n",
    "graphs = [env.reset()['state'] for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e9ec6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8.5300,  1.7900,  8.2200,  ..., -5.5000, -6.5000, -1.4100],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs[0].edges[('row', 'elem', 'col')].data['w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0120abbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'col': tensor([[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]], device='cuda:0'),\n",
       " 'row': tensor([[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]], device='cuda:0')}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs[0].ndata['feat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a03605",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f057d67ad8388b0f5d50624cd1d42e8685c722b60a2c37b21ef81e4231f602cb"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
