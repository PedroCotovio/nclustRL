{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nclustRL.trainer import Trainer\n",
    "from nclustRL.configs.default_configs import PPO_PBT, DEFAULT_CONFIG\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from nclustenv.configs import biclustering, triclustering\n",
    "from nclustRL.configs.save import TrainerConfig\n",
    "from ray.tune import ExperimentAnalysis, uniform\n",
    "from ray.tune.suggest.bayesopt import BayesOptSearch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train\n",
    "    - Train basic v2 (done)\n",
    "    - Hyperparam tune basic_v2 (500 it) (done)\n",
    "    - train again with new params (done)\n",
    "        - test trained (done)\n",
    "    - Hyperparam tune basic_v2 without reward shaping (500 it) (done)\n",
    "    - train again with new params (running)\n",
    "        - test trained (running)\n",
    "    \n",
    "\n",
    "\n",
    "- Plot\n",
    "    - basic v2 vs tunned v2 with baseline\n",
    "    - basic v3 with baseline\n",
    "    - hyperparam tunes\n",
    "\n",
    "Compare all pre and pos training test scores "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v2 Shaped Reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparam tune basic_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inicialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 19:12:57,483\tINFO ppo.py:166 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676818)\u001b[0m 2022-03-08 19:13:01,503\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676819)\u001b[0m 2022-03-08 19:13:01,568\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676826)\u001b[0m 2022-03-08 19:13:01,631\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676815)\u001b[0m 2022-03-08 19:13:01,769\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676819)\u001b[0m 2022-03-08 19:13:06,007\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676819)\u001b[0m 2022-03-08 19:13:06,007\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676818)\u001b[0m 2022-03-08 19:13:06,054\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676818)\u001b[0m 2022-03-08 19:13:06,054\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676818)\u001b[0m 2022-03-08 19:13:06,056\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676818)\u001b[0m 2022-03-08 19:13:06,058\tINFO torch_policy.py:186 -- TorchPolicy (worker=3) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676818)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676818)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676826)\u001b[0m 2022-03-08 19:13:05,989\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676826)\u001b[0m 2022-03-08 19:13:05,989\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676815)\u001b[0m 2022-03-08 19:13:06,125\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676815)\u001b[0m 2022-03-08 19:13:06,125\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676826)\u001b[0m 2022-03-08 19:13:06,140\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676826)\u001b[0m 2022-03-08 19:13:06,143\tINFO torch_policy.py:186 -- TorchPolicy (worker=1) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676826)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676826)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676819)\u001b[0m 2022-03-08 19:13:06,175\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676819)\u001b[0m 2022-03-08 19:13:06,178\tINFO torch_policy.py:186 -- TorchPolicy (worker=2) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676819)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676819)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676815)\u001b[0m 2022-03-08 19:13:06,265\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676815)\u001b[0m 2022-03-08 19:13:06,268\tINFO torch_policy.py:186 -- TorchPolicy (worker=4) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676815)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676815)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676818)\u001b[0m 2022-03-08 19:13:06,972\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f539a8eee80> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "2022-03-08 19:13:07,091\tINFO worker_set.py:104 -- Inferred observation/action spaces from remote worker (local worker has no env): {'default_policy': (Dict(action_mask:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), avail_actions:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), state:Box([6 6], [6 6], (2,), int32)), Tuple(Discrete(4), Tuple(Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32)))), '__env__': (Dict(action_mask:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), avail_actions:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), state:Box([6 6], [6 6], (2,), int32)), Tuple(Discrete(4), Tuple(Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32))))}\n",
      "2022-03-08 19:13:07,093\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "2022-03-08 19:13:07,096\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "2022-03-08 19:13:07,118\tINFO torch_policy.py:186 -- TorchPolicy (worker=local) running on 0.0001 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676819)\u001b[0m 2022-03-08 19:13:07,092\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f2dc3984d90> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676826)\u001b[0m 2022-03-08 19:13:07,081\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f4548b08730> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676815)\u001b[0m 2022-03-08 19:13:07,421\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f7649840640> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "/home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "  warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "2022-03-08 19:13:10,993\tINFO rollout_worker.py:1555 -- Built policy map: {}\n",
      "2022-03-08 19:13:10,994\tINFO rollout_worker.py:1556 -- Built preprocessor map: {'default_policy': None}\n",
      "2022-03-08 19:13:10,994\tINFO rollout_worker.py:618 -- Built filter map: {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x7fc5e850cd60>}\n",
      "2022-03-08 19:13:10,994\tDEBUG rollout_worker.py:728 -- Created rollout worker with env None (None), policies {}\n",
      "2022-03-08 19:13:10,997\tINFO trainable.py:124 -- Trainable.setup took 13.515 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    }
   ],
   "source": [
    "config = DEFAULT_CONFIG.copy()\n",
    "config['env_config'] = biclustering.binary.basic_v2\n",
    "\n",
    "trainer = Trainer(\n",
    "    trainer=PPOTrainer,\n",
    "    env='BiclusterEnv-v0',\n",
    "    save_dir='/home/pgcotovio/repos/nclustRL/Exp/test_framework2',\n",
    "    name='basic_config_v2_hypertune',\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-08 23:33:34 (running for 04:20:20.79)<br>Memory usage on this node: 12.3/62.7 GiB<br>PopulationBasedTraining: 22 checkpoints, 20 perturbs<br>Resources requested: 5.0/12 CPUs, 0.9991/2 GPUs, 0.0/33.29 GiB heap, 0.0/16.65 GiB objects<br>Current best trial: cd6a3_00001 with episode_reward_mean=-0.8183759820426495 and parameters={'num_workers': 4, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 163, 'batch_mode': 'truncate_episodes', 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 655, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': True, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'general_model_torch', 'custom_model_config': {'fcnet_feats': [256, 256]}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'BiclusterEnv-v0', 'observation_space': None, 'action_space': None, 'env_config': {'shape': [[6, 6], [6, 6]], 'n': 1, 'clusters': [1, 1], 'dataset_settings': {'dstype': {'value': 'Symbolic'}, 'patterns': {'value': [['CONSTANT', 'CONSTANT']]}, 'symbols': {'value': [-1, 1]}, 'bktype': {'value': 'UNIFORM'}, 'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]}, 'contiguity': {'value': None}, 'plaidcoherency': {'value': 'NO_OVERLAPPING'}}, 'max_steps': 1000, 'seed': 175}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': False, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': None, 'log_level': 'DEBUG', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': 175, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0.0001, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.24975, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'default_policy': PolicySpec(policy_class=<class 'ray.rllib.agents.ppo.ppo_torch_policy.PPOTorchPolicy'>, observation_space=None, action_space=None, config={})}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': True, 'simple_optimizer': False, 'monitor': -1, 'use_critic': True, 'use_gae': True, 'lambda': 0.96, 'kl_coeff': 0.288, 'sgd_minibatch_size': 122, 'shuffle_sequences': True, 'num_sgd_iter': 19, 'lr_schedule': None, 'vf_loss_coeff': 1.44, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.432, 'vf_clip_param': 14.399999999999999, 'grad_clip': None, 'kl_target': 0.0064, 'vf_share_layers': -1}<br>Result logdir: /home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_config_v2_hypertune/sample_0/PPO_2022-03-08_19-13-14<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 23:33:34,988\tWARNING worker.py:1245 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffd715c3caf9e9bff10812760d01000000 Worker ID: 95fcb97face687f350c5df206bd4b9796ee54fdea0296ee42ffbea7f Node ID: 55996604780d5c204f46219fe26df8f24e4bbe77cb9e563fa2724bba Worker IP address: 10.20.0.204 Worker port: 46729 Worker PID: 1676819\n",
      "2022-03-08 23:33:35,060\tWARNING worker.py:1245 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff1a442c5a7a9513a11e685e2f01000000 Worker ID: 6c0b11e358c19518e92161a0f04b2fb6d9b13293bee5de163a79894f Node ID: 55996604780d5c204f46219fe26df8f24e4bbe77cb9e563fa2724bba Worker IP address: 10.20.0.204 Worker port: 41927 Worker PID: 1676818\n",
      "2022-03-08 23:33:35,144\tERROR tune.py:622 -- Trials did not complete: [PPO_BiclusterEnv-v0_cd6a3_00000, PPO_BiclusterEnv-v0_cd6a3_00001, PPO_BiclusterEnv-v0_cd6a3_00002, PPO_BiclusterEnv-v0_cd6a3_00003, PPO_BiclusterEnv-v0_cd6a3_00004, PPO_BiclusterEnv-v0_cd6a3_00005, PPO_BiclusterEnv-v0_cd6a3_00006, PPO_BiclusterEnv-v0_cd6a3_00007]\n",
      "2022-03-08 23:33:35,144\tINFO tune.py:626 -- Total run time: 15621.04 seconds (15620.78 seconds for the tuning loop).\n",
      "2022-03-08 23:33:35,145\tWARNING tune.py:630 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n",
      "Sample 1: : 1sample [4:20:21, 15621.07s/sample, metric={'episode_reward_max': 2.984, 'episode_reward_min': -1.6666666666666676, 'episode_reward_mean': -0.8183759820426495, 'episode_len_mean': 895.5, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.035999999999999, -1.600000000000001, -1.600000000000001, -1.6363636363636371, 2.984, -1.600000000000001, -1.5454545454545463, -1.4444444444444453, -1.3333333333333344, -1.6363636363636371, 2.876, -1.4444444444444453, -1.2500000000000009, -1.6666666666666676, -1.5000000000000009, -1.6363636363636371, -1.4000000000000008, -1.3333333333333344], 'episode_lengths': [964, 1001, 1001, 1001, 16, 1001, 1001, 1001, 1001, 1001, 124, 1001, 1001, 1001, 1001, 1001, 1001, 1001]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15396040772497432, 'mean_inference_ms': 15.886685111726731, 'mean_action_processing_ms': 0.1739471256799097, 'mean_env_wait_ms': 2.9833305957190106, 'mean_env_render_ms': 0.0}, 'off_policy_estimator': {}, 'num_healthy_workers': 4, 'timesteps_total': 140296, 'timesteps_this_iter': 0, 'agent_timesteps_total': 140296, 'timers': {'sample_time_ms': 11420.364, 'sample_throughput': 114.182, 'load_time_ms': 0.895, 'load_throughput': 1456285.757, 'learn_time_ms': 3900.089, 'learn_throughput': 334.351, 'update_time_ms': 1.901}, 'info': {'learner': {'default_policy': {'learner_stats': {'cur_kl_coeff': 2.1869999999999994, 'cur_lr': 5.000000000000001e-05, 'total_loss': 0.023040482373969433, 'policy_loss': 0.0063706706866229834, 'vf_loss': 0.006575056636019757, 'vf_explained_var': 0.2176180949336604, 'kl': 0.0032929715663684825, 'entropy': 13.179562719244705, 'entropy_coeff': 0.0}}}, 'num_steps_sampled': 140296, 'num_agent_steps_sampled': 140296, 'num_steps_trained': 140296, 'num_agent_steps_trained': 140296, 'num_steps_trained_this_iter': 0}, 'done': False, 'episodes_total': 128, 'training_iteration': 115, 'trial_id': 'cd6a3_00001', 'experiment_id': '0cf8cf54edd34419bfa82bcca2d54520', 'date': '2022-03-08_23-07-08', 'timestamp': 1646780828, 'time_this_iter_s': 11.373039722442627, 'time_total_s': 1439.9905858039856, 'pid': 1949329, 'hostname': 'pgcotovio-B450-AORUS-ELITE', 'node_ip': '10.20.0.204', 'config': {'num_workers': 4, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 163, 'batch_mode': 'truncate_episodes', 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 655, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': True, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'general_model_torch', 'custom_model_config': {'fcnet_feats': [256, 256]}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'BiclusterEnv-v0', 'observation_space': None, 'action_space': None, 'env_config': {'shape': [[6, 6], [6, 6]], 'n': 1, 'clusters': [1, 1], 'dataset_settings': {'dstype': {'value': 'Symbolic'}, 'patterns': {'value': [['CONSTANT', 'CONSTANT']]}, 'symbols': {'value': [-1, 1]}, 'bktype': {'value': 'UNIFORM'}, 'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]}, 'contiguity': {'value': None}, 'plaidcoherency': {'value': 'NO_OVERLAPPING'}}, 'max_steps': 1000, 'seed': 175}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': False, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': None, 'log_level': 'DEBUG', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': 175, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0.0001, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.24975, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'default_policy': PolicySpec(policy_class=<class 'ray.rllib.agents.ppo.ppo_torch_policy.PPOTorchPolicy'>, observation_space=None, action_space=None, config={})}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': True, 'simple_optimizer': False, 'monitor': -1, 'use_critic': True, 'use_gae': True, 'lambda': 0.96, 'kl_coeff': 0.288, 'sgd_minibatch_size': 122, 'shuffle_sequences': True, 'num_sgd_iter': 19, 'lr_schedule': None, 'vf_loss_coeff': 1.44, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.432, 'vf_clip_param': 14.399999999999999, 'grad_clip': None, 'kl_target': 0.0064, 'vf_share_layers': -1}, 'time_since_restore': 171.02070879936218, 'timesteps_since_restore': 0, 'iterations_since_restore': 15, 'perf': {'cpu_util_percent': 29.949999999999996, 'ram_util_percent': 64.10000000000001, 'gpu_util_percent0': 0.06642857142857142, 'vram_util_percent0': 0.9249267578125, 'gpu_util_percent1': 0.5614285714285714, 'vram_util_percent1': 0.6594325474330357}, 'experiment_tag': '1@perturbed[clip_param=0.432,entropy_coeff=0.0,kl_coeff=0.288,kl_target=0.0064,lambda=0.96,lr=5e-05,num_sgd_iter=19,sgd_minibatch_size=122,train_batch_size=655,vf_clip_param=14.4,vf_loss_coeff=1.44]'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'config': {'num_workers': 4,\n",
       "  'create_env_on_driver': False,\n",
       "  'num_envs_per_worker': 1,\n",
       "  'batch_mode': 'truncate_episodes',\n",
       "  'gamma': 0.99,\n",
       "  'use_critic': True,\n",
       "  'use_gae': True,\n",
       "  'lambda': 0.96,\n",
       "  'kl_coeff': 0.288,\n",
       "  'rollout_fragment_length': 256,\n",
       "  'train_batch_size': 655,\n",
       "  'sgd_minibatch_size': 122,\n",
       "  'shuffle_sequences': True,\n",
       "  'num_sgd_iter': 19,\n",
       "  'lr': 5e-05,\n",
       "  'lr_schedule': None,\n",
       "  'vf_loss_coeff': 1.44,\n",
       "  'entropy_coeff': 0.0,\n",
       "  'entropy_coeff_schedule': None,\n",
       "  'clip_param': 0.432,\n",
       "  'vf_clip_param': 14.399999999999999,\n",
       "  'grad_clip': None,\n",
       "  'kl_target': 0.0064,\n",
       "  'optimizer': {},\n",
       "  'horizon': None,\n",
       "  'soft_horizon': False,\n",
       "  'no_done_at_end': False,\n",
       "  'env': 'BiclusterEnv-v0',\n",
       "  'observation_space': None,\n",
       "  'action_space': None,\n",
       "  'env_config': {'shape': [[6, 6], [6, 6]],\n",
       "   'n': 1,\n",
       "   'clusters': [1, 1],\n",
       "   'dataset_settings': {'dstype': {'value': 'Symbolic'},\n",
       "    'patterns': {'value': [['CONSTANT', 'CONSTANT']]},\n",
       "    'symbols': {'value': [-1, 1]},\n",
       "    'bktype': {'value': 'UNIFORM'},\n",
       "    'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]},\n",
       "    'contiguity': {'value': None},\n",
       "    'plaidcoherency': {'value': 'NO_OVERLAPPING'}},\n",
       "   'max_steps': 1000,\n",
       "   'seed': 175},\n",
       "  'env_task_fn': None,\n",
       "  'render_env': False,\n",
       "  'record_env': False,\n",
       "  'clip_rewards': False,\n",
       "  'normalize_actions': True,\n",
       "  'preprocessor_pref': None,\n",
       "  'log_level': 'DEBUG',\n",
       "  'ignore_worker_failures': False,\n",
       "  'log_sys_usage': True,\n",
       "  'framework': 'torch',\n",
       "  'eager_tracing': False,\n",
       "  'explore': True,\n",
       "  'exploration_config': {'type': 'StochasticSampling'},\n",
       "  'evaluation_interval': None,\n",
       "  'evaluation_num_episodes': 10,\n",
       "  'evaluation_parallel_to_training': False,\n",
       "  'in_evaluation': False,\n",
       "  'evaluation_config': {'explore': False},\n",
       "  'evaluation_num_workers': 0,\n",
       "  'custom_eval_function': None,\n",
       "  'sample_async': False,\n",
       "  'observation_filter': 'NoFilter',\n",
       "  'synchronize_filters': True,\n",
       "  'compress_observations': False,\n",
       "  'collect_metrics_timeout': 180,\n",
       "  'metrics_smoothing_episodes': 100,\n",
       "  'min_iter_time_s': 0,\n",
       "  'timesteps_per_iteration': 0,\n",
       "  'seed': 175,\n",
       "  'extra_python_environs_for_driver': {},\n",
       "  'extra_python_environs_for_worker': {},\n",
       "  'num_gpus': 0.0001,\n",
       "  '_fake_gpus': False,\n",
       "  'num_cpus_per_worker': 1,\n",
       "  'num_gpus_per_worker': 0.24975,\n",
       "  'custom_resources_per_worker': {},\n",
       "  'num_cpus_for_driver': 1,\n",
       "  'placement_strategy': 'PACK',\n",
       "  'logger_config': None,\n",
       "  '_disable_preprocessor_api': True,\n",
       "  'model': {'custom_model': 'general_model_torch',\n",
       "   'custom_model_config': {'fcnet_feats': [256, 256]},\n",
       "   'custom_action_dist': None}},\n",
       " 'path': '/home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_config_v2_hypertune/sample_0/PPO_2022-03-08_19-13-14/PPO_BiclusterEnv-v0_cd6a3_00001_1_2022-03-08_19-13-14/checkpoint_000040/checkpoint-40',\n",
       " 'metric': {'episode_reward_max': 2.984,\n",
       "  'episode_reward_min': -1.6666666666666676,\n",
       "  'episode_reward_mean': -0.8183759820426495,\n",
       "  'episode_len_mean': 895.5,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 0,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [2.035999999999999,\n",
       "    -1.600000000000001,\n",
       "    -1.600000000000001,\n",
       "    -1.6363636363636371,\n",
       "    2.984,\n",
       "    -1.600000000000001,\n",
       "    -1.5454545454545463,\n",
       "    -1.4444444444444453,\n",
       "    -1.3333333333333344,\n",
       "    -1.6363636363636371,\n",
       "    2.876,\n",
       "    -1.4444444444444453,\n",
       "    -1.2500000000000009,\n",
       "    -1.6666666666666676,\n",
       "    -1.5000000000000009,\n",
       "    -1.6363636363636371,\n",
       "    -1.4000000000000008,\n",
       "    -1.3333333333333344],\n",
       "   'episode_lengths': [964,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    16,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    124,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.15396040772497432,\n",
       "   'mean_inference_ms': 15.886685111726731,\n",
       "   'mean_action_processing_ms': 0.1739471256799097,\n",
       "   'mean_env_wait_ms': 2.9833305957190106,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 4,\n",
       "  'timesteps_total': 140296,\n",
       "  'timesteps_this_iter': 0,\n",
       "  'agent_timesteps_total': 140296,\n",
       "  'timers': {'sample_time_ms': 11420.364,\n",
       "   'sample_throughput': 114.182,\n",
       "   'load_time_ms': 0.895,\n",
       "   'load_throughput': 1456285.757,\n",
       "   'learn_time_ms': 3900.089,\n",
       "   'learn_throughput': 334.351,\n",
       "   'update_time_ms': 1.901},\n",
       "  'info': {'learner': {'default_policy': {'learner_stats': {'cur_kl_coeff': 2.1869999999999994,\n",
       "      'cur_lr': 5.000000000000001e-05,\n",
       "      'total_loss': 0.023040482373969433,\n",
       "      'policy_loss': 0.0063706706866229834,\n",
       "      'vf_loss': 0.006575056636019757,\n",
       "      'vf_explained_var': 0.2176180949336604,\n",
       "      'kl': 0.0032929715663684825,\n",
       "      'entropy': 13.179562719244705,\n",
       "      'entropy_coeff': 0.0}}},\n",
       "   'num_steps_sampled': 140296,\n",
       "   'num_agent_steps_sampled': 140296,\n",
       "   'num_steps_trained': 140296,\n",
       "   'num_agent_steps_trained': 140296,\n",
       "   'num_steps_trained_this_iter': 0},\n",
       "  'done': False,\n",
       "  'episodes_total': 128,\n",
       "  'training_iteration': 115,\n",
       "  'trial_id': 'cd6a3_00001',\n",
       "  'experiment_id': '0cf8cf54edd34419bfa82bcca2d54520',\n",
       "  'date': '2022-03-08_23-07-08',\n",
       "  'timestamp': 1646780828,\n",
       "  'time_this_iter_s': 11.373039722442627,\n",
       "  'time_total_s': 1439.9905858039856,\n",
       "  'pid': 1949329,\n",
       "  'hostname': 'pgcotovio-B450-AORUS-ELITE',\n",
       "  'node_ip': '10.20.0.204',\n",
       "  'config': {'num_workers': 4,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 163,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'gamma': 0.99,\n",
       "   'lr': 5e-05,\n",
       "   'train_batch_size': 655,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    '_disable_preprocessor_api': True,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': False,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'framestack': True,\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': 'general_model_torch',\n",
       "    'custom_model_config': {'fcnet_feats': [256, 256]},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1},\n",
       "   'optimizer': {},\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'BiclusterEnv-v0',\n",
       "   'observation_space': None,\n",
       "   'action_space': None,\n",
       "   'env_config': {'shape': [[6, 6], [6, 6]],\n",
       "    'n': 1,\n",
       "    'clusters': [1, 1],\n",
       "    'dataset_settings': {'dstype': {'value': 'Symbolic'},\n",
       "     'patterns': {'value': [['CONSTANT', 'CONSTANT']]},\n",
       "     'symbols': {'value': [-1, 1]},\n",
       "     'bktype': {'value': 'UNIFORM'},\n",
       "     'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]},\n",
       "     'contiguity': {'value': None},\n",
       "     'plaidcoherency': {'value': 'NO_OVERLAPPING'}},\n",
       "    'max_steps': 1000,\n",
       "    'seed': 175},\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'clip_rewards': False,\n",
       "   'normalize_actions': True,\n",
       "   'clip_actions': False,\n",
       "   'preprocessor_pref': None,\n",
       "   'log_level': 'DEBUG',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'torch',\n",
       "   'eager_tracing': False,\n",
       "   'eager_max_retraces': 20,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'StochasticSampling'},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 10,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'min_iter_time_s': 0,\n",
       "   'timesteps_per_iteration': 0,\n",
       "   'seed': 175,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0.0001,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0.24975,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_config': {},\n",
       "   'actions_in_input_normalized': False,\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {'default_policy': PolicySpec(policy_class=<class 'ray.rllib.agents.ppo.ppo_torch_policy.PPOTorchPolicy'>, observation_space=None, action_space=None, config={})},\n",
       "    'policy_map_capacity': 100,\n",
       "    'policy_map_cache': None,\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   '_tf_policy_handles_more_than_one_loss': False,\n",
       "   '_disable_preprocessor_api': True,\n",
       "   'simple_optimizer': False,\n",
       "   'monitor': -1,\n",
       "   'use_critic': True,\n",
       "   'use_gae': True,\n",
       "   'lambda': 0.96,\n",
       "   'kl_coeff': 0.288,\n",
       "   'sgd_minibatch_size': 122,\n",
       "   'shuffle_sequences': True,\n",
       "   'num_sgd_iter': 19,\n",
       "   'lr_schedule': None,\n",
       "   'vf_loss_coeff': 1.44,\n",
       "   'entropy_coeff': 0.0,\n",
       "   'entropy_coeff_schedule': None,\n",
       "   'clip_param': 0.432,\n",
       "   'vf_clip_param': 14.399999999999999,\n",
       "   'grad_clip': None,\n",
       "   'kl_target': 0.0064,\n",
       "   'vf_share_layers': -1},\n",
       "  'time_since_restore': 171.02070879936218,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 15,\n",
       "  'perf': {'cpu_util_percent': 29.949999999999996,\n",
       "   'ram_util_percent': 64.10000000000001,\n",
       "   'gpu_util_percent0': 0.06642857142857142,\n",
       "   'vram_util_percent0': 0.9249267578125,\n",
       "   'gpu_util_percent1': 0.5614285714285714,\n",
       "   'vram_util_percent1': 0.6594325474330357},\n",
       "  'experiment_tag': '1@perturbed[clip_param=0.432,entropy_coeff=0.0,kl_coeff=0.288,kl_target=0.0064,lambda=0.96,lr=5e-05,num_sgd_iter=19,sgd_minibatch_size=122,train_batch_size=655,vf_clip_param=14.4,vf_loss_coeff=1.44]'},\n",
       " 'df': Empty DataFrame\n",
       " Columns: []\n",
       " Index: []}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 23:33:35,265\tWARNING worker.py:1245 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff0227e69b475a9eb7302a09c201000000 Worker ID: 205853743bddaf2571b11b226a09c991beec572ced9f5cbd9366952a Node ID: 55996604780d5c204f46219fe26df8f24e4bbe77cb9e563fa2724bba Worker IP address: 10.20.0.204 Worker port: 36531 Worker PID: 1676815\n",
      "2022-03-08 23:33:35,265\tWARNING worker.py:1245 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff23224c104535b3eed95f72f101000000 Worker ID: 690771c631a8827d872df4d7a8e3a14ccbcdcf47bdad9da1fb655c84 Node ID: 55996604780d5c204f46219fe26df8f24e4bbe77cb9e563fa2724bba Worker IP address: 10.20.0.204 Worker port: 37557 Worker PID: 1676826\n"
     ]
    }
   ],
   "source": [
    "best_checkpoint = trainer.train(\n",
    "    num_samples=8, \n",
    "    scheduler=PPO_PBT,\n",
    "    stop_iters=500,\n",
    ")\n",
    "best_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 23:34:11,930\tINFO experiment_analysis.py:673 -- No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "/home/pgcotovio/repos/nclustRL/venv/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py:262: UserWarning: Dataframes will use '/' instead of '.' to delimit nested result keys in future versions of Ray. For forward compatibility, set the environment variable TUNE_RESULT_DELIM='/'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_reward_max</th>\n",
       "      <th>episode_reward_min</th>\n",
       "      <th>episode_reward_mean</th>\n",
       "      <th>episode_len_mean</th>\n",
       "      <th>episodes_this_iter</th>\n",
       "      <th>num_healthy_workers</th>\n",
       "      <th>timesteps_total</th>\n",
       "      <th>timesteps_this_iter</th>\n",
       "      <th>agent_timesteps_total</th>\n",
       "      <th>done</th>\n",
       "      <th>...</th>\n",
       "      <th>info.learner.default_policy.learner_stats.kl</th>\n",
       "      <th>info.learner.default_policy.learner_stats.entropy</th>\n",
       "      <th>info.learner.default_policy.learner_stats.entropy_coeff</th>\n",
       "      <th>config.env_config.dataset_settings.dstype.value</th>\n",
       "      <th>config.env_config.dataset_settings.patterns.value</th>\n",
       "      <th>config.env_config.dataset_settings.symbols.value</th>\n",
       "      <th>config.env_config.dataset_settings.bktype.value</th>\n",
       "      <th>config.env_config.dataset_settings.clusterdistribution.value</th>\n",
       "      <th>config.env_config.dataset_settings.contiguity.value</th>\n",
       "      <th>config.env_config.dataset_settings.plaidcoherency.value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cd6a3_00000</th>\n",
       "      <td>2.814000</td>\n",
       "      <td>-1.750000</td>\n",
       "      <td>-0.916221</td>\n",
       "      <td>914.230769</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>117240</td>\n",
       "      <td>0</td>\n",
       "      <td>117240</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004712</td>\n",
       "      <td>16.667426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Symbolic</td>\n",
       "      <td>[[CONSTANT, CONSTANT]]</td>\n",
       "      <td>[-1, 1]</td>\n",
       "      <td>UNIFORM</td>\n",
       "      <td>[[UNIFORM, 4, 4], [UNIFORM, 3, 3]]</td>\n",
       "      <td>None</td>\n",
       "      <td>NO_OVERLAPPING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cd6a3_00007</th>\n",
       "      <td>-1.400000</td>\n",
       "      <td>-1.636364</td>\n",
       "      <td>-1.533144</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>149472</td>\n",
       "      <td>0</td>\n",
       "      <td>149472</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023853</td>\n",
       "      <td>12.915991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Symbolic</td>\n",
       "      <td>[[CONSTANT, CONSTANT]]</td>\n",
       "      <td>[-1, 1]</td>\n",
       "      <td>UNIFORM</td>\n",
       "      <td>[[UNIFORM, 4, 4], [UNIFORM, 3, 3]]</td>\n",
       "      <td>None</td>\n",
       "      <td>NO_OVERLAPPING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cd6a3_00001</th>\n",
       "      <td>2.984000</td>\n",
       "      <td>-1.666667</td>\n",
       "      <td>-0.632934</td>\n",
       "      <td>865.357143</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>133776</td>\n",
       "      <td>0</td>\n",
       "      <td>133776</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008617</td>\n",
       "      <td>13.219076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Symbolic</td>\n",
       "      <td>[[CONSTANT, CONSTANT]]</td>\n",
       "      <td>[-1, 1]</td>\n",
       "      <td>UNIFORM</td>\n",
       "      <td>[[UNIFORM, 4, 4], [UNIFORM, 3, 3]]</td>\n",
       "      <td>None</td>\n",
       "      <td>NO_OVERLAPPING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cd6a3_00006</th>\n",
       "      <td>-1.333333</td>\n",
       "      <td>-1.600000</td>\n",
       "      <td>-1.477904</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>144952</td>\n",
       "      <td>0</td>\n",
       "      <td>144952</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013828</td>\n",
       "      <td>13.013030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Symbolic</td>\n",
       "      <td>[[CONSTANT, CONSTANT]]</td>\n",
       "      <td>[-1, 1]</td>\n",
       "      <td>UNIFORM</td>\n",
       "      <td>[[UNIFORM, 4, 4], [UNIFORM, 3, 3]]</td>\n",
       "      <td>None</td>\n",
       "      <td>NO_OVERLAPPING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cd6a3_00005</th>\n",
       "      <td>-1.333333</td>\n",
       "      <td>-1.666667</td>\n",
       "      <td>-1.472348</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>135744</td>\n",
       "      <td>0</td>\n",
       "      <td>135744</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>13.675836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Symbolic</td>\n",
       "      <td>[[CONSTANT, CONSTANT]]</td>\n",
       "      <td>[-1, 1]</td>\n",
       "      <td>UNIFORM</td>\n",
       "      <td>[[UNIFORM, 4, 4], [UNIFORM, 3, 3]]</td>\n",
       "      <td>None</td>\n",
       "      <td>NO_OVERLAPPING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cd6a3_00004</th>\n",
       "      <td>-1.333333</td>\n",
       "      <td>-1.818182</td>\n",
       "      <td>-1.620202</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>122728</td>\n",
       "      <td>0</td>\n",
       "      <td>122728</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018965</td>\n",
       "      <td>15.620097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Symbolic</td>\n",
       "      <td>[[CONSTANT, CONSTANT]]</td>\n",
       "      <td>[-1, 1]</td>\n",
       "      <td>UNIFORM</td>\n",
       "      <td>[[UNIFORM, 4, 4], [UNIFORM, 3, 3]]</td>\n",
       "      <td>None</td>\n",
       "      <td>NO_OVERLAPPING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cd6a3_00003</th>\n",
       "      <td>2.974000</td>\n",
       "      <td>-1.727273</td>\n",
       "      <td>-0.353490</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>137712</td>\n",
       "      <td>0</td>\n",
       "      <td>137712</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024227</td>\n",
       "      <td>13.747019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Symbolic</td>\n",
       "      <td>[[CONSTANT, CONSTANT]]</td>\n",
       "      <td>[-1, 1]</td>\n",
       "      <td>UNIFORM</td>\n",
       "      <td>[[UNIFORM, 4, 4], [UNIFORM, 3, 3]]</td>\n",
       "      <td>None</td>\n",
       "      <td>NO_OVERLAPPING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cd6a3_00002</th>\n",
       "      <td>-1.333333</td>\n",
       "      <td>-1.818182</td>\n",
       "      <td>-1.583586</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>126256</td>\n",
       "      <td>0</td>\n",
       "      <td>126256</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015725</td>\n",
       "      <td>15.986398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Symbolic</td>\n",
       "      <td>[[CONSTANT, CONSTANT]]</td>\n",
       "      <td>[-1, 1]</td>\n",
       "      <td>UNIFORM</td>\n",
       "      <td>[[UNIFORM, 4, 4], [UNIFORM, 3, 3]]</td>\n",
       "      <td>None</td>\n",
       "      <td>NO_OVERLAPPING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             episode_reward_max  episode_reward_min  episode_reward_mean  \\\n",
       "trial_id                                                                   \n",
       "cd6a3_00000            2.814000           -1.750000            -0.916221   \n",
       "cd6a3_00007           -1.400000           -1.636364            -1.533144   \n",
       "cd6a3_00001            2.984000           -1.666667            -0.632934   \n",
       "cd6a3_00006           -1.333333           -1.600000            -1.477904   \n",
       "cd6a3_00005           -1.333333           -1.666667            -1.472348   \n",
       "cd6a3_00004           -1.333333           -1.818182            -1.620202   \n",
       "cd6a3_00003            2.974000           -1.727273            -0.353490   \n",
       "cd6a3_00002           -1.333333           -1.818182            -1.583586   \n",
       "\n",
       "             episode_len_mean  episodes_this_iter  num_healthy_workers  \\\n",
       "trial_id                                                                 \n",
       "cd6a3_00000        914.230769                   0                    4   \n",
       "cd6a3_00007       1001.000000                   0                    4   \n",
       "cd6a3_00001        865.357143                   5                    4   \n",
       "cd6a3_00006       1001.000000                   0                    4   \n",
       "cd6a3_00005       1001.000000                   0                    4   \n",
       "cd6a3_00004       1001.000000                   4                    4   \n",
       "cd6a3_00003        787.000000                   0                    4   \n",
       "cd6a3_00002       1001.000000                   4                    4   \n",
       "\n",
       "             timesteps_total  timesteps_this_iter  agent_timesteps_total  \\\n",
       "trial_id                                                                   \n",
       "cd6a3_00000           117240                    0                 117240   \n",
       "cd6a3_00007           149472                    0                 149472   \n",
       "cd6a3_00001           133776                    0                 133776   \n",
       "cd6a3_00006           144952                    0                 144952   \n",
       "cd6a3_00005           135744                    0                 135744   \n",
       "cd6a3_00004           122728                    0                 122728   \n",
       "cd6a3_00003           137712                    0                 137712   \n",
       "cd6a3_00002           126256                    0                 126256   \n",
       "\n",
       "              done  ...  info.learner.default_policy.learner_stats.kl  \\\n",
       "trial_id            ...                                                 \n",
       "cd6a3_00000  False  ...                                      0.004712   \n",
       "cd6a3_00007  False  ...                                      0.023853   \n",
       "cd6a3_00001  False  ...                                      0.008617   \n",
       "cd6a3_00006  False  ...                                      0.013828   \n",
       "cd6a3_00005  False  ...                                      0.009497   \n",
       "cd6a3_00004  False  ...                                      0.018965   \n",
       "cd6a3_00003  False  ...                                      0.024227   \n",
       "cd6a3_00002  False  ...                                      0.015725   \n",
       "\n",
       "             info.learner.default_policy.learner_stats.entropy  \\\n",
       "trial_id                                                         \n",
       "cd6a3_00000                                          16.667426   \n",
       "cd6a3_00007                                          12.915991   \n",
       "cd6a3_00001                                          13.219076   \n",
       "cd6a3_00006                                          13.013030   \n",
       "cd6a3_00005                                          13.675836   \n",
       "cd6a3_00004                                          15.620097   \n",
       "cd6a3_00003                                          13.747019   \n",
       "cd6a3_00002                                          15.986398   \n",
       "\n",
       "            info.learner.default_policy.learner_stats.entropy_coeff  \\\n",
       "trial_id                                                              \n",
       "cd6a3_00000                                                0.0        \n",
       "cd6a3_00007                                                0.0        \n",
       "cd6a3_00001                                                0.0        \n",
       "cd6a3_00006                                                0.0        \n",
       "cd6a3_00005                                                0.0        \n",
       "cd6a3_00004                                                0.0        \n",
       "cd6a3_00003                                                0.0        \n",
       "cd6a3_00002                                                0.0        \n",
       "\n",
       "            config.env_config.dataset_settings.dstype.value  \\\n",
       "trial_id                                                      \n",
       "cd6a3_00000                                        Symbolic   \n",
       "cd6a3_00007                                        Symbolic   \n",
       "cd6a3_00001                                        Symbolic   \n",
       "cd6a3_00006                                        Symbolic   \n",
       "cd6a3_00005                                        Symbolic   \n",
       "cd6a3_00004                                        Symbolic   \n",
       "cd6a3_00003                                        Symbolic   \n",
       "cd6a3_00002                                        Symbolic   \n",
       "\n",
       "             config.env_config.dataset_settings.patterns.value  \\\n",
       "trial_id                                                         \n",
       "cd6a3_00000                             [[CONSTANT, CONSTANT]]   \n",
       "cd6a3_00007                             [[CONSTANT, CONSTANT]]   \n",
       "cd6a3_00001                             [[CONSTANT, CONSTANT]]   \n",
       "cd6a3_00006                             [[CONSTANT, CONSTANT]]   \n",
       "cd6a3_00005                             [[CONSTANT, CONSTANT]]   \n",
       "cd6a3_00004                             [[CONSTANT, CONSTANT]]   \n",
       "cd6a3_00003                             [[CONSTANT, CONSTANT]]   \n",
       "cd6a3_00002                             [[CONSTANT, CONSTANT]]   \n",
       "\n",
       "             config.env_config.dataset_settings.symbols.value  \\\n",
       "trial_id                                                        \n",
       "cd6a3_00000                                           [-1, 1]   \n",
       "cd6a3_00007                                           [-1, 1]   \n",
       "cd6a3_00001                                           [-1, 1]   \n",
       "cd6a3_00006                                           [-1, 1]   \n",
       "cd6a3_00005                                           [-1, 1]   \n",
       "cd6a3_00004                                           [-1, 1]   \n",
       "cd6a3_00003                                           [-1, 1]   \n",
       "cd6a3_00002                                           [-1, 1]   \n",
       "\n",
       "             config.env_config.dataset_settings.bktype.value  \\\n",
       "trial_id                                                       \n",
       "cd6a3_00000                                          UNIFORM   \n",
       "cd6a3_00007                                          UNIFORM   \n",
       "cd6a3_00001                                          UNIFORM   \n",
       "cd6a3_00006                                          UNIFORM   \n",
       "cd6a3_00005                                          UNIFORM   \n",
       "cd6a3_00004                                          UNIFORM   \n",
       "cd6a3_00003                                          UNIFORM   \n",
       "cd6a3_00002                                          UNIFORM   \n",
       "\n",
       "             config.env_config.dataset_settings.clusterdistribution.value  \\\n",
       "trial_id                                                                    \n",
       "cd6a3_00000                 [[UNIFORM, 4, 4], [UNIFORM, 3, 3]]              \n",
       "cd6a3_00007                 [[UNIFORM, 4, 4], [UNIFORM, 3, 3]]              \n",
       "cd6a3_00001                 [[UNIFORM, 4, 4], [UNIFORM, 3, 3]]              \n",
       "cd6a3_00006                 [[UNIFORM, 4, 4], [UNIFORM, 3, 3]]              \n",
       "cd6a3_00005                 [[UNIFORM, 4, 4], [UNIFORM, 3, 3]]              \n",
       "cd6a3_00004                 [[UNIFORM, 4, 4], [UNIFORM, 3, 3]]              \n",
       "cd6a3_00003                 [[UNIFORM, 4, 4], [UNIFORM, 3, 3]]              \n",
       "cd6a3_00002                 [[UNIFORM, 4, 4], [UNIFORM, 3, 3]]              \n",
       "\n",
       "            config.env_config.dataset_settings.contiguity.value  \\\n",
       "trial_id                                                          \n",
       "cd6a3_00000                                               None    \n",
       "cd6a3_00007                                               None    \n",
       "cd6a3_00001                                               None    \n",
       "cd6a3_00006                                               None    \n",
       "cd6a3_00005                                               None    \n",
       "cd6a3_00004                                               None    \n",
       "cd6a3_00003                                               None    \n",
       "cd6a3_00002                                               None    \n",
       "\n",
       "            config.env_config.dataset_settings.plaidcoherency.value  \n",
       "trial_id                                                             \n",
       "cd6a3_00000                                     NO_OVERLAPPING       \n",
       "cd6a3_00007                                     NO_OVERLAPPING       \n",
       "cd6a3_00001                                     NO_OVERLAPPING       \n",
       "cd6a3_00006                                     NO_OVERLAPPING       \n",
       "cd6a3_00005                                     NO_OVERLAPPING       \n",
       "cd6a3_00004                                     NO_OVERLAPPING       \n",
       "cd6a3_00003                                     NO_OVERLAPPING       \n",
       "cd6a3_00002                                     NO_OVERLAPPING       \n",
       "\n",
       "[8 rows x 208 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get report config\n",
    "\n",
    "analysis = ExperimentAnalysis('/home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_config_v2_hypertune/sample_0/PPO_2022-03-08_19-13-14')\n",
    "\n",
    "analysis.results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Trial:  PPO_BiclusterEnv-v0_cd6a3_00003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_config_v2_hypertune/sample_0/PPO_2022-03-08_19-13-14/PPO_BiclusterEnv-v0_cd6a3_00003_3_2022-03-08_19-17-55/checkpoint_000030/checkpoint-30'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trial = analysis.get_best_trial(metric='episode_reward_mean', mode='max')\n",
    "print('Best Trial: ', best_trial)\n",
    "\n",
    "# best checkpoint\n",
    "\n",
    "analysis.get_best_checkpoint(trial=best_trial, metric='episode_reward_mean', mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_workers': 4,\n",
       " 'create_env_on_driver': False,\n",
       " 'num_envs_per_worker': 1,\n",
       " 'batch_mode': 'truncate_episodes',\n",
       " 'gamma': 0.99,\n",
       " 'use_critic': True,\n",
       " 'use_gae': True,\n",
       " 'lambda': 0.6400000000000001,\n",
       " 'kl_coeff': 0.192,\n",
       " 'rollout_fragment_length': 256,\n",
       " 'train_batch_size': 982,\n",
       " 'sgd_minibatch_size': 122,\n",
       " 'shuffle_sequences': True,\n",
       " 'num_sgd_iter': 19,\n",
       " 'lr': 5e-05,\n",
       " 'lr_schedule': None,\n",
       " 'vf_loss_coeff': 0.96,\n",
       " 'entropy_coeff': 0.0,\n",
       " 'entropy_coeff_schedule': None,\n",
       " 'clip_param': 0.432,\n",
       " 'vf_clip_param': 14.399999999999999,\n",
       " 'grad_clip': None,\n",
       " 'kl_target': 0.0096,\n",
       " 'optimizer': {},\n",
       " 'horizon': None,\n",
       " 'soft_horizon': False,\n",
       " 'no_done_at_end': False,\n",
       " 'env': 'BiclusterEnv-v0',\n",
       " 'observation_space': None,\n",
       " 'action_space': None,\n",
       " 'env_config': {'shape': [[6, 6], [6, 6]],\n",
       "  'n': 1,\n",
       "  'clusters': [1, 1],\n",
       "  'dataset_settings': {'dstype': {'value': 'Symbolic'},\n",
       "   'patterns': {'value': [['CONSTANT', 'CONSTANT']]},\n",
       "   'symbols': {'value': [-1, 1]},\n",
       "   'bktype': {'value': 'UNIFORM'},\n",
       "   'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]},\n",
       "   'contiguity': {'value': None},\n",
       "   'plaidcoherency': {'value': 'NO_OVERLAPPING'}},\n",
       "  'max_steps': 1000,\n",
       "  'seed': 175},\n",
       " 'env_task_fn': None,\n",
       " 'render_env': False,\n",
       " 'record_env': False,\n",
       " 'clip_rewards': False,\n",
       " 'normalize_actions': True,\n",
       " 'preprocessor_pref': None,\n",
       " 'log_level': 'DEBUG',\n",
       " 'ignore_worker_failures': False,\n",
       " 'log_sys_usage': True,\n",
       " 'framework': 'torch',\n",
       " 'eager_tracing': False,\n",
       " 'explore': True,\n",
       " 'exploration_config': {'type': 'StochasticSampling'},\n",
       " 'evaluation_interval': None,\n",
       " 'evaluation_num_episodes': 10,\n",
       " 'evaluation_parallel_to_training': False,\n",
       " 'in_evaluation': False,\n",
       " 'evaluation_config': {'explore': False},\n",
       " 'evaluation_num_workers': 0,\n",
       " 'custom_eval_function': None,\n",
       " 'sample_async': False,\n",
       " 'observation_filter': 'NoFilter',\n",
       " 'synchronize_filters': True,\n",
       " 'compress_observations': False,\n",
       " 'collect_metrics_timeout': 180,\n",
       " 'metrics_smoothing_episodes': 100,\n",
       " 'min_iter_time_s': 0,\n",
       " 'timesteps_per_iteration': 0,\n",
       " 'seed': 175,\n",
       " 'extra_python_environs_for_driver': {},\n",
       " 'extra_python_environs_for_worker': {},\n",
       " 'num_gpus': 0.0001,\n",
       " '_fake_gpus': False,\n",
       " 'num_cpus_per_worker': 1,\n",
       " 'num_gpus_per_worker': 0.24975,\n",
       " 'custom_resources_per_worker': {},\n",
       " 'num_cpus_for_driver': 1,\n",
       " 'placement_strategy': 'PACK',\n",
       " 'logger_config': None,\n",
       " '_disable_preprocessor_api': True,\n",
       " 'model': {'custom_model': 'general_model_torch',\n",
       "  'custom_model_config': {'fcnet_feats': [256, 256]},\n",
       "  'custom_action_dist': None}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0308 23:39:39.764528120 1987670 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646782779.764462976\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646782779.764450883\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get best config\n",
    "\n",
    "tunned_config = analysis.get_best_config(metric='episode_reward_mean', mode='max', scope='all')\n",
    "\n",
    "configs = TrainerConfig('tunned_configs', '/home/pgcotovio/repos/nclustRL/Exp/test_framework2')\n",
    "configs.save(tunned_config)\n",
    "\n",
    "tunned_config == configs.obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train basic_v2 (untunned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 18:17:08,120\tINFO ppo.py:166 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99980)\u001b[0m 2022-03-09 18:17:12,125\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99990)\u001b[0m 2022-03-09 18:17:12,186\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99989)\u001b[0m 2022-03-09 18:17:12,210\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99986)\u001b[0m 2022-03-09 18:17:12,215\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99980)\u001b[0m 2022-03-09 18:17:16,690\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99980)\u001b[0m 2022-03-09 18:17:16,690\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99990)\u001b[0m 2022-03-09 18:17:16,728\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99990)\u001b[0m 2022-03-09 18:17:16,728\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99989)\u001b[0m 2022-03-09 18:17:16,769\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99989)\u001b[0m 2022-03-09 18:17:16,769\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99986)\u001b[0m 2022-03-09 18:17:16,741\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99986)\u001b[0m 2022-03-09 18:17:16,742\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99980)\u001b[0m 2022-03-09 18:17:16,861\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99980)\u001b[0m 2022-03-09 18:17:16,865\tINFO torch_policy.py:186 -- TorchPolicy (worker=1) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99980)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99980)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99990)\u001b[0m 2022-03-09 18:17:16,901\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99990)\u001b[0m 2022-03-09 18:17:16,904\tINFO torch_policy.py:186 -- TorchPolicy (worker=2) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99990)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99990)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99986)\u001b[0m 2022-03-09 18:17:16,913\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99986)\u001b[0m 2022-03-09 18:17:16,915\tINFO torch_policy.py:186 -- TorchPolicy (worker=3) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99989)\u001b[0m 2022-03-09 18:17:16,924\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99989)\u001b[0m 2022-03-09 18:17:16,929\tINFO torch_policy.py:186 -- TorchPolicy (worker=4) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99989)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99989)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99986)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99986)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "2022-03-09 18:17:17,763\tINFO worker_set.py:104 -- Inferred observation/action spaces from remote worker (local worker has no env): {'default_policy': (Dict(action_mask:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), avail_actions:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), state:Box([6 6], [6 6], (2,), int32)), Tuple(Discrete(4), Tuple(Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32)))), '__env__': (Dict(action_mask:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), avail_actions:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), state:Box([6 6], [6 6], (2,), int32)), Tuple(Discrete(4), Tuple(Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32))))}\n",
      "2022-03-09 18:17:17,765\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "2022-03-09 18:17:17,769\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "2022-03-09 18:17:17,815\tINFO torch_policy.py:186 -- TorchPolicy (worker=local) running on 0.0001 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99980)\u001b[0m 2022-03-09 18:17:17,755\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f6a1c6b9640> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99990)\u001b[0m 2022-03-09 18:17:17,853\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f9a20ef2640> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99989)\u001b[0m 2022-03-09 18:17:17,894\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f6760cba640> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=99986)\u001b[0m 2022-03-09 18:17:17,868\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f7dd8aa2640> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "/home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "  warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "2022-03-09 18:17:21,706\tINFO rollout_worker.py:1555 -- Built policy map: {}\n",
      "2022-03-09 18:17:21,707\tINFO rollout_worker.py:1556 -- Built preprocessor map: {'default_policy': None}\n",
      "2022-03-09 18:17:21,707\tINFO rollout_worker.py:618 -- Built filter map: {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x7f5c7fcdbfd0>}\n",
      "2022-03-09 18:17:21,708\tDEBUG rollout_worker.py:728 -- Created rollout worker with env None (None), policies {}\n",
      "2022-03-09 18:17:21,710\tINFO trainable.py:124 -- Trainable.setup took 13.591 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    }
   ],
   "source": [
    "config = DEFAULT_CONFIG.copy()\n",
    "config['env_config'] = biclustering.binary.basic_v2\n",
    "\n",
    "trainer_basic_v2_unttuned = Trainer(\n",
    "    trainer=PPOTrainer,\n",
    "    env='BiclusterEnv-v0',\n",
    "    save_dir='/home/pedro.cotovio/Repos/nclustRL/Exp/test_framework2',\n",
    "    name='basic_v2_config',\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test random agent in basic_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 of 10 done.\n",
      "Episode 2 of 10 done.\n",
      "Episode 3 of 10 done.\n",
      "Episode 4 of 10 done.\n",
      "Episode 5 of 10 done.\n",
      "Episode 6 of 10 done.\n",
      "Episode 7 of 10 done.\n",
      "Episode 8 of 10 done.\n",
      "Episode 9 of 10 done.\n",
      "Episode 10 of 10 done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1.900000000000001, 0.09999999999999995, 5.525888757999928)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_basic_v2_unttuned.test(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-06 18:49:58 (running for 04:31:07.40)<br>Memory usage on this node: 14.2/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 1.0/1 GPUs, 0.0/7.92 GiB heap, 0.0/3.96 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 58725_00000 with episode_reward_mean=-1.2226448484848493 and parameters={'num_workers': 3, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 341, 'batch_mode': 'truncate_episodes', 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 1024, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': True, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'general_model_torch', 'custom_model_config': {'fcnet_feats': [256, 256]}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'BiclusterEnv-v0', 'observation_space': None, 'action_space': None, 'env_config': {'shape': [[6, 6], [6, 6]], 'n': 1, 'clusters': [1, 1], 'dataset_settings': {'dstype': {'value': 'Symbolic'}, 'patterns': {'value': [['CONSTANT', 'CONSTANT']]}, 'symbols': {'value': [-1, 1]}, 'bktype': {'value': 'UNIFORM'}, 'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]}, 'contiguity': {'value': None}, 'plaidcoherency': {'value': 'NO_OVERLAPPING'}}, 'max_steps': 1000, 'seed': 537}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': False, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': None, 'log_level': 'DEBUG', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': 537, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0.0001, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.3333, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'default_policy': PolicySpec(policy_class=<class 'ray.rllib.agents.ppo.ppo_torch_policy.PPOTorchPolicy'>, observation_space=None, action_space=None, config={})}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': True, 'simple_optimizer': False, 'monitor': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1}<br>Result logdir: /home/pedro.cotovio/Repos/nclustRL/Exp/test_framework2/basic_v2_config/sample_0/PPO_2022-03-06_14-18-50<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_checkpoint = trainer_basic_v2_unttuned.train(stop_iters=1000)\n",
    "best_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load and test trained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 18:24:37,386\tINFO trainable.py:467 -- Restored on 10.20.0.204 from checkpoint: /home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_v2_config/sample_0/PPO_2022-03-06_14-18-50/PPO_BiclusterEnv-v0_58725_00000_0_2022-03-06_14-18-50/checkpoint_000270/checkpoint-270\n",
      "2022-03-09 18:24:37,387\tINFO trainable.py:475 -- Current state after restoring: {'_iteration': 270, '_timesteps_total': 0, '_time_total': 8638.795632839203, '_episodes_total': 578}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 of 10 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0309 18:24:46.817591283  104963 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646850286.817553121\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646850286.817549454\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2 of 10 done.\n",
      "Episode 3 of 10 done.\n",
      "Episode 4 of 10 done.\n",
      "Episode 5 of 10 done.\n",
      "Episode 6 of 10 done.\n",
      "Episode 7 of 10 done.\n",
      "Episode 8 of 10 done.\n",
      "Episode 9 of 10 done.\n",
      "Episode 10 of 10 done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1.9160714285714295, 0.0839285714285714, 5.528052786999979)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load agent\n",
    "trainer_basic_v2_unttuned.load('/home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_v2_config/sample_0/PPO_2022-03-06_14-18-50/PPO_BiclusterEnv-v0_58725_00000_0_2022-03-06_14-18-50/checkpoint_000270/checkpoint-270')\n",
    "\n",
    "# test agent\n",
    "trainer_basic_v2_unttuned.test(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train basic_v2 (tunned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 18:26:38,303\tWARNING ppo.py:143 -- `train_batch_size` (982) cannot be achieved with your other settings (num_workers=4 num_envs_per_worker=1 rollout_fragment_length=256)! Auto-adjusting `rollout_fragment_length` to 245.\n",
      "2022-03-09 18:26:38,304\tINFO ppo.py:166 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106096)\u001b[0m 2022-03-09 18:26:42,295\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106102)\u001b[0m 2022-03-09 18:26:42,371\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106098)\u001b[0m 2022-03-09 18:26:42,540\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106093)\u001b[0m 2022-03-09 18:26:42,697\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106096)\u001b[0m 2022-03-09 18:26:46,707\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106096)\u001b[0m 2022-03-09 18:26:46,707\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106102)\u001b[0m 2022-03-09 18:26:46,752\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106102)\u001b[0m 2022-03-09 18:26:46,752\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106093)\u001b[0m 2022-03-09 18:26:47,003\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106093)\u001b[0m 2022-03-09 18:26:47,004\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106096)\u001b[0m 2022-03-09 18:26:46,909\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106096)\u001b[0m 2022-03-09 18:26:46,913\tINFO torch_policy.py:186 -- TorchPolicy (worker=2) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106096)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106096)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106098)\u001b[0m 2022-03-09 18:26:46,927\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106098)\u001b[0m 2022-03-09 18:26:46,927\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106102)\u001b[0m 2022-03-09 18:26:46,921\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106102)\u001b[0m 2022-03-09 18:26:46,925\tINFO torch_policy.py:186 -- TorchPolicy (worker=1) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106102)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106102)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106098)\u001b[0m 2022-03-09 18:26:47,079\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106098)\u001b[0m 2022-03-09 18:26:47,081\tINFO torch_policy.py:186 -- TorchPolicy (worker=4) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106098)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106098)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106093)\u001b[0m 2022-03-09 18:26:47,142\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106093)\u001b[0m 2022-03-09 18:26:47,144\tINFO torch_policy.py:186 -- TorchPolicy (worker=3) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106093)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106093)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "2022-03-09 18:26:47,872\tINFO worker_set.py:104 -- Inferred observation/action spaces from remote worker (local worker has no env): {'default_policy': (Dict(action_mask:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), avail_actions:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), state:Box([6 6], [6 6], (2,), int32)), Tuple(Discrete(4), Tuple(Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32)))), '__env__': (Dict(action_mask:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), avail_actions:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), state:Box([6 6], [6 6], (2,), int32)), Tuple(Discrete(4), Tuple(Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32))))}\n",
      "2022-03-09 18:26:47,873\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "2022-03-09 18:26:47,875\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "2022-03-09 18:26:47,898\tINFO torch_policy.py:186 -- TorchPolicy (worker=local) running on 0.0001 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106096)\u001b[0m 2022-03-09 18:26:47,866\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f1680a028b0> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106102)\u001b[0m 2022-03-09 18:26:47,865\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7efbf21945b0> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106098)\u001b[0m 2022-03-09 18:26:47,994\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f2c25f178b0> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=106093)\u001b[0m 2022-03-09 18:26:48,086\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f9b8d3284f0> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "/home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "  warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "2022-03-09 18:26:51,737\tINFO rollout_worker.py:1555 -- Built policy map: {}\n",
      "2022-03-09 18:26:51,737\tINFO rollout_worker.py:1556 -- Built preprocessor map: {'default_policy': None}\n",
      "2022-03-09 18:26:51,738\tINFO rollout_worker.py:618 -- Built filter map: {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x7f71edabebb0>}\n",
      "2022-03-09 18:26:51,738\tDEBUG rollout_worker.py:728 -- Created rollout worker with env None (None), policies {}\n",
      "2022-03-09 18:26:51,741\tINFO trainable.py:124 -- Trainable.setup took 13.439 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    }
   ],
   "source": [
    "# Inicilize\n",
    "\n",
    "configs = TrainerConfig('tunned_configs', '/home/pgcotovio/repos/nclustRL/Exp/test_framework2')\n",
    "tunned_config = configs.obj\n",
    "\n",
    "trainer_basic_v2_tunned = Trainer(\n",
    "    trainer=PPOTrainer,\n",
    "    env='BiclusterEnv-v0',\n",
    "    save_dir='/home/pgcotovio/repos/nclustRL/Exp/test_framework2',\n",
    "    name='basic_v2_tunned_config',\n",
    "    config=tunned_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-09 04:55:08 (running for 05:12:04.55)<br>Memory usage on this node: 40.4/62.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/2 GPUs, 0.0/31.03 GiB heap, 0.0/15.52 GiB objects<br>Current best trial: 7f365_00000 with episode_reward_mean=-1.4001847474747484 and parameters={'num_workers': 4, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 245, 'batch_mode': 'truncate_episodes', 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 982, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': True, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'general_model_torch', 'custom_model_config': {'fcnet_feats': [256, 256]}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'BiclusterEnv-v0', 'observation_space': None, 'action_space': None, 'env_config': {'shape': [[6, 6], [6, 6]], 'n': 1, 'clusters': [1, 1], 'dataset_settings': {'dstype': {'value': 'Symbolic'}, 'patterns': {'value': [['CONSTANT', 'CONSTANT']]}, 'symbols': {'value': [-1, 1]}, 'bktype': {'value': 'UNIFORM'}, 'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]}, 'contiguity': {'value': None}, 'plaidcoherency': {'value': 'NO_OVERLAPPING'}}, 'max_steps': 1000, 'seed': 175}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': False, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': None, 'log_level': 'DEBUG', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': 175, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0.0001, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.24975, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'default_policy': PolicySpec(policy_class=<class 'ray.rllib.agents.ppo.ppo_torch_policy.PPOTorchPolicy'>, observation_space=None, action_space=None, config={})}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': True, 'simple_optimizer': False, 'monitor': -1, 'use_critic': True, 'use_gae': True, 'lambda': 0.6400000000000001, 'kl_coeff': 0.192, 'sgd_minibatch_size': 122, 'shuffle_sequences': True, 'num_sgd_iter': 19, 'lr_schedule': None, 'vf_loss_coeff': 0.96, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.432, 'vf_clip_param': 14.399999999999999, 'grad_clip': None, 'kl_target': 0.0096, 'vf_share_layers': -1}<br>Result logdir: /home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_v2_tunned_config/sample_0/PPO_2022-03-08_23-43-03<br>Number of trials: 1/1 (1 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 04:55:08,873\tINFO tune.py:626 -- Total run time: 18725.09 seconds (18724.49 seconds for the tuning loop).\n",
      "Sample 1: : 1sample [5:12:05, 18725.13s/sample, metric={'episode_reward_max': 2.679, 'episode_reward_min': -1.6666666666666676, 'episode_reward_mean': -1.4001847474747484, 'episode_len_mean': 994.2, 'episode_media': {}, 'episodes_this_iter': 3, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-1.3636363636363646, -1.3636363636363646, -1.5000000000000009, -1.4166666666666674, -1.5454545454545463, -1.3636363636363646, -1.4166666666666674, -1.5000000000000009, -1.3636363636363646, -1.5833333333333341, -1.3636363636363646, -1.5833333333333341, -1.5000000000000009, -1.300000000000001, -1.5833333333333341, -1.5000000000000009, -1.3636363636363646, -1.3636363636363646, -1.3636363636363646, -1.3636363636363646, -1.5000000000000009, -1.3636363636363646, -1.5000000000000009, -1.6666666666666676, -1.4000000000000008, -1.4545454545454555, -1.5833333333333341, -1.5000000000000009, -1.5000000000000009, -1.3636363636363646, -1.4545454545454555, -1.4545454545454555, -1.5000000000000009, -1.5833333333333341, -1.4166666666666674, -1.3636363636363646, -1.4545454545454555, -1.3636363636363646, -1.4166666666666674, -1.5000000000000009, -1.4545454545454555, -1.3636363636363646, -1.3636363636363646, -1.5000000000000009, -1.4166666666666674, -1.4166666666666674, -1.5000000000000009, -1.5000000000000009, -1.3636363636363646, -1.5000000000000009, -1.5833333333333341, -1.300000000000001, -1.5000000000000009, -1.5000000000000009, 2.679, -1.3636363636363646, -1.5000000000000009, -1.3636363636363646, -1.4545454545454555, -1.4166666666666674, -1.4545454545454555, -1.3636363636363646, -1.3333333333333344, -1.4545454545454555, -1.4444444444444453, -1.4166666666666674, -1.4166666666666674, -1.3636363636363646, -1.4166666666666674, -1.4166666666666674, -1.300000000000001, -1.5833333333333341, -1.5833333333333341, -1.5000000000000009, -1.3636363636363646, -1.4000000000000008, -1.4545454545454555, -1.3636363636363646, -1.5000000000000009, -1.5000000000000009, -1.4166666666666674, -1.3636363636363646, -1.5000000000000009, -1.5000000000000009, -1.3636363636363646, -1.5000000000000009, -1.4166666666666674, -1.3636363636363646, -1.4166666666666674, -1.3636363636363646, -1.5000000000000009, -1.3636363636363646, -1.5000000000000009, -1.4166666666666674, -1.5000000000000009, -1.3636363636363646, -1.5000000000000009, -1.3636363636363646, -1.4545454545454555, -1.5000000000000009], 'episode_lengths': [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 321, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1423636668627669, 'mean_inference_ms': 15.9199235444402, 'mean_action_processing_ms': 0.1718515149551055, 'mean_env_wait_ms': 2.9248115064551614, 'mean_env_render_ms': 0.0}, 'off_policy_estimator': {}, 'num_healthy_workers': 4, 'timesteps_total': 1960000, 'timesteps_this_iter': 0, 'agent_timesteps_total': 1960000, 'timers': {'sample_time_ms': 18776.874, 'sample_throughput': 104.384, 'load_time_ms': 1.009, 'load_throughput': 1942587.452, 'learn_time_ms': 5701.674, 'learn_throughput': 343.759, 'update_time_ms': 2.117}, 'info': {'learner': {'default_policy': {'learner_stats': {'cur_kl_coeff': 1.2812289018575773, 'cur_lr': 5.000000000000001e-05, 'total_loss': -0.003565374703432673, 'policy_loss': -0.017629630728558703, 'vf_loss': 0.003641506034431299, 'vf_explained_var': 0.02838941408615363, 'kl': 0.008248650571323722, 'entropy': 16.75646790705229, 'entropy_coeff': 0.0}}}, 'num_steps_sampled': 1960000, 'num_agent_steps_sampled': 1960000, 'num_steps_trained': 1960000, 'num_agent_steps_trained': 1960000, 'num_steps_trained_this_iter': 0}, 'done': True, 'episodes_total': 1973, 'training_iteration': 1000, 'trial_id': '7f365_00000', 'experiment_id': '47c90f2a88a04c438db949ba43479d5c', 'date': '2022-03-09_04-55-08', 'timestamp': 1646801708, 'time_this_iter_s': 18.776913166046143, 'time_total_s': 18685.924142837524, 'pid': 1989390, 'hostname': 'pgcotovio-B450-AORUS-ELITE', 'node_ip': '10.20.0.204', 'config': {'num_workers': 4, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 245, 'batch_mode': 'truncate_episodes', 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 982, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': True, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'general_model_torch', 'custom_model_config': {'fcnet_feats': [256, 256]}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'BiclusterEnv-v0', 'observation_space': None, 'action_space': None, 'env_config': {'shape': [[6, 6], [6, 6]], 'n': 1, 'clusters': [1, 1], 'dataset_settings': {'dstype': {'value': 'Symbolic'}, 'patterns': {'value': [['CONSTANT', 'CONSTANT']]}, 'symbols': {'value': [-1, 1]}, 'bktype': {'value': 'UNIFORM'}, 'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]}, 'contiguity': {'value': None}, 'plaidcoherency': {'value': 'NO_OVERLAPPING'}}, 'max_steps': 1000, 'seed': 175}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': False, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': None, 'log_level': 'DEBUG', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': 175, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0.0001, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.24975, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'default_policy': PolicySpec(policy_class=<class 'ray.rllib.agents.ppo.ppo_torch_policy.PPOTorchPolicy'>, observation_space=None, action_space=None, config={})}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': True, 'simple_optimizer': False, 'monitor': -1, 'use_critic': True, 'use_gae': True, 'lambda': 0.6400000000000001, 'kl_coeff': 0.192, 'sgd_minibatch_size': 122, 'shuffle_sequences': True, 'num_sgd_iter': 19, 'lr_schedule': None, 'vf_loss_coeff': 0.96, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.432, 'vf_clip_param': 14.399999999999999, 'grad_clip': None, 'kl_target': 0.0096, 'vf_share_layers': -1}, 'time_since_restore': 18685.924142837524, 'timesteps_since_restore': 0, 'iterations_since_restore': 1000, 'perf': {'cpu_util_percent': 26.366666666666664, 'ram_util_percent': 64.40416666666668, 'gpu_util_percent0': 0.06916666666666667, 'vram_util_percent0': 0.9256591796875, 'gpu_util_percent1': 0.47625, 'vram_util_percent1': 0.6539306640625}, 'experiment_tag': '0'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'config': {'num_workers': 4,\n",
       "  'create_env_on_driver': False,\n",
       "  'num_envs_per_worker': 1,\n",
       "  'batch_mode': 'truncate_episodes',\n",
       "  'gamma': 0.99,\n",
       "  'use_critic': True,\n",
       "  'use_gae': True,\n",
       "  'lambda': 0.6400000000000001,\n",
       "  'kl_coeff': 0.192,\n",
       "  'rollout_fragment_length': 256,\n",
       "  'train_batch_size': 982,\n",
       "  'sgd_minibatch_size': 122,\n",
       "  'shuffle_sequences': True,\n",
       "  'num_sgd_iter': 19,\n",
       "  'lr': 5e-05,\n",
       "  'lr_schedule': None,\n",
       "  'vf_loss_coeff': 0.96,\n",
       "  'entropy_coeff': 0.0,\n",
       "  'entropy_coeff_schedule': None,\n",
       "  'clip_param': 0.432,\n",
       "  'vf_clip_param': 14.399999999999999,\n",
       "  'grad_clip': None,\n",
       "  'kl_target': 0.0096,\n",
       "  'optimizer': {},\n",
       "  'horizon': None,\n",
       "  'soft_horizon': False,\n",
       "  'no_done_at_end': False,\n",
       "  'env': 'BiclusterEnv-v0',\n",
       "  'observation_space': None,\n",
       "  'action_space': None,\n",
       "  'env_config': {'shape': [[6, 6], [6, 6]],\n",
       "   'n': 1,\n",
       "   'clusters': [1, 1],\n",
       "   'dataset_settings': {'dstype': {'value': 'Symbolic'},\n",
       "    'patterns': {'value': [['CONSTANT', 'CONSTANT']]},\n",
       "    'symbols': {'value': [-1, 1]},\n",
       "    'bktype': {'value': 'UNIFORM'},\n",
       "    'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]},\n",
       "    'contiguity': {'value': None},\n",
       "    'plaidcoherency': {'value': 'NO_OVERLAPPING'}},\n",
       "   'max_steps': 1000,\n",
       "   'seed': 175},\n",
       "  'env_task_fn': None,\n",
       "  'render_env': False,\n",
       "  'record_env': False,\n",
       "  'clip_rewards': False,\n",
       "  'normalize_actions': True,\n",
       "  'preprocessor_pref': None,\n",
       "  'log_level': 'DEBUG',\n",
       "  'ignore_worker_failures': False,\n",
       "  'log_sys_usage': True,\n",
       "  'framework': 'torch',\n",
       "  'eager_tracing': False,\n",
       "  'explore': True,\n",
       "  'exploration_config': {'type': 'StochasticSampling'},\n",
       "  'evaluation_interval': None,\n",
       "  'evaluation_num_episodes': 10,\n",
       "  'evaluation_parallel_to_training': False,\n",
       "  'in_evaluation': False,\n",
       "  'evaluation_config': {'explore': False},\n",
       "  'evaluation_num_workers': 0,\n",
       "  'custom_eval_function': None,\n",
       "  'sample_async': False,\n",
       "  'observation_filter': 'NoFilter',\n",
       "  'synchronize_filters': True,\n",
       "  'compress_observations': False,\n",
       "  'collect_metrics_timeout': 180,\n",
       "  'metrics_smoothing_episodes': 100,\n",
       "  'min_iter_time_s': 0,\n",
       "  'timesteps_per_iteration': 0,\n",
       "  'seed': 175,\n",
       "  'extra_python_environs_for_driver': {},\n",
       "  'extra_python_environs_for_worker': {},\n",
       "  'num_gpus': 0.0001,\n",
       "  '_fake_gpus': False,\n",
       "  'num_cpus_per_worker': 1,\n",
       "  'num_gpus_per_worker': 0.24975,\n",
       "  'custom_resources_per_worker': {},\n",
       "  'num_cpus_for_driver': 1,\n",
       "  'placement_strategy': 'PACK',\n",
       "  'logger_config': None,\n",
       "  '_disable_preprocessor_api': True,\n",
       "  'model': {'custom_model': 'general_model_torch',\n",
       "   'custom_model_config': {'fcnet_feats': [256, 256]},\n",
       "   'custom_action_dist': None}},\n",
       " 'path': '/home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_v2_tunned_config/sample_0/PPO_2022-03-08_23-43-03/PPO_BiclusterEnv-v0_7f365_00000_0_2022-03-08_23-43-03/checkpoint_000060/checkpoint-60',\n",
       " 'metric': {'episode_reward_max': 2.679,\n",
       "  'episode_reward_min': -1.6666666666666676,\n",
       "  'episode_reward_mean': -1.4001847474747484,\n",
       "  'episode_len_mean': 994.2,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 3,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-1.3636363636363646,\n",
       "    -1.3636363636363646,\n",
       "    -1.5000000000000009,\n",
       "    -1.4166666666666674,\n",
       "    -1.5454545454545463,\n",
       "    -1.3636363636363646,\n",
       "    -1.4166666666666674,\n",
       "    -1.5000000000000009,\n",
       "    -1.3636363636363646,\n",
       "    -1.5833333333333341,\n",
       "    -1.3636363636363646,\n",
       "    -1.5833333333333341,\n",
       "    -1.5000000000000009,\n",
       "    -1.300000000000001,\n",
       "    -1.5833333333333341,\n",
       "    -1.5000000000000009,\n",
       "    -1.3636363636363646,\n",
       "    -1.3636363636363646,\n",
       "    -1.3636363636363646,\n",
       "    -1.3636363636363646,\n",
       "    -1.5000000000000009,\n",
       "    -1.3636363636363646,\n",
       "    -1.5000000000000009,\n",
       "    -1.6666666666666676,\n",
       "    -1.4000000000000008,\n",
       "    -1.4545454545454555,\n",
       "    -1.5833333333333341,\n",
       "    -1.5000000000000009,\n",
       "    -1.5000000000000009,\n",
       "    -1.3636363636363646,\n",
       "    -1.4545454545454555,\n",
       "    -1.4545454545454555,\n",
       "    -1.5000000000000009,\n",
       "    -1.5833333333333341,\n",
       "    -1.4166666666666674,\n",
       "    -1.3636363636363646,\n",
       "    -1.4545454545454555,\n",
       "    -1.3636363636363646,\n",
       "    -1.4166666666666674,\n",
       "    -1.5000000000000009,\n",
       "    -1.4545454545454555,\n",
       "    -1.3636363636363646,\n",
       "    -1.3636363636363646,\n",
       "    -1.5000000000000009,\n",
       "    -1.4166666666666674,\n",
       "    -1.4166666666666674,\n",
       "    -1.5000000000000009,\n",
       "    -1.5000000000000009,\n",
       "    -1.3636363636363646,\n",
       "    -1.5000000000000009,\n",
       "    -1.5833333333333341,\n",
       "    -1.300000000000001,\n",
       "    -1.5000000000000009,\n",
       "    -1.5000000000000009,\n",
       "    2.679,\n",
       "    -1.3636363636363646,\n",
       "    -1.5000000000000009,\n",
       "    -1.3636363636363646,\n",
       "    -1.4545454545454555,\n",
       "    -1.4166666666666674,\n",
       "    -1.4545454545454555,\n",
       "    -1.3636363636363646,\n",
       "    -1.3333333333333344,\n",
       "    -1.4545454545454555,\n",
       "    -1.4444444444444453,\n",
       "    -1.4166666666666674,\n",
       "    -1.4166666666666674,\n",
       "    -1.3636363636363646,\n",
       "    -1.4166666666666674,\n",
       "    -1.4166666666666674,\n",
       "    -1.300000000000001,\n",
       "    -1.5833333333333341,\n",
       "    -1.5833333333333341,\n",
       "    -1.5000000000000009,\n",
       "    -1.3636363636363646,\n",
       "    -1.4000000000000008,\n",
       "    -1.4545454545454555,\n",
       "    -1.3636363636363646,\n",
       "    -1.5000000000000009,\n",
       "    -1.5000000000000009,\n",
       "    -1.4166666666666674,\n",
       "    -1.3636363636363646,\n",
       "    -1.5000000000000009,\n",
       "    -1.5000000000000009,\n",
       "    -1.3636363636363646,\n",
       "    -1.5000000000000009,\n",
       "    -1.4166666666666674,\n",
       "    -1.3636363636363646,\n",
       "    -1.4166666666666674,\n",
       "    -1.3636363636363646,\n",
       "    -1.5000000000000009,\n",
       "    -1.3636363636363646,\n",
       "    -1.5000000000000009,\n",
       "    -1.4166666666666674,\n",
       "    -1.5000000000000009,\n",
       "    -1.3636363636363646,\n",
       "    -1.5000000000000009,\n",
       "    -1.3636363636363646,\n",
       "    -1.4545454545454555,\n",
       "    -1.5000000000000009],\n",
       "   'episode_lengths': [1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    321,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.1423636668627669,\n",
       "   'mean_inference_ms': 15.9199235444402,\n",
       "   'mean_action_processing_ms': 0.1718515149551055,\n",
       "   'mean_env_wait_ms': 2.9248115064551614,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 4,\n",
       "  'timesteps_total': 1960000,\n",
       "  'timesteps_this_iter': 0,\n",
       "  'agent_timesteps_total': 1960000,\n",
       "  'timers': {'sample_time_ms': 18776.874,\n",
       "   'sample_throughput': 104.384,\n",
       "   'load_time_ms': 1.009,\n",
       "   'load_throughput': 1942587.452,\n",
       "   'learn_time_ms': 5701.674,\n",
       "   'learn_throughput': 343.759,\n",
       "   'update_time_ms': 2.117},\n",
       "  'info': {'learner': {'default_policy': {'learner_stats': {'cur_kl_coeff': 1.2812289018575773,\n",
       "      'cur_lr': 5.000000000000001e-05,\n",
       "      'total_loss': -0.003565374703432673,\n",
       "      'policy_loss': -0.017629630728558703,\n",
       "      'vf_loss': 0.003641506034431299,\n",
       "      'vf_explained_var': 0.02838941408615363,\n",
       "      'kl': 0.008248650571323722,\n",
       "      'entropy': 16.75646790705229,\n",
       "      'entropy_coeff': 0.0}}},\n",
       "   'num_steps_sampled': 1960000,\n",
       "   'num_agent_steps_sampled': 1960000,\n",
       "   'num_steps_trained': 1960000,\n",
       "   'num_agent_steps_trained': 1960000,\n",
       "   'num_steps_trained_this_iter': 0},\n",
       "  'done': True,\n",
       "  'episodes_total': 1973,\n",
       "  'training_iteration': 1000,\n",
       "  'trial_id': '7f365_00000',\n",
       "  'experiment_id': '47c90f2a88a04c438db949ba43479d5c',\n",
       "  'date': '2022-03-09_04-55-08',\n",
       "  'timestamp': 1646801708,\n",
       "  'time_this_iter_s': 18.776913166046143,\n",
       "  'time_total_s': 18685.924142837524,\n",
       "  'pid': 1989390,\n",
       "  'hostname': 'pgcotovio-B450-AORUS-ELITE',\n",
       "  'node_ip': '10.20.0.204',\n",
       "  'config': {'num_workers': 4,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 245,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'gamma': 0.99,\n",
       "   'lr': 5e-05,\n",
       "   'train_batch_size': 982,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    '_disable_preprocessor_api': True,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': False,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'framestack': True,\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': 'general_model_torch',\n",
       "    'custom_model_config': {'fcnet_feats': [256, 256]},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1},\n",
       "   'optimizer': {},\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'BiclusterEnv-v0',\n",
       "   'observation_space': None,\n",
       "   'action_space': None,\n",
       "   'env_config': {'shape': [[6, 6], [6, 6]],\n",
       "    'n': 1,\n",
       "    'clusters': [1, 1],\n",
       "    'dataset_settings': {'dstype': {'value': 'Symbolic'},\n",
       "     'patterns': {'value': [['CONSTANT', 'CONSTANT']]},\n",
       "     'symbols': {'value': [-1, 1]},\n",
       "     'bktype': {'value': 'UNIFORM'},\n",
       "     'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]},\n",
       "     'contiguity': {'value': None},\n",
       "     'plaidcoherency': {'value': 'NO_OVERLAPPING'}},\n",
       "    'max_steps': 1000,\n",
       "    'seed': 175},\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'clip_rewards': False,\n",
       "   'normalize_actions': True,\n",
       "   'clip_actions': False,\n",
       "   'preprocessor_pref': None,\n",
       "   'log_level': 'DEBUG',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'torch',\n",
       "   'eager_tracing': False,\n",
       "   'eager_max_retraces': 20,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'StochasticSampling'},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 10,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'min_iter_time_s': 0,\n",
       "   'timesteps_per_iteration': 0,\n",
       "   'seed': 175,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0.0001,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0.24975,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_config': {},\n",
       "   'actions_in_input_normalized': False,\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {'default_policy': PolicySpec(policy_class=<class 'ray.rllib.agents.ppo.ppo_torch_policy.PPOTorchPolicy'>, observation_space=None, action_space=None, config={})},\n",
       "    'policy_map_capacity': 100,\n",
       "    'policy_map_cache': None,\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   '_tf_policy_handles_more_than_one_loss': False,\n",
       "   '_disable_preprocessor_api': True,\n",
       "   'simple_optimizer': False,\n",
       "   'monitor': -1,\n",
       "   'use_critic': True,\n",
       "   'use_gae': True,\n",
       "   'lambda': 0.6400000000000001,\n",
       "   'kl_coeff': 0.192,\n",
       "   'sgd_minibatch_size': 122,\n",
       "   'shuffle_sequences': True,\n",
       "   'num_sgd_iter': 19,\n",
       "   'lr_schedule': None,\n",
       "   'vf_loss_coeff': 0.96,\n",
       "   'entropy_coeff': 0.0,\n",
       "   'entropy_coeff_schedule': None,\n",
       "   'clip_param': 0.432,\n",
       "   'vf_clip_param': 14.399999999999999,\n",
       "   'grad_clip': None,\n",
       "   'kl_target': 0.0096,\n",
       "   'vf_share_layers': -1},\n",
       "  'time_since_restore': 18685.924142837524,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 1000,\n",
       "  'perf': {'cpu_util_percent': 26.366666666666664,\n",
       "   'ram_util_percent': 64.40416666666668,\n",
       "   'gpu_util_percent0': 0.06916666666666667,\n",
       "   'vram_util_percent0': 0.9256591796875,\n",
       "   'gpu_util_percent1': 0.47625,\n",
       "   'vram_util_percent1': 0.6539306640625},\n",
       "  'experiment_tag': '0'},\n",
       " 'df':    episode_reward_max  episode_reward_min  episode_reward_mean  \\\n",
       " 0               2.359           -1.666667            -0.797695   \n",
       " \n",
       "    episode_len_mean  episodes_this_iter  num_healthy_workers  timesteps_total  \\\n",
       " 0             929.0                   1                    4             7840   \n",
       " \n",
       "    timesteps_this_iter  agent_timesteps_total   done  ...  \\\n",
       " 0                    0                   7840  False  ...   \n",
       " \n",
       "    config/shuffle_sequences  config/soft_horizon config/synchronize_filters  \\\n",
       " 0                      True                False                       True   \n",
       " \n",
       "   config/timesteps_per_iteration config/train_batch_size  config/use_critic  \\\n",
       " 0                              0                     982               True   \n",
       " \n",
       "    config/use_gae  config/vf_clip_param  config/vf_loss_coeff  \\\n",
       " 0            True                  14.4                  0.96   \n",
       " \n",
       "                                               logdir  \n",
       " 0  /home/pgcotovio/repos/nclustRL/Exp/test_framew...  \n",
       " \n",
       " [1 rows x 125 columns]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0309 05:04:43.857621560 2335227 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646802283.857580873\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646802283.857573900\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 05:09:03.942579142 2337586 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646802543.942511494\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646802543.942501275\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 05:33:44.319683530 2351328 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646804024.319617525\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646804024.319606023\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 06:08:49.982421117 2370365 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646806129.982374459\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646806129.982370100\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 06:20:55.307150511 2377058 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646806855.307086219\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646806855.307076170\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 06:35:40.606708346 2385649 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646807740.606637823\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646807740.606619438\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 07:26:01.497666483 2413430 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646810761.497603444\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646810761.497593274\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 07:33:26.673686503 2417460 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646811206.673623845\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646811206.673614097\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 07:34:26.685685257 2418009 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646811266.685618841\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646811266.685608031\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 08:15:27.692751495 2440478 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646813727.692685760\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646813727.692674990\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 08:20:47.948691178 2443395 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646814047.948629582\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646814047.948619533\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 08:36:58.351666770 2452186 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646815018.351606435\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646815018.351593882\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 09:03:09.005662820 2466537 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646816589.005599901\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646816589.005590173\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 09:29:54.609662459 2481218 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646818194.609600131\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646818194.609587868\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "best_checkpoint = trainer_basic_v2_tunned.train(stop_iters=1000)\n",
    "best_checkpoint['df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_reward_max</th>\n",
       "      <th>episode_reward_min</th>\n",
       "      <th>episode_reward_mean</th>\n",
       "      <th>episode_len_mean</th>\n",
       "      <th>episodes_this_iter</th>\n",
       "      <th>num_healthy_workers</th>\n",
       "      <th>timesteps_total</th>\n",
       "      <th>timesteps_this_iter</th>\n",
       "      <th>agent_timesteps_total</th>\n",
       "      <th>done</th>\n",
       "      <th>...</th>\n",
       "      <th>config/shuffle_sequences</th>\n",
       "      <th>config/soft_horizon</th>\n",
       "      <th>config/synchronize_filters</th>\n",
       "      <th>config/timesteps_per_iteration</th>\n",
       "      <th>config/train_batch_size</th>\n",
       "      <th>config/use_critic</th>\n",
       "      <th>config/use_gae</th>\n",
       "      <th>config/vf_clip_param</th>\n",
       "      <th>config/vf_loss_coeff</th>\n",
       "      <th>logdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.359</td>\n",
       "      <td>-1.666667</td>\n",
       "      <td>-0.797695</td>\n",
       "      <td>929.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7840</td>\n",
       "      <td>0</td>\n",
       "      <td>7840</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>982</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0.96</td>\n",
       "      <td>/home/pgcotovio/repos/nclustRL/Exp/test_framew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode_reward_max  episode_reward_min  episode_reward_mean  \\\n",
       "0               2.359           -1.666667            -0.797695   \n",
       "\n",
       "   episode_len_mean  episodes_this_iter  num_healthy_workers  timesteps_total  \\\n",
       "0             929.0                   1                    4             7840   \n",
       "\n",
       "   timesteps_this_iter  agent_timesteps_total   done  ...  \\\n",
       "0                    0                   7840  False  ...   \n",
       "\n",
       "   config/shuffle_sequences  config/soft_horizon config/synchronize_filters  \\\n",
       "0                      True                False                       True   \n",
       "\n",
       "  config/timesteps_per_iteration config/train_batch_size  config/use_critic  \\\n",
       "0                              0                     982               True   \n",
       "\n",
       "   config/use_gae  config/vf_clip_param  config/vf_loss_coeff  \\\n",
       "0            True                  14.4                  0.96   \n",
       "\n",
       "                                              logdir  \n",
       "0  /home/pgcotovio/repos/nclustRL/Exp/test_framew...  \n",
       "\n",
       "[1 rows x 125 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_checkpoint['df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_v2_tunned_config/sample_0/PPO_2022-03-08_23-43-03/PPO_BiclusterEnv-v0_7f365_00000_0_2022-03-08_23-43-03/checkpoint_000060/checkpoint-60'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_checkpoint['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 18:28:09,743\tINFO trainable.py:467 -- Restored on 10.20.0.204 from checkpoint: /home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_v2_tunned_config/sample_0/PPO_2022-03-08_23-43-03/PPO_BiclusterEnv-v0_7f365_00000_0_2022-03-08_23-43-03/checkpoint_000060/checkpoint-60\n",
      "2022-03-09 18:28:09,744\tINFO trainable.py:475 -- Current state after restoring: {'_iteration': 60, '_timesteps_total': 0, '_time_total': 1072.0786392688751, '_episodes_total': 124}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 of 10 done.\n",
      "Episode 2 of 10 done.\n",
      "Episode 3 of 10 done.\n",
      "Episode 4 of 10 done.\n",
      "Episode 5 of 10 done.\n",
      "Episode 6 of 10 done.\n",
      "Episode 7 of 10 done.\n",
      "Episode 8 of 10 done.\n",
      "Episode 9 of 10 done.\n",
      "Episode 10 of 10 done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1.8464285714285722, 0.15357142857142855, 5.4613246079999955)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0309 19:52:43.908705212  157933 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646855563.908656960\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646855563.908653093\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 20:06:48.965770920  166416 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646856408.965718972\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646856408.965714363\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 20:26:19.077712065  178015 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646857579.077663373\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646857579.077659656\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 21:39:59.349754574  221933 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646861999.349701493\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646861999.349697496\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 22:04:44.393937918  236851 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646863484.393887272\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646863484.393883034\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 22:16:04.415774896  243617 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646864164.415724611\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646864164.415720604\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 22:46:04.525765546  261499 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646865964.525712907\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646865964.525708589\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 22:52:19.525800949  265203 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646866339.525748449\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646866339.525744422\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n"
     ]
    }
   ],
   "source": [
    "# load and test\n",
    "trainer_basic_v2_tunned.load('/home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_v2_tunned_config/sample_0/PPO_2022-03-08_23-43-03/PPO_BiclusterEnv-v0_7f365_00000_0_2022-03-08_23-43-03/checkpoint_000060/checkpoint-60')\n",
    "\n",
    "trainer_basic_v2_tunned.test(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v3 Midly Shaped Reward (Reduced steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparam tune basic_v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inicialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 01:09:18,097\tINFO ppo.py:166 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352196)\u001b[0m 2022-03-10 01:09:22,365\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352193)\u001b[0m 2022-03-10 01:09:22,386\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352200)\u001b[0m 2022-03-10 01:09:22,501\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352199)\u001b[0m 2022-03-10 01:09:22,457\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352200)\u001b[0m 2022-03-10 01:09:27,055\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352200)\u001b[0m 2022-03-10 01:09:27,056\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352193)\u001b[0m 2022-03-10 01:09:27,033\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352193)\u001b[0m 2022-03-10 01:09:27,034\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352199)\u001b[0m 2022-03-10 01:09:27,084\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352199)\u001b[0m 2022-03-10 01:09:27,084\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352200)\u001b[0m 2022-03-10 01:09:27,248\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352200)\u001b[0m 2022-03-10 01:09:27,252\tINFO torch_policy.py:186 -- TorchPolicy (worker=1) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352200)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352200)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352196)\u001b[0m 2022-03-10 01:09:27,248\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352196)\u001b[0m 2022-03-10 01:09:27,249\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352196)\u001b[0m 2022-03-10 01:09:27,251\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352196)\u001b[0m 2022-03-10 01:09:27,254\tINFO torch_policy.py:186 -- TorchPolicy (worker=3) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352196)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352196)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352193)\u001b[0m 2022-03-10 01:09:27,238\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352193)\u001b[0m 2022-03-10 01:09:27,242\tINFO torch_policy.py:186 -- TorchPolicy (worker=4) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352193)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352193)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352199)\u001b[0m 2022-03-10 01:09:27,283\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352199)\u001b[0m 2022-03-10 01:09:27,286\tINFO torch_policy.py:186 -- TorchPolicy (worker=2) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352199)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352199)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352196)\u001b[0m 2022-03-10 01:09:28,265\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7fd9993bee20> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352193)\u001b[0m 2022-03-10 01:09:28,255\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7fbd72d47e50> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352199)\u001b[0m 2022-03-10 01:09:28,231\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f5fbced9e20> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "2022-03-10 01:09:28,411\tINFO worker_set.py:104 -- Inferred observation/action spaces from remote worker (local worker has no env): {'default_policy': (Dict(action_mask:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), avail_actions:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), state:Box([6 6], [6 6], (2,), int32)), Tuple(Discrete(4), Tuple(Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32)))), '__env__': (Dict(action_mask:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), avail_actions:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), state:Box([6 6], [6 6], (2,), int32)), Tuple(Discrete(4), Tuple(Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32))))}\n",
      "2022-03-10 01:09:28,412\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "2022-03-10 01:09:28,415\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "2022-03-10 01:09:28,443\tINFO torch_policy.py:186 -- TorchPolicy (worker=local) running on 0.0001 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=352200)\u001b[0m 2022-03-10 01:09:28,403\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f45d5fb3b50> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "/home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "  warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "2022-03-10 01:09:32,400\tINFO rollout_worker.py:1555 -- Built policy map: {}\n",
      "2022-03-10 01:09:32,400\tINFO rollout_worker.py:1556 -- Built preprocessor map: {'default_policy': None}\n",
      "2022-03-10 01:09:32,401\tINFO rollout_worker.py:618 -- Built filter map: {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x7f25b63b4fd0>}\n",
      "2022-03-10 01:09:32,401\tDEBUG rollout_worker.py:728 -- Created rollout worker with env None (None), policies {}\n",
      "2022-03-10 01:09:32,404\tINFO trainable.py:124 -- Trainable.setup took 14.308 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    }
   ],
   "source": [
    "config = DEFAULT_CONFIG.copy()\n",
    "config['env_config'] = biclustering.binary.basic_v3\n",
    "\n",
    "trainer = Trainer(\n",
    "    trainer=PPOTrainer,\n",
    "    env='BiclusterEnv-v0',\n",
    "    save_dir='/home/pgcotovio/repos/nclustRL/Exp/test_framework2',\n",
    "    name='basic_config_v3_hypertune',\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-10 14:58:50 (running for 13:49:18.30)<br>Memory usage on this node: 39.5/62.7 GiB<br>PopulationBasedTraining: 82 checkpoints, 66 perturbs<br>Resources requested: 0/12 CPUs, 0/2 GPUs, 0.0/34.5 GiB heap, 0.0/17.25 GiB objects<br>Current best trial: be5d5_00001 with episode_reward_mean=0.3908080808080808 and parameters={'num_workers': 4, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 144, 'batch_mode': 'truncate_episodes', 'gamma': 0.99, 'lr': 1e-05, 'train_batch_size': 577, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': True, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'general_model_torch', 'custom_model_config': {'fcnet_feats': [256, 256]}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'BiclusterEnv-v0', 'observation_space': None, 'action_space': None, 'env_config': {'shape': [[6, 6], [6, 6]], 'n': 1, 'clusters': [1, 1], 'dataset_settings': {'dstype': {'value': 'Symbolic'}, 'patterns': {'value': [['CONSTANT', 'CONSTANT']]}, 'symbols': {'value': [-1, 1]}, 'bktype': {'value': 'UNIFORM'}, 'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]}, 'contiguity': {'value': None}, 'plaidcoherency': {'value': 'NO_OVERLAPPING'}}, 'max_steps': 50, 'reward_shaping': 0.1, 'seed': 175}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': False, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': None, 'log_level': 'DEBUG', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': 175, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0.0001, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.24975, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'default_policy': PolicySpec(policy_class=<class 'ray.rllib.agents.ppo.ppo_torch_policy.PPOTorchPolicy'>, observation_space=None, action_space=None, config={})}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': True, 'simple_optimizer': False, 'monitor': -1, 'use_critic': True, 'use_gae': True, 'lambda': 0.37748736000000005, 'kl_coeff': 0.382205952, 'sgd_minibatch_size': 70, 'shuffle_sequences': True, 'num_sgd_iter': 21, 'lr_schedule': None, 'vf_loss_coeff': 0.8493465600000002, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.254803968, 'vf_clip_param': 3.7748736000000016, 'grad_clip': None, 'kl_target': 0.008493465599999998, 'vf_share_layers': -1}<br>Result logdir: /home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_config_v3_hypertune/sample_0/PPO_2022-03-10_01-09-32<br>Number of trials: 8/8 (8 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 14:58:51,697\tINFO tune.py:626 -- Total run time: 49759.16 seconds (49758.25 seconds for the tuning loop).\n",
      "Sample 1: : 1sample [13:49:19, 49759.24s/sample, metric={'episode_reward_max': 0.6277777777777778, 'episode_reward_min': 0.12272727272727266, 'episode_reward_mean': 0.3908080808080808, 'episode_len_mean': 51.0, 'episode_media': {}, 'episodes_this_iter': 24, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.3954545454545454, 0.3954545454545454, 0.44999999999999996, 0.44999999999999996, 0.3954545454545454, 0.30454545454545456, 0.44999999999999996, 0.6277777777777778, 0.6, 0.44999999999999996, 0.30454545454545456, 0.35, 0.30454545454545456, 0.35, 0.35, 0.30454545454545456, 0.35, 0.30454545454545456, 0.44999999999999996, 0.1833333333333332, 0.6277777777777778, 0.12272727272727266, 0.3954545454545454, 0.5499999999999999, 0.5166666666666666, 0.35, 0.5166666666666666, 0.5499999999999999, 0.3954545454545454, 0.44999999999999996, 0.35, 0.2666666666666667, 0.24999999999999997, 0.3954545454545454, 0.48636363636363633, 0.5499999999999999, 0.5166666666666666, 0.2666666666666667, 0.35, 0.44999999999999996, 0.2136363636363636, 0.44999999999999996, 0.5166666666666666, 0.48636363636363633, 0.5166666666666666, 0.5166666666666666, 0.48636363636363633, 0.3954545454545454, 0.44999999999999996, 0.3954545454545454, 0.3954545454545454, 0.5499999999999999, 0.35, 0.35, 0.30454545454545456, 0.3954545454545454, 0.30454545454545456, 0.44999999999999996, 0.2666666666666667, 0.2666666666666667, 0.2666666666666667, 0.3954545454545454, 0.24999999999999997, 0.35, 0.30454545454545456, 0.1833333333333332, 0.40555555555555556, 0.2666666666666667, 0.2666666666666667, 0.30454545454545456, 0.3954545454545454, 0.3954545454545454, 0.3954545454545454, 0.5166666666666666, 0.3954545454545454, 0.24999999999999997, 0.30454545454545456, 0.5166666666666666, 0.35, 0.44999999999999996, 0.44999999999999996, 0.44999999999999996, 0.2666666666666667, 0.35, 0.30454545454545456, 0.6277777777777778, 0.35, 0.2666666666666667, 0.30454545454545456, 0.44999999999999996, 0.35, 0.5499999999999999, 0.30454545454545456, 0.44999999999999996, 0.44999999999999996, 0.5499999999999999, 0.35, 0.35, 0.40555555555555556, 0.35], 'episode_lengths': [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.29559095734252794, 'mean_inference_ms': 15.212757694154575, 'mean_action_processing_ms': 0.1710952861799759, 'mean_env_wait_ms': 2.863935045137165, 'mean_env_render_ms': 0.0}, 'off_policy_estimator': {}, 'num_healthy_workers': 4, 'timesteps_total': 545696, 'timesteps_this_iter': 0, 'agent_timesteps_total': 545696, 'timers': {'sample_time_ms': 11674.321, 'sample_throughput': 98.678, 'load_time_ms': 0.949, 'load_throughput': 1214220.376, 'learn_time_ms': 6081.905, 'learn_throughput': 189.414, 'update_time_ms': 2.132}, 'info': {'learner': {'default_policy': {'learner_stats': {'cur_kl_coeff': 1.2899450879999999, 'cur_lr': 1e-05, 'total_loss': 0.0028112514986181245, 'policy_loss': -0.017196579008343958, 'vf_loss': 0.005571838875073895, 'vf_explained_var': 0.1131897284871056, 'kl': 0.01184190554687077, 'entropy': 13.627630307560874, 'entropy_coeff': 0.0}}}, 'num_steps_sampled': 545696, 'num_agent_steps_sampled': 545696, 'num_steps_trained': 545696, 'num_agent_steps_trained': 545696, 'num_steps_trained_this_iter': 0}, 'done': True, 'episodes_total': 10635, 'training_iteration': 500, 'trial_id': 'be5d5_00001', 'experiment_id': 'd35c5f6902ad458ab484dcc74c45a8ad', 'date': '2022-03-10_14-58-50', 'timestamp': 1646924330, 'time_this_iter_s': 12.396902084350586, 'time_total_s': 5351.209007740021, 'pid': 1357446, 'hostname': 'pgcotovio-B450-AORUS-ELITE', 'node_ip': '10.20.0.204', 'config': {'num_workers': 4, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 144, 'batch_mode': 'truncate_episodes', 'gamma': 0.99, 'lr': 1e-05, 'train_batch_size': 577, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': True, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'general_model_torch', 'custom_model_config': {'fcnet_feats': [256, 256]}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'BiclusterEnv-v0', 'observation_space': None, 'action_space': None, 'env_config': {'shape': [[6, 6], [6, 6]], 'n': 1, 'clusters': [1, 1], 'dataset_settings': {'dstype': {'value': 'Symbolic'}, 'patterns': {'value': [['CONSTANT', 'CONSTANT']]}, 'symbols': {'value': [-1, 1]}, 'bktype': {'value': 'UNIFORM'}, 'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]}, 'contiguity': {'value': None}, 'plaidcoherency': {'value': 'NO_OVERLAPPING'}}, 'max_steps': 50, 'reward_shaping': 0.1, 'seed': 175}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': False, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': None, 'log_level': 'DEBUG', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': 175, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0.0001, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.24975, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'default_policy': PolicySpec(policy_class=<class 'ray.rllib.agents.ppo.ppo_torch_policy.PPOTorchPolicy'>, observation_space=None, action_space=None, config={})}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': True, 'simple_optimizer': False, 'monitor': -1, 'use_critic': True, 'use_gae': True, 'lambda': 0.37748736000000005, 'kl_coeff': 0.382205952, 'sgd_minibatch_size': 70, 'shuffle_sequences': True, 'num_sgd_iter': 21, 'lr_schedule': None, 'vf_loss_coeff': 0.8493465600000002, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.254803968, 'vf_clip_param': 3.7748736000000016, 'grad_clip': None, 'kl_target': 0.008493465599999998, 'vf_share_layers': -1}, 'time_since_restore': 99.32835578918457, 'timesteps_since_restore': 0, 'iterations_since_restore': 8, 'perf': {'cpu_util_percent': 24.84666666666666, 'ram_util_percent': 62.87999999999999, 'gpu_util_percent0': 0.09733333333333333, 'vram_util_percent0': 0.9246826171875, 'gpu_util_percent1': 0.3893333333333333, 'vram_util_percent1': 0.6618815104166667}, 'experiment_tag': '1@perturbed[clip_param=0.2548,entropy_coeff=0.0,kl_coeff=0.38221,kl_target=0.0084935,lambda=0.37749,lr=1e-05,num_sgd_iter=21,sgd_minibatch_size=70,train_batch_size=577,vf_clip_param=3.7749,vf_loss_coeff=0.84935]'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'config': {'num_workers': 4,\n",
       "  'create_env_on_driver': False,\n",
       "  'num_envs_per_worker': 1,\n",
       "  'batch_mode': 'truncate_episodes',\n",
       "  'gamma': 0.99,\n",
       "  'use_critic': True,\n",
       "  'use_gae': True,\n",
       "  'lambda': 0.37748736000000005,\n",
       "  'kl_coeff': 0.382205952,\n",
       "  'rollout_fragment_length': 256,\n",
       "  'train_batch_size': 577,\n",
       "  'sgd_minibatch_size': 70,\n",
       "  'shuffle_sequences': True,\n",
       "  'num_sgd_iter': 21,\n",
       "  'lr': 1e-05,\n",
       "  'lr_schedule': None,\n",
       "  'vf_loss_coeff': 0.8493465600000002,\n",
       "  'entropy_coeff': 0.0,\n",
       "  'entropy_coeff_schedule': None,\n",
       "  'clip_param': 0.254803968,\n",
       "  'vf_clip_param': 3.7748736000000016,\n",
       "  'grad_clip': None,\n",
       "  'kl_target': 0.008493465599999998,\n",
       "  'optimizer': {},\n",
       "  'horizon': None,\n",
       "  'soft_horizon': False,\n",
       "  'no_done_at_end': False,\n",
       "  'env': 'BiclusterEnv-v0',\n",
       "  'observation_space': None,\n",
       "  'action_space': None,\n",
       "  'env_config': {'shape': [[6, 6], [6, 6]],\n",
       "   'n': 1,\n",
       "   'clusters': [1, 1],\n",
       "   'dataset_settings': {'dstype': {'value': 'Symbolic'},\n",
       "    'patterns': {'value': [['CONSTANT', 'CONSTANT']]},\n",
       "    'symbols': {'value': [-1, 1]},\n",
       "    'bktype': {'value': 'UNIFORM'},\n",
       "    'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]},\n",
       "    'contiguity': {'value': None},\n",
       "    'plaidcoherency': {'value': 'NO_OVERLAPPING'}},\n",
       "   'max_steps': 50,\n",
       "   'reward_shaping': 0.1,\n",
       "   'seed': 175},\n",
       "  'env_task_fn': None,\n",
       "  'render_env': False,\n",
       "  'record_env': False,\n",
       "  'clip_rewards': False,\n",
       "  'normalize_actions': True,\n",
       "  'preprocessor_pref': None,\n",
       "  'log_level': 'DEBUG',\n",
       "  'ignore_worker_failures': False,\n",
       "  'log_sys_usage': True,\n",
       "  'framework': 'torch',\n",
       "  'eager_tracing': False,\n",
       "  'explore': True,\n",
       "  'exploration_config': {'type': 'StochasticSampling'},\n",
       "  'evaluation_interval': None,\n",
       "  'evaluation_num_episodes': 10,\n",
       "  'evaluation_parallel_to_training': False,\n",
       "  'in_evaluation': False,\n",
       "  'evaluation_config': {'explore': False},\n",
       "  'evaluation_num_workers': 0,\n",
       "  'custom_eval_function': None,\n",
       "  'sample_async': False,\n",
       "  'observation_filter': 'NoFilter',\n",
       "  'synchronize_filters': True,\n",
       "  'compress_observations': False,\n",
       "  'collect_metrics_timeout': 180,\n",
       "  'metrics_smoothing_episodes': 100,\n",
       "  'min_iter_time_s': 0,\n",
       "  'timesteps_per_iteration': 0,\n",
       "  'seed': 175,\n",
       "  'extra_python_environs_for_driver': {},\n",
       "  'extra_python_environs_for_worker': {},\n",
       "  'num_gpus': 0.0001,\n",
       "  '_fake_gpus': False,\n",
       "  'num_cpus_per_worker': 1,\n",
       "  'num_gpus_per_worker': 0.24975,\n",
       "  'custom_resources_per_worker': {},\n",
       "  'num_cpus_for_driver': 1,\n",
       "  'placement_strategy': 'PACK',\n",
       "  'logger_config': None,\n",
       "  '_disable_preprocessor_api': True,\n",
       "  'model': {'custom_model': 'general_model_torch',\n",
       "   'custom_model_config': {'fcnet_feats': [256, 256]},\n",
       "   'custom_action_dist': None}},\n",
       " 'path': '/home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_config_v3_hypertune/sample_0/PPO_2022-03-10_01-09-32/PPO_BiclusterEnv-v0_be5d5_00001_1_2022-03-10_01-09-32/checkpoint_000500/checkpoint-500',\n",
       " 'metric': {'episode_reward_max': 0.6277777777777778,\n",
       "  'episode_reward_min': 0.12272727272727266,\n",
       "  'episode_reward_mean': 0.3908080808080808,\n",
       "  'episode_len_mean': 51.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 24,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [0.3954545454545454,\n",
       "    0.3954545454545454,\n",
       "    0.44999999999999996,\n",
       "    0.44999999999999996,\n",
       "    0.3954545454545454,\n",
       "    0.30454545454545456,\n",
       "    0.44999999999999996,\n",
       "    0.6277777777777778,\n",
       "    0.6,\n",
       "    0.44999999999999996,\n",
       "    0.30454545454545456,\n",
       "    0.35,\n",
       "    0.30454545454545456,\n",
       "    0.35,\n",
       "    0.35,\n",
       "    0.30454545454545456,\n",
       "    0.35,\n",
       "    0.30454545454545456,\n",
       "    0.44999999999999996,\n",
       "    0.1833333333333332,\n",
       "    0.6277777777777778,\n",
       "    0.12272727272727266,\n",
       "    0.3954545454545454,\n",
       "    0.5499999999999999,\n",
       "    0.5166666666666666,\n",
       "    0.35,\n",
       "    0.5166666666666666,\n",
       "    0.5499999999999999,\n",
       "    0.3954545454545454,\n",
       "    0.44999999999999996,\n",
       "    0.35,\n",
       "    0.2666666666666667,\n",
       "    0.24999999999999997,\n",
       "    0.3954545454545454,\n",
       "    0.48636363636363633,\n",
       "    0.5499999999999999,\n",
       "    0.5166666666666666,\n",
       "    0.2666666666666667,\n",
       "    0.35,\n",
       "    0.44999999999999996,\n",
       "    0.2136363636363636,\n",
       "    0.44999999999999996,\n",
       "    0.5166666666666666,\n",
       "    0.48636363636363633,\n",
       "    0.5166666666666666,\n",
       "    0.5166666666666666,\n",
       "    0.48636363636363633,\n",
       "    0.3954545454545454,\n",
       "    0.44999999999999996,\n",
       "    0.3954545454545454,\n",
       "    0.3954545454545454,\n",
       "    0.5499999999999999,\n",
       "    0.35,\n",
       "    0.35,\n",
       "    0.30454545454545456,\n",
       "    0.3954545454545454,\n",
       "    0.30454545454545456,\n",
       "    0.44999999999999996,\n",
       "    0.2666666666666667,\n",
       "    0.2666666666666667,\n",
       "    0.2666666666666667,\n",
       "    0.3954545454545454,\n",
       "    0.24999999999999997,\n",
       "    0.35,\n",
       "    0.30454545454545456,\n",
       "    0.1833333333333332,\n",
       "    0.40555555555555556,\n",
       "    0.2666666666666667,\n",
       "    0.2666666666666667,\n",
       "    0.30454545454545456,\n",
       "    0.3954545454545454,\n",
       "    0.3954545454545454,\n",
       "    0.3954545454545454,\n",
       "    0.5166666666666666,\n",
       "    0.3954545454545454,\n",
       "    0.24999999999999997,\n",
       "    0.30454545454545456,\n",
       "    0.5166666666666666,\n",
       "    0.35,\n",
       "    0.44999999999999996,\n",
       "    0.44999999999999996,\n",
       "    0.44999999999999996,\n",
       "    0.2666666666666667,\n",
       "    0.35,\n",
       "    0.30454545454545456,\n",
       "    0.6277777777777778,\n",
       "    0.35,\n",
       "    0.2666666666666667,\n",
       "    0.30454545454545456,\n",
       "    0.44999999999999996,\n",
       "    0.35,\n",
       "    0.5499999999999999,\n",
       "    0.30454545454545456,\n",
       "    0.44999999999999996,\n",
       "    0.44999999999999996,\n",
       "    0.5499999999999999,\n",
       "    0.35,\n",
       "    0.35,\n",
       "    0.40555555555555556,\n",
       "    0.35],\n",
       "   'episode_lengths': [51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51,\n",
       "    51]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.29559095734252794,\n",
       "   'mean_inference_ms': 15.212757694154575,\n",
       "   'mean_action_processing_ms': 0.1710952861799759,\n",
       "   'mean_env_wait_ms': 2.863935045137165,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 4,\n",
       "  'timesteps_total': 545696,\n",
       "  'timesteps_this_iter': 0,\n",
       "  'agent_timesteps_total': 545696,\n",
       "  'timers': {'sample_time_ms': 11674.321,\n",
       "   'sample_throughput': 98.678,\n",
       "   'load_time_ms': 0.949,\n",
       "   'load_throughput': 1214220.376,\n",
       "   'learn_time_ms': 6081.905,\n",
       "   'learn_throughput': 189.414,\n",
       "   'update_time_ms': 2.132},\n",
       "  'info': {'learner': {'default_policy': {'learner_stats': {'cur_kl_coeff': 1.2899450879999999,\n",
       "      'cur_lr': 1e-05,\n",
       "      'total_loss': 0.0028112514986181245,\n",
       "      'policy_loss': -0.017196579008343958,\n",
       "      'vf_loss': 0.005571838875073895,\n",
       "      'vf_explained_var': 0.1131897284871056,\n",
       "      'kl': 0.01184190554687077,\n",
       "      'entropy': 13.627630307560874,\n",
       "      'entropy_coeff': 0.0}}},\n",
       "   'num_steps_sampled': 545696,\n",
       "   'num_agent_steps_sampled': 545696,\n",
       "   'num_steps_trained': 545696,\n",
       "   'num_agent_steps_trained': 545696,\n",
       "   'num_steps_trained_this_iter': 0},\n",
       "  'done': True,\n",
       "  'episodes_total': 10635,\n",
       "  'training_iteration': 500,\n",
       "  'trial_id': 'be5d5_00001',\n",
       "  'experiment_id': 'd35c5f6902ad458ab484dcc74c45a8ad',\n",
       "  'date': '2022-03-10_14-58-50',\n",
       "  'timestamp': 1646924330,\n",
       "  'time_this_iter_s': 12.396902084350586,\n",
       "  'time_total_s': 5351.209007740021,\n",
       "  'pid': 1357446,\n",
       "  'hostname': 'pgcotovio-B450-AORUS-ELITE',\n",
       "  'node_ip': '10.20.0.204',\n",
       "  'config': {'num_workers': 4,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 144,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'gamma': 0.99,\n",
       "   'lr': 1e-05,\n",
       "   'train_batch_size': 577,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    '_disable_preprocessor_api': True,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': False,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'framestack': True,\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': 'general_model_torch',\n",
       "    'custom_model_config': {'fcnet_feats': [256, 256]},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1},\n",
       "   'optimizer': {},\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'BiclusterEnv-v0',\n",
       "   'observation_space': None,\n",
       "   'action_space': None,\n",
       "   'env_config': {'shape': [[6, 6], [6, 6]],\n",
       "    'n': 1,\n",
       "    'clusters': [1, 1],\n",
       "    'dataset_settings': {'dstype': {'value': 'Symbolic'},\n",
       "     'patterns': {'value': [['CONSTANT', 'CONSTANT']]},\n",
       "     'symbols': {'value': [-1, 1]},\n",
       "     'bktype': {'value': 'UNIFORM'},\n",
       "     'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]},\n",
       "     'contiguity': {'value': None},\n",
       "     'plaidcoherency': {'value': 'NO_OVERLAPPING'}},\n",
       "    'max_steps': 50,\n",
       "    'reward_shaping': 0.1,\n",
       "    'seed': 175},\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'clip_rewards': False,\n",
       "   'normalize_actions': True,\n",
       "   'clip_actions': False,\n",
       "   'preprocessor_pref': None,\n",
       "   'log_level': 'DEBUG',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'torch',\n",
       "   'eager_tracing': False,\n",
       "   'eager_max_retraces': 20,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'StochasticSampling'},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 10,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'min_iter_time_s': 0,\n",
       "   'timesteps_per_iteration': 0,\n",
       "   'seed': 175,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0.0001,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0.24975,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_config': {},\n",
       "   'actions_in_input_normalized': False,\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {'default_policy': PolicySpec(policy_class=<class 'ray.rllib.agents.ppo.ppo_torch_policy.PPOTorchPolicy'>, observation_space=None, action_space=None, config={})},\n",
       "    'policy_map_capacity': 100,\n",
       "    'policy_map_cache': None,\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   '_tf_policy_handles_more_than_one_loss': False,\n",
       "   '_disable_preprocessor_api': True,\n",
       "   'simple_optimizer': False,\n",
       "   'monitor': -1,\n",
       "   'use_critic': True,\n",
       "   'use_gae': True,\n",
       "   'lambda': 0.37748736000000005,\n",
       "   'kl_coeff': 0.382205952,\n",
       "   'sgd_minibatch_size': 70,\n",
       "   'shuffle_sequences': True,\n",
       "   'num_sgd_iter': 21,\n",
       "   'lr_schedule': None,\n",
       "   'vf_loss_coeff': 0.8493465600000002,\n",
       "   'entropy_coeff': 0.0,\n",
       "   'entropy_coeff_schedule': None,\n",
       "   'clip_param': 0.254803968,\n",
       "   'vf_clip_param': 3.7748736000000016,\n",
       "   'grad_clip': None,\n",
       "   'kl_target': 0.008493465599999998,\n",
       "   'vf_share_layers': -1},\n",
       "  'time_since_restore': 99.32835578918457,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 8,\n",
       "  'perf': {'cpu_util_percent': 24.84666666666666,\n",
       "   'ram_util_percent': 62.87999999999999,\n",
       "   'gpu_util_percent0': 0.09733333333333333,\n",
       "   'vram_util_percent0': 0.9246826171875,\n",
       "   'gpu_util_percent1': 0.3893333333333333,\n",
       "   'vram_util_percent1': 0.6618815104166667},\n",
       "  'experiment_tag': '1@perturbed[clip_param=0.2548,entropy_coeff=0.0,kl_coeff=0.38221,kl_target=0.0084935,lambda=0.37749,lr=1e-05,num_sgd_iter=21,sgd_minibatch_size=70,train_batch_size=577,vf_clip_param=3.7749,vf_loss_coeff=0.84935]'},\n",
       " 'df': Empty DataFrame\n",
       " Columns: []\n",
       " Index: []}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0310 15:46:37.915773861 1387312 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646927197.915734587\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646927197.915729898\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n"
     ]
    }
   ],
   "source": [
    "best_checkpoint = trainer.train(\n",
    "    num_samples=8, \n",
    "    scheduler=PPO_PBT,\n",
    "    stop_iters=500,\n",
    ")\n",
    "best_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate tune and get config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3908080808080808"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_checkpoint['metric']['episode_reward_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunned_v3_config = best_checkpoint['config']\n",
    "\n",
    "configs = TrainerConfig('tunned_v3_configs', '/home/pgcotovio/repos/nclustRL/Exp/test_framework2')\n",
    "configs.save(tunned_v3_config)\n",
    "\n",
    "tunned_v3_config == configs.obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_config_v3_hypertune/sample_0/PPO_2022-03-10_01-09-32/PPO_BiclusterEnv-v0_be5d5_00001_1_2022-03-10_01-09-32/checkpoint_000500/checkpoint-500'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_checkpoint['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 17:03:03,883\tINFO trainable.py:467 -- Restored on 10.20.0.204 from checkpoint: /home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_config_v3_hypertune/sample_0/PPO_2022-03-10_01-09-32/PPO_BiclusterEnv-v0_be5d5_00001_1_2022-03-10_01-09-32/checkpoint_000500/checkpoint-500\n",
      "2022-03-10 17:03:03,884\tINFO trainable.py:475 -- Current state after restoring: {'_iteration': 500, '_timesteps_total': 0, '_time_total': 5351.209007740021, '_episodes_total': 10635}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 of 10 done.\n",
      "Episode 2 of 10 done.\n",
      "Episode 3 of 10 done.\n",
      "Episode 4 of 10 done.\n",
      "Episode 5 of 10 done.\n",
      "Episode 6 of 10 done.\n",
      "Episode 7 of 10 done.\n",
      "Episode 8 of 10 done.\n",
      "Episode 9 of 10 done.\n",
      "Episode 10 of 10 done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.007142857142857212, 0.14285714285714285, 0.35760759099939604)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load and test\n",
    "trainer.load('/home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_config_v3_hypertune/sample_0/PPO_2022-03-10_01-09-32/PPO_BiclusterEnv-v0_be5d5_00001_1_2022-03-10_01-09-32/checkpoint_000500/checkpoint-500')\n",
    "\n",
    "trainer.test(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train basic_v3 (tunned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inicialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 23:04:54,613\tWARNING ppo.py:143 -- `train_batch_size` (577) cannot be achieved with your other settings (num_workers=4 num_envs_per_worker=1 rollout_fragment_length=256)! Auto-adjusting `rollout_fragment_length` to 144.\n",
      "2022-03-10 23:04:54,614\tINFO ppo.py:166 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744048)\u001b[0m 2022-03-10 23:04:58,788\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744046)\u001b[0m 2022-03-10 23:04:58,879\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744051)\u001b[0m 2022-03-10 23:04:59,049\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744045)\u001b[0m 2022-03-10 23:04:59,065\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744048)\u001b[0m 2022-03-10 23:05:03,307\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744048)\u001b[0m 2022-03-10 23:05:03,307\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744048)\u001b[0m 2022-03-10 23:05:03,483\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744048)\u001b[0m 2022-03-10 23:05:03,488\tINFO torch_policy.py:186 -- TorchPolicy (worker=1) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744048)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744048)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744046)\u001b[0m 2022-03-10 23:05:03,491\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744046)\u001b[0m 2022-03-10 23:05:03,492\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744046)\u001b[0m 2022-03-10 23:05:03,677\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744046)\u001b[0m 2022-03-10 23:05:03,680\tINFO torch_policy.py:186 -- TorchPolicy (worker=3) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744046)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744046)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744051)\u001b[0m 2022-03-10 23:05:03,731\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744051)\u001b[0m 2022-03-10 23:05:03,731\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744045)\u001b[0m 2022-03-10 23:05:03,792\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744045)\u001b[0m 2022-03-10 23:05:03,792\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744051)\u001b[0m 2022-03-10 23:05:03,911\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744051)\u001b[0m 2022-03-10 23:05:03,915\tINFO torch_policy.py:186 -- TorchPolicy (worker=2) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744051)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744051)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744045)\u001b[0m 2022-03-10 23:05:03,964\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744045)\u001b[0m 2022-03-10 23:05:03,968\tINFO torch_policy.py:186 -- TorchPolicy (worker=4) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744045)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744045)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "2022-03-10 23:05:04,497\tINFO worker_set.py:104 -- Inferred observation/action spaces from remote worker (local worker has no env): {'default_policy': (Dict(action_mask:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), avail_actions:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), state:Box([6 6], [6 6], (2,), int32)), Tuple(Discrete(4), Tuple(Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32)))), '__env__': (Dict(action_mask:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), avail_actions:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), state:Box([6 6], [6 6], (2,), int32)), Tuple(Discrete(4), Tuple(Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32))))}\n",
      "2022-03-10 23:05:04,499\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "2022-03-10 23:05:04,504\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "2022-03-10 23:05:04,526\tINFO torch_policy.py:186 -- TorchPolicy (worker=local) running on 0.0001 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744048)\u001b[0m 2022-03-10 23:05:04,490\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7ef6451aa550> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744046)\u001b[0m 2022-03-10 23:05:04,645\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f8a6922a550> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744051)\u001b[0m 2022-03-10 23:05:04,869\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7fb819505220> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1744045)\u001b[0m 2022-03-10 23:05:04,957\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f3878400880> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "/home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "  warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "2022-03-10 23:05:08,516\tINFO rollout_worker.py:1555 -- Built policy map: {}\n",
      "2022-03-10 23:05:08,517\tINFO rollout_worker.py:1556 -- Built preprocessor map: {'default_policy': None}\n",
      "2022-03-10 23:05:08,517\tINFO rollout_worker.py:618 -- Built filter map: {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x7ff504e55b20>}\n",
      "2022-03-10 23:05:08,517\tDEBUG rollout_worker.py:728 -- Created rollout worker with env None (None), policies {}\n",
      "2022-03-10 23:05:08,520\tINFO trainable.py:124 -- Trainable.setup took 13.908 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "E0310 23:05:08.564405150 1744584 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646953508.564341580\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646953508.564334025\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n"
     ]
    }
   ],
   "source": [
    "configs = TrainerConfig('tunned_v3_configs', '/home/pgcotovio/repos/nclustRL/Exp/test_framework2')\n",
    "tunned_v3_config = configs.obj\n",
    "\n",
    "trainer_basic_v3_tunned = Trainer(\n",
    "    trainer=PPOTrainer,\n",
    "    env='BiclusterEnv-v0',\n",
    "    save_dir='/home/pgcotovio/repos/nclustRL/Exp/test_framework2',\n",
    "    name='basic_v3_tunned_config',\n",
    "    config=tunned_v3_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test random agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 of 10 done.\n",
      "Episode 2 of 10 done.\n",
      "Episode 3 of 10 done.\n",
      "Episode 4 of 10 done.\n",
      "Episode 5 of 10 done.\n",
      "Episode 6 of 10 done.\n",
      "Episode 7 of 10 done.\n",
      "Episode 8 of 10 done.\n",
      "Episode 9 of 10 done.\n",
      "Episode 10 of 10 done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.1071428571428572, 0.0714285714285714, 0.3455851513004745)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_basic_v3_tunned.test(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-10 20:39:36 (running for 03:23:44.80)<br>Memory usage on this node: 39.3/62.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/2 GPUs, 0.0/33.82 GiB heap, 0.0/16.91 GiB objects<br>Current best trial: bcdd2_00000 with episode_reward_mean=0.3676515151515152 and parameters={'num_workers': 4, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 144, 'batch_mode': 'truncate_episodes', 'gamma': 0.99, 'lr': 1e-05, 'train_batch_size': 577, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': True, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'general_model_torch', 'custom_model_config': {'fcnet_feats': [256, 256]}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'BiclusterEnv-v0', 'observation_space': None, 'action_space': None, 'env_config': {'shape': [[6, 6], [6, 6]], 'n': 1, 'clusters': [1, 1], 'dataset_settings': {'dstype': {'value': 'Symbolic'}, 'patterns': {'value': [['CONSTANT', 'CONSTANT']]}, 'symbols': {'value': [-1, 1]}, 'bktype': {'value': 'UNIFORM'}, 'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]}, 'contiguity': {'value': None}, 'plaidcoherency': {'value': 'NO_OVERLAPPING'}}, 'max_steps': 50, 'reward_shaping': 0.1, 'seed': 175}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': False, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': None, 'log_level': 'DEBUG', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': 175, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0.0001, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.24975, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'default_policy': PolicySpec(policy_class=<class 'ray.rllib.agents.ppo.ppo_torch_policy.PPOTorchPolicy'>, observation_space=None, action_space=None, config={})}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': True, 'simple_optimizer': False, 'monitor': -1, 'use_critic': True, 'use_gae': True, 'lambda': 0.37748736000000005, 'kl_coeff': 0.382205952, 'sgd_minibatch_size': 70, 'shuffle_sequences': True, 'num_sgd_iter': 21, 'lr_schedule': None, 'vf_loss_coeff': 0.8493465600000002, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.254803968, 'vf_clip_param': 3.7748736000000016, 'grad_clip': None, 'kl_target': 0.008493465599999998, 'vf_share_layers': -1}<br>Result logdir: /home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_v3_tunned_config/sample_0/PPO_2022-03-10_17-15-52<br>Number of trials: 1/1 (1 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 20:39:37,271\tINFO tune.py:626 -- Total run time: 12225.19 seconds (12224.74 seconds for the tuning loop).\n",
      "Sample 1: : 1sample [3:23:45, 12225.23s/sample, metric={'episode_reward_max': 0.6277777777777778, 'episode_reward_min': 0.09999999999999995, 'episode_reward_mean': 0.3676515151515152, 'episode_len_mean': 51.0, 'episode_media': {}, 'episodes_this_iter': 22, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.2666666666666667, 0.3954545454545454, 0.3954545454545454, 0.48636363636363633, 0.30454545454545456, 0.3954545454545454, 0.3954545454545454, 0.2666666666666667, 0.30454545454545456, 0.3954545454545454, 0.3954545454545454, 0.3954545454545454, 0.2136363636363636, 0.48636363636363633, 0.09999999999999995, 0.30454545454545456, 0.2666666666666667, 0.40555555555555556, 0.3954545454545454, 0.1833333333333332, 0.30454545454545456, 0.44999999999999996, 0.2666666666666667, 0.44999999999999996, 0.09999999999999995, 0.30454545454545456, 0.35, 0.2666666666666667, 0.3954545454545454, 0.44999999999999996, 0.3954545454545454, 0.40555555555555556, 0.1833333333333332, 0.35, 0.35, 0.48636363636363633, 0.5499999999999999, 0.3954545454545454, 0.40555555555555556, 0.48636363636363633, 0.6, 0.2136363636363636, 0.2136363636363636, 0.30454545454545456, 0.3954545454545454, 0.24999999999999997, 0.2666666666666667, 0.48636363636363633, 0.24999999999999997, 0.2666666666666667, 0.35, 0.35, 0.6277777777777778, 0.3954545454545454, 0.3954545454545454, 0.30454545454545456, 0.44999999999999996, 0.44999999999999996, 0.2666666666666667, 0.3954545454545454, 0.3954545454545454, 0.3954545454545454, 0.6277777777777778, 0.3954545454545454, 0.2944444444444444, 0.3954545454545454, 0.44999999999999996, 0.30454545454545456, 0.2666666666666667, 0.5499999999999999, 0.30454545454545456, 0.5499999999999999, 0.44999999999999996, 0.3954545454545454, 0.48636363636363633, 0.44999999999999996, 0.3954545454545454, 0.35, 0.2666666666666667, 0.3954545454545454, 0.30454545454545456, 0.2666666666666667, 0.24999999999999997, 0.3954545454545454, 0.30454545454545456, 0.3954545454545454, 0.44999999999999996, 0.48636363636363633, 0.35, 0.2666666666666667, 0.3954545454545454, 0.5166666666666666, 0.35, 0.30454545454545456, 0.1833333333333332, 0.44999999999999996, 0.35, 0.3954545454545454, 0.5499999999999999, 0.35], 'episode_lengths': [51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.24714111126852675, 'mean_inference_ms': 15.369484463207971, 'mean_action_processing_ms': 0.17072697593410496, 'mean_env_wait_ms': 2.923585207125113, 'mean_env_render_ms': 0.0}, 'off_policy_estimator': {}, 'num_healthy_workers': 4, 'timesteps_total': 1152000, 'timesteps_this_iter': 0, 'agent_timesteps_total': 1152000, 'timers': {'sample_time_ms': 12104.917, 'sample_throughput': 95.168, 'load_time_ms': 0.841, 'load_throughput': 1370384.358, 'learn_time_ms': 5373.605, 'learn_throughput': 214.381, 'update_time_ms': 1.991}, 'info': {'learner': {'default_policy': {'learner_stats': {'cur_kl_coeff': 0.967458816, 'cur_lr': 1e-05, 'total_loss': -0.012711999261834231, 'policy_loss': -0.029290717239962846, 'vf_loss': 0.005340690015665521, 'vf_explained_var': 0.3909284763392948, 'kl': 0.012447683296895343, 'entropy': 6.191021774496351, 'entropy_coeff': 0.0}}}, 'num_steps_sampled': 1152000, 'num_agent_steps_sampled': 1152000, 'num_steps_trained': 1152000, 'num_agent_steps_trained': 1152000, 'num_steps_trained_this_iter': 0}, 'done': True, 'episodes_total': 22611, 'training_iteration': 1000, 'trial_id': 'bcdd2_00000', 'experiment_id': '6cdd0c7213fa49aab68699e80f0a73cb', 'date': '2022-03-10_20-39-36', 'timestamp': 1646944776, 'time_this_iter_s': 12.120639562606812, 'time_total_s': 12189.423601388931, 'pid': 1433597, 'hostname': 'pgcotovio-B450-AORUS-ELITE', 'node_ip': '10.20.0.204', 'config': {'num_workers': 4, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 144, 'batch_mode': 'truncate_episodes', 'gamma': 0.99, 'lr': 1e-05, 'train_batch_size': 577, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': True, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'general_model_torch', 'custom_model_config': {'fcnet_feats': [256, 256]}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'BiclusterEnv-v0', 'observation_space': None, 'action_space': None, 'env_config': {'shape': [[6, 6], [6, 6]], 'n': 1, 'clusters': [1, 1], 'dataset_settings': {'dstype': {'value': 'Symbolic'}, 'patterns': {'value': [['CONSTANT', 'CONSTANT']]}, 'symbols': {'value': [-1, 1]}, 'bktype': {'value': 'UNIFORM'}, 'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]}, 'contiguity': {'value': None}, 'plaidcoherency': {'value': 'NO_OVERLAPPING'}}, 'max_steps': 50, 'reward_shaping': 0.1, 'seed': 175}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': False, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': None, 'log_level': 'DEBUG', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': 175, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0.0001, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.24975, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'default_policy': PolicySpec(policy_class=<class 'ray.rllib.agents.ppo.ppo_torch_policy.PPOTorchPolicy'>, observation_space=None, action_space=None, config={})}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': True, 'simple_optimizer': False, 'monitor': -1, 'use_critic': True, 'use_gae': True, 'lambda': 0.37748736000000005, 'kl_coeff': 0.382205952, 'sgd_minibatch_size': 70, 'shuffle_sequences': True, 'num_sgd_iter': 21, 'lr_schedule': None, 'vf_loss_coeff': 0.8493465600000002, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.254803968, 'vf_clip_param': 3.7748736000000016, 'grad_clip': None, 'kl_target': 0.008493465599999998, 'vf_share_layers': -1}, 'time_since_restore': 12189.423601388931, 'timesteps_since_restore': 0, 'iterations_since_restore': 1000, 'perf': {'cpu_util_percent': 24.2875, 'ram_util_percent': 62.55625, 'gpu_util_percent0': 0.096875, 'vram_util_percent0': 0.9246826171875, 'gpu_util_percent1': 0.454375, 'vram_util_percent1': 0.6617050170898438}, 'experiment_tag': '0'}]\n",
      "E0310 20:45:21.619266584 1664928 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646945121.619218904\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646945121.619214535\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0310 20:49:31.636212569 1667265 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646945371.636177873\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646945371.636174807\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0310 20:53:16.661235509 1669355 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646945596.661191235\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646945596.661186556\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0310 20:55:46.665272193 1670734 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646945746.665227999\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646945746.665223902\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0310 21:40:11.948301320 1695528 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646948411.948254772\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646948411.948250153\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0310 21:44:16.995251997 1697793 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646948656.995206070\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646948656.995201812\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0310 22:27:52.350778412 1723026 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646951272.350730632\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646951272.350725793\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0310 22:41:57.473238742 1730964 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646952117.473193827\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646952117.473189418\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n"
     ]
    }
   ],
   "source": [
    "best_checkpoint = trainer_basic_v3_tunned.train(stop_iters=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test trained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_reward_max</th>\n",
       "      <th>episode_reward_min</th>\n",
       "      <th>episode_reward_mean</th>\n",
       "      <th>episode_len_mean</th>\n",
       "      <th>episodes_this_iter</th>\n",
       "      <th>num_healthy_workers</th>\n",
       "      <th>timesteps_total</th>\n",
       "      <th>timesteps_this_iter</th>\n",
       "      <th>agent_timesteps_total</th>\n",
       "      <th>done</th>\n",
       "      <th>...</th>\n",
       "      <th>config/shuffle_sequences</th>\n",
       "      <th>config/soft_horizon</th>\n",
       "      <th>config/synchronize_filters</th>\n",
       "      <th>config/timesteps_per_iteration</th>\n",
       "      <th>config/train_batch_size</th>\n",
       "      <th>config/use_critic</th>\n",
       "      <th>config/use_gae</th>\n",
       "      <th>config/vf_clip_param</th>\n",
       "      <th>config/vf_loss_coeff</th>\n",
       "      <th>logdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.183</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.407151</td>\n",
       "      <td>50.47</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>1032192</td>\n",
       "      <td>0</td>\n",
       "      <td>1032192</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>577</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.774874</td>\n",
       "      <td>0.849347</td>\n",
       "      <td>/home/pgcotovio/repos/nclustRL/Exp/test_framew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode_reward_max  episode_reward_min  episode_reward_mean  \\\n",
       "0               1.183                 0.1             0.407151   \n",
       "\n",
       "   episode_len_mean  episodes_this_iter  num_healthy_workers  timesteps_total  \\\n",
       "0             50.47                  23                    4          1032192   \n",
       "\n",
       "   timesteps_this_iter  agent_timesteps_total   done  ...  \\\n",
       "0                    0                1032192  False  ...   \n",
       "\n",
       "   config/shuffle_sequences  config/soft_horizon config/synchronize_filters  \\\n",
       "0                      True                False                       True   \n",
       "\n",
       "  config/timesteps_per_iteration config/train_batch_size  config/use_critic  \\\n",
       "0                              0                     577               True   \n",
       "\n",
       "   config/use_gae  config/vf_clip_param  config/vf_loss_coeff  \\\n",
       "0            True              3.774874              0.849347   \n",
       "\n",
       "                                              logdir  \n",
       "0  /home/pgcotovio/repos/nclustRL/Exp/test_framew...  \n",
       "\n",
       "[1 rows x 130 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_checkpoint['df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_v3_tunned_config/sample_0/PPO_2022-03-10_17-15-52/PPO_BiclusterEnv-v0_bcdd2_00000_0_2022-03-10_17-15-52/checkpoint_000980/checkpoint-980'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_checkpoint['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 23:05:29,494\tINFO trainable.py:467 -- Restored on 10.20.0.204 from checkpoint: /home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_v3_tunned_config/sample_0/PPO_2022-03-10_17-15-52/PPO_BiclusterEnv-v0_bcdd2_00000_0_2022-03-10_17-15-52/checkpoint_000980/checkpoint-980\n",
      "2022-03-10 23:05:29,495\tINFO trainable.py:475 -- Current state after restoring: {'_iteration': 980, '_timesteps_total': 0, '_time_total': 11948.106652021408, '_episodes_total': 22159}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 of 10 done.\n",
      "Episode 2 of 10 done.\n",
      "Episode 3 of 10 done.\n",
      "Episode 4 of 10 done.\n",
      "Episode 5 of 10 done.\n",
      "Episode 6 of 10 done.\n",
      "Episode 7 of 10 done.\n",
      "Episode 8 of 10 done.\n",
      "Episode 9 of 10 done.\n",
      "Episode 10 of 10 done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.035714285714285816, 0.11428571428571424, 0.3286868808005238)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load and test\n",
    "trainer_basic_v3_tunned.load('/home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_v3_tunned_config/sample_0/PPO_2022-03-10_17-15-52/PPO_BiclusterEnv-v0_bcdd2_00000_0_2022-03-10_17-15-52/checkpoint_000980/checkpoint-980')\n",
    "\n",
    "trainer_basic_v3_tunned.test(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# v3 Search Max_Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inicialize trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 01:05:45,072\tWARNING ppo.py:143 -- `train_batch_size` (577) cannot be achieved with your other settings (num_workers=4 num_envs_per_worker=1 rollout_fragment_length=256)! Auto-adjusting `rollout_fragment_length` to 144.\n",
      "2022-03-11 01:05:45,073\tINFO ppo.py:166 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813369)\u001b[0m 2022-03-11 01:05:49,396\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813372)\u001b[0m 2022-03-11 01:05:49,462\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813364)\u001b[0m 2022-03-11 01:05:49,519\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813367)\u001b[0m 2022-03-11 01:05:49,761\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813369)\u001b[0m 2022-03-11 01:05:54,054\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813369)\u001b[0m 2022-03-11 01:05:54,055\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813372)\u001b[0m 2022-03-11 01:05:54,062\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813372)\u001b[0m 2022-03-11 01:05:54,062\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813364)\u001b[0m 2022-03-11 01:05:54,141\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813364)\u001b[0m 2022-03-11 01:05:54,142\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813367)\u001b[0m 2022-03-11 01:05:54,256\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813367)\u001b[0m 2022-03-11 01:05:54,257\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813369)\u001b[0m 2022-03-11 01:05:54,230\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813369)\u001b[0m 2022-03-11 01:05:54,233\tINFO torch_policy.py:186 -- TorchPolicy (worker=4) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813369)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813369)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813372)\u001b[0m 2022-03-11 01:05:54,248\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813372)\u001b[0m 2022-03-11 01:05:54,251\tINFO torch_policy.py:186 -- TorchPolicy (worker=3) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813372)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813372)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813364)\u001b[0m 2022-03-11 01:05:54,329\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813364)\u001b[0m 2022-03-11 01:05:54,332\tINFO torch_policy.py:186 -- TorchPolicy (worker=2) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813364)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813364)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813367)\u001b[0m 2022-03-11 01:05:54,429\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813367)\u001b[0m 2022-03-11 01:05:54,433\tINFO torch_policy.py:186 -- TorchPolicy (worker=1) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813367)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813367)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813369)\u001b[0m 2022-03-11 01:05:55,216\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f653cceaa00> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813372)\u001b[0m 2022-03-11 01:05:55,255\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7fc58da6f970> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813364)\u001b[0m 2022-03-11 01:05:55,285\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f3055505970> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "2022-03-11 01:05:55,374\tINFO worker_set.py:104 -- Inferred observation/action spaces from remote worker (local worker has no env): {'default_policy': (Dict(action_mask:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), avail_actions:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), state:Box([6 6], [6 6], (2,), int32)), Tuple(Discrete(4), Tuple(Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32)))), '__env__': (Dict(action_mask:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), avail_actions:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), state:Box([6 6], [6 6], (2,), int32)), Tuple(Discrete(4), Tuple(Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32))))}\n",
      "2022-03-11 01:05:55,376\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "2022-03-11 01:05:55,379\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "2022-03-11 01:05:55,402\tINFO torch_policy.py:186 -- TorchPolicy (worker=local) running on 0.0001 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1813367)\u001b[0m 2022-03-11 01:05:55,365\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f74d18128e0> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "/home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "  warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "2022-03-11 01:05:59,425\tINFO rollout_worker.py:1555 -- Built policy map: {}\n",
      "2022-03-11 01:05:59,425\tINFO rollout_worker.py:1556 -- Built preprocessor map: {'default_policy': None}\n",
      "2022-03-11 01:05:59,426\tINFO rollout_worker.py:618 -- Built filter map: {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x7f14cf946490>}\n",
      "2022-03-11 01:05:59,426\tDEBUG rollout_worker.py:728 -- Created rollout worker with env None (None), policies {}\n",
      "2022-03-11 01:05:59,430\tINFO trainable.py:124 -- Trainable.setup took 14.359 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    }
   ],
   "source": [
    "configs = TrainerConfig('tunned_v3_configs', '/home/pgcotovio/repos/nclustRL/Exp/test_framework2')\n",
    "tunned_v3_config = configs.obj\n",
    "\n",
    "tunned_v3_config['env_config']['max_steps'] = uniform(50, 1000)\n",
    "\n",
    "trainer_basic_v3_tunned = Trainer(\n",
    "    trainer=PPOTrainer,\n",
    "    env='BiclusterEnv-v0',\n",
    "    save_dir='/home/pgcotovio/repos/nclustRL/Exp/test_framework2',\n",
    "    name='basic_config_v3_tunned_maxsteps_hypertune',\n",
    "    config=tunned_v3_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-11 14:44:23 (running for 13:38:21.47)<br>Memory usage on this node: 39.6/62.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/2 GPUs, 0.0/33.64 GiB heap, 0.0/16.82 GiB objects<br>Current best trial: 4a7daf16 with episode_reward_mean=0.3499696969696969 and parameters={'num_workers': 4, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 144, 'batch_mode': 'truncate_episodes', 'gamma': 0.99, 'lr': 1e-05, 'train_batch_size': 577, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': True, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'general_model_torch', 'custom_model_config': {'fcnet_feats': [256, 256]}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'BiclusterEnv-v0', 'observation_space': None, 'action_space': None, 'env_config': {'shape': [[6, 6], [6, 6]], 'n': 1, 'clusters': [1, 1], 'dataset_settings': {'dstype': {'value': 'Symbolic'}, 'patterns': {'value': [['CONSTANT', 'CONSTANT']]}, 'symbols': {'value': [-1, 1]}, 'bktype': {'value': 'UNIFORM'}, 'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]}, 'contiguity': {'value': None}, 'plaidcoherency': {'value': 'NO_OVERLAPPING'}}, 'max_steps': 105.17943155978949, 'reward_shaping': 0.1, 'seed': 175}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': False, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': None, 'log_level': 'DEBUG', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': 175, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0.0001, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.24975, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'default_policy': PolicySpec(policy_class=<class 'ray.rllib.agents.ppo.ppo_torch_policy.PPOTorchPolicy'>, observation_space=None, action_space=None, config={})}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': True, 'simple_optimizer': False, 'monitor': -1, 'use_critic': True, 'use_gae': True, 'lambda': 0.37748736000000005, 'kl_coeff': 0.382205952, 'sgd_minibatch_size': 70, 'shuffle_sequences': True, 'num_sgd_iter': 21, 'lr_schedule': None, 'vf_loss_coeff': 0.8493465600000002, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.254803968, 'vf_clip_param': 3.7748736000000016, 'grad_clip': None, 'kl_target': 0.008493465599999998, 'vf_share_layers': -1}<br>Result logdir: /home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_config_v3_tunned_maxsteps_hypertune/sample_0/PPO_2022-03-11_01-06-01<br>Number of trials: 8/8 (8 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 14:44:23,655\tINFO tune.py:626 -- Total run time: 49101.90 seconds (49101.42 seconds for the tuning loop).\n",
      "Sample 1: : 1sample [13:38:23, 49103.15s/sample, metric={'episode_reward_max': 0.4949999999999999, 'episode_reward_min': 0.12833333333333316, 'episode_reward_mean': 0.3499696969696969, 'episode_len_mean': 106.0, 'episode_media': {}, 'episodes_this_iter': 12, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.4313636363636363, 0.4313636363636363, 0.29499999999999993, 0.29499999999999993, 0.4313636363636363, 0.4313636363636363, 0.34045454545454534, 0.29499999999999993, 0.3783333333333333, 0.4313636363636363, 0.12833333333333316, 0.29499999999999993, 0.4313636363636363, 0.4313636363636363, 0.34045454545454534, 0.29499999999999993, 0.34045454545454534, 0.3949999999999999, 0.29499999999999993, 0.21166666666666664, 0.29499999999999993, 0.2495454545454545, 0.34045454545454534, 0.4313636363636363, 0.2495454545454545, 0.34045454545454534, 0.4313636363636363, 0.4949999999999999, 0.4313636363636363, 0.29499999999999993, 0.21166666666666664, 0.29499999999999993, 0.21166666666666664, 0.29499999999999993, 0.29499999999999993, 0.4313636363636363, 0.29499999999999993, 0.29499999999999993, 0.34045454545454534, 0.4313636363636363, 0.34045454545454534, 0.4313636363636363, 0.29499999999999993, 0.29499999999999993, 0.29499999999999993, 0.21166666666666664, 0.29499999999999993, 0.4313636363636363, 0.34045454545454534, 0.29499999999999993, 0.29499999999999993, 0.29499999999999993, 0.4313636363636363, 0.3783333333333333, 0.29499999999999993, 0.29499999999999993, 0.34045454545454534, 0.4313636363636363, 0.34045454545454534, 0.34045454545454534, 0.4313636363636363, 0.4313636363636363, 0.4313636363636363, 0.3783333333333333, 0.21166666666666664, 0.21166666666666664, 0.29499999999999993, 0.29499999999999993, 0.29499999999999993, 0.4313636363636363, 0.4313636363636363, 0.4313636363636363, 0.34045454545454534, 0.4313636363636363, 0.34045454545454534, 0.29499999999999993, 0.34045454545454534, 0.34045454545454534, 0.29499999999999993, 0.4313636363636363, 0.3783333333333333, 0.4313636363636363, 0.4313636363636363, 0.34045454545454534, 0.4949999999999999, 0.3783333333333333, 0.29499999999999993, 0.3783333333333333, 0.3783333333333333, 0.4313636363636363, 0.21166666666666664, 0.29499999999999993, 0.29499999999999993, 0.29499999999999993, 0.4949999999999999, 0.4313636363636363, 0.4313636363636363, 0.4313636363636363, 0.3949999999999999, 0.4313636363636363], 'episode_lengths': [106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.19745319642734505, 'mean_inference_ms': 15.530381929603143, 'mean_action_processing_ms': 0.16902741440772243, 'mean_env_wait_ms': 2.9111113826664963, 'mean_env_render_ms': 0.0}, 'off_policy_estimator': {}, 'num_healthy_workers': 4, 'timesteps_total': 576000, 'timesteps_this_iter': 0, 'agent_timesteps_total': 576000, 'timers': {'sample_time_ms': 12009.818, 'sample_throughput': 95.922, 'load_time_ms': 0.841, 'load_throughput': 1369762.78, 'learn_time_ms': 5300.668, 'learn_throughput': 217.331, 'update_time_ms': 2.038}, 'info': {'learner': {'default_policy': {'learner_stats': {'cur_kl_coeff': 1.4511882239999998, 'cur_lr': 1e-05, 'total_loss': -0.01017952257132579, 'policy_loss': -0.020544522897623773, 'vf_loss': 0.0024294918870769572, 'vf_explained_var': 0.18092642955127217, 'kl': 0.005720498541796544, 'entropy': 13.17307926075799, 'entropy_coeff': 0.0}}}, 'num_steps_sampled': 576000, 'num_agent_steps_sampled': 576000, 'num_steps_trained': 576000, 'num_agent_steps_trained': 576000, 'num_steps_trained_this_iter': 0}, 'done': True, 'episodes_total': 5445, 'training_iteration': 500, 'trial_id': '4a7daf16', 'experiment_id': '6be95979652c4ebf88a341bccdfaa369', 'date': '2022-03-11_13-04-49', 'timestamp': 1647003889, 'time_this_iter_s': 11.783470869064331, 'time_total_s': 6062.324910402298, 'pid': 2504813, 'hostname': 'pgcotovio-B450-AORUS-ELITE', 'node_ip': '10.20.0.204', 'config': {'num_workers': 4, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 144, 'batch_mode': 'truncate_episodes', 'gamma': 0.99, 'lr': 1e-05, 'train_batch_size': 577, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': True, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'general_model_torch', 'custom_model_config': {'fcnet_feats': [256, 256]}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'BiclusterEnv-v0', 'observation_space': None, 'action_space': None, 'env_config': {'shape': [[6, 6], [6, 6]], 'n': 1, 'clusters': [1, 1], 'dataset_settings': {'dstype': {'value': 'Symbolic'}, 'patterns': {'value': [['CONSTANT', 'CONSTANT']]}, 'symbols': {'value': [-1, 1]}, 'bktype': {'value': 'UNIFORM'}, 'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]}, 'contiguity': {'value': None}, 'plaidcoherency': {'value': 'NO_OVERLAPPING'}}, 'max_steps': 105.17943155978949, 'reward_shaping': 0.1, 'seed': 175}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': False, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': None, 'log_level': 'DEBUG', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': 175, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0.0001, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.24975, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'default_policy': PolicySpec(policy_class=<class 'ray.rllib.agents.ppo.ppo_torch_policy.PPOTorchPolicy'>, observation_space=None, action_space=None, config={})}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': True, 'simple_optimizer': False, 'monitor': -1, 'use_critic': True, 'use_gae': True, 'lambda': 0.37748736000000005, 'kl_coeff': 0.382205952, 'sgd_minibatch_size': 70, 'shuffle_sequences': True, 'num_sgd_iter': 21, 'lr_schedule': None, 'vf_loss_coeff': 0.8493465600000002, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.254803968, 'vf_clip_param': 3.7748736000000016, 'grad_clip': None, 'kl_target': 0.008493465599999998, 'vf_share_layers': -1}, 'time_since_restore': 6062.324910402298, 'timesteps_since_restore': 0, 'iterations_since_restore': 500, 'perf': {'cpu_util_percent': 23.762500000000003, 'ram_util_percent': 63.2, 'gpu_util_percent0': 0.098125, 'vram_util_percent0': 0.9246826171875, 'gpu_util_percent1': 0.43625, 'vram_util_percent1': 0.66192626953125}, 'experiment_tag': \"7__disable_preprocessor_api=True,_fake_gpus=False,action_space=None,batch_mode=truncate_episodes,clip_param=0.2548,clip_rewards=False,collect_metrics_timeout=180,compress_observations=False,create_env_on_driver=False,custom_eval_function=None,eager_tracing=False,entropy_coeff=0.0,entropy_coeff_schedule=None,clusters=[1, 1],value=UNIFORM,value=[['UNIFORM', 4, 4], ['UNIFORM', 3, 3]],value=None,value=Symbolic,value=[['CONSTANT', 'CONSTANT']],value=NO_OVERLAPPING,value=[-1, 1],max_steps=105.18,n=1,reward_shaping=0.1,seed=175,shape=[[6, 6], [6, 6]],env_task_fn=None,explore=False,evaluation_interval=None,evaluation_num_episodes=10,evaluation_num_workers=0,evaluation_parallel_to_training=False,type=StochasticSampling,explore=True,framework=torch,gamma=0.99,grad_clip=None,horizon=None,ignore_worker_failures=False,in_evaluation=False,kl_coeff=0.38221,kl_target=0.0084935,lambda=0.37749,log_level=DEBUG,log_sys_usage=True,logger_config=None,lr=1e-05,lr_schedule=None,metrics_smoothing_episodes=100,min_iter_time_s=0,custom_action_dist=None,custom_model=general_model_torch,fcnet_feats=[256, 256],no_done_at_end=False,normalize_actions=True,num_cpus_for_driver=1,num_cpus_per_worker=1,num_envs_per_worker=1,num_gpus=0.0001,num_gpus_per_worker=0.24975,num_sgd_iter=21,num_workers=4,observation_filter=NoFilter,observation_space=None,placement_strategy=PACK,preprocessor_pref=None,record_env=False,render_env=False,rollout_fragment_length=256,sample_async=False,seed=175,sgd_minibatch_size=70,shuffle_sequences=True,soft_horizon=False,synchronize_filters=True,timesteps_per_iteration=0,train_batch_size=577,use_critic=True,use_gae=True,vf_clip_param=3.7749,vf_loss_coeff=0.84935\"}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'config': {'num_workers': 4,\n",
       "  'create_env_on_driver': False,\n",
       "  'num_envs_per_worker': 1,\n",
       "  'batch_mode': 'truncate_episodes',\n",
       "  'gamma': 0.99,\n",
       "  'use_critic': True,\n",
       "  'use_gae': True,\n",
       "  'lambda': 0.37748736000000005,\n",
       "  'kl_coeff': 0.382205952,\n",
       "  'rollout_fragment_length': 256,\n",
       "  'train_batch_size': 577,\n",
       "  'sgd_minibatch_size': 70,\n",
       "  'shuffle_sequences': True,\n",
       "  'num_sgd_iter': 21,\n",
       "  'lr': 1e-05,\n",
       "  'lr_schedule': None,\n",
       "  'vf_loss_coeff': 0.8493465600000002,\n",
       "  'entropy_coeff': 0.0,\n",
       "  'entropy_coeff_schedule': None,\n",
       "  'clip_param': 0.254803968,\n",
       "  'vf_clip_param': 3.7748736000000016,\n",
       "  'grad_clip': None,\n",
       "  'kl_target': 0.008493465599999998,\n",
       "  'optimizer': {},\n",
       "  'horizon': None,\n",
       "  'soft_horizon': False,\n",
       "  'no_done_at_end': False,\n",
       "  'env': 'BiclusterEnv-v0',\n",
       "  'observation_space': None,\n",
       "  'action_space': None,\n",
       "  'env_config': {'shape': [[6, 6], [6, 6]],\n",
       "   'n': 1,\n",
       "   'clusters': [1, 1],\n",
       "   'dataset_settings': {'dstype': {'value': 'Symbolic'},\n",
       "    'patterns': {'value': [['CONSTANT', 'CONSTANT']]},\n",
       "    'symbols': {'value': [-1, 1]},\n",
       "    'bktype': {'value': 'UNIFORM'},\n",
       "    'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]},\n",
       "    'contiguity': {'value': None},\n",
       "    'plaidcoherency': {'value': 'NO_OVERLAPPING'}},\n",
       "   'max_steps': 105.17943155978949,\n",
       "   'reward_shaping': 0.1,\n",
       "   'seed': 175},\n",
       "  'env_task_fn': None,\n",
       "  'render_env': False,\n",
       "  'record_env': False,\n",
       "  'clip_rewards': False,\n",
       "  'normalize_actions': True,\n",
       "  'preprocessor_pref': None,\n",
       "  'log_level': 'DEBUG',\n",
       "  'ignore_worker_failures': False,\n",
       "  'log_sys_usage': True,\n",
       "  'framework': 'torch',\n",
       "  'eager_tracing': False,\n",
       "  'explore': True,\n",
       "  'exploration_config': {'type': 'StochasticSampling'},\n",
       "  'evaluation_interval': None,\n",
       "  'evaluation_num_episodes': 10,\n",
       "  'evaluation_parallel_to_training': False,\n",
       "  'in_evaluation': False,\n",
       "  'evaluation_config': {'explore': False},\n",
       "  'evaluation_num_workers': 0,\n",
       "  'custom_eval_function': None,\n",
       "  'sample_async': False,\n",
       "  'observation_filter': 'NoFilter',\n",
       "  'synchronize_filters': True,\n",
       "  'compress_observations': False,\n",
       "  'collect_metrics_timeout': 180,\n",
       "  'metrics_smoothing_episodes': 100,\n",
       "  'min_iter_time_s': 0,\n",
       "  'timesteps_per_iteration': 0,\n",
       "  'seed': 175,\n",
       "  'extra_python_environs_for_driver': {},\n",
       "  'extra_python_environs_for_worker': {},\n",
       "  'num_gpus': 0.0001,\n",
       "  '_fake_gpus': False,\n",
       "  'num_cpus_per_worker': 1,\n",
       "  'num_gpus_per_worker': 0.24975,\n",
       "  'custom_resources_per_worker': {},\n",
       "  'num_cpus_for_driver': 1,\n",
       "  'placement_strategy': 'PACK',\n",
       "  'logger_config': None,\n",
       "  '_disable_preprocessor_api': True,\n",
       "  'model': {'custom_model': 'general_model_torch',\n",
       "   'custom_model_config': {'fcnet_feats': [256, 256]},\n",
       "   'custom_action_dist': None}},\n",
       " 'path': '/home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_config_v3_tunned_maxsteps_hypertune/sample_0/PPO_2022-03-11_01-06-01/PPO_BiclusterEnv-v0_4a7daf16_7__disable_preprocessor_api=True,_fake_gpus=False,action_space=None,batch_mode=truncate_episodes,clip_2022-03-11_09-40-30/checkpoint_000480/checkpoint-480',\n",
       " 'metric': {'episode_reward_max': 0.4949999999999999,\n",
       "  'episode_reward_min': 0.12833333333333316,\n",
       "  'episode_reward_mean': 0.3499696969696969,\n",
       "  'episode_len_mean': 106.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 12,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [0.4313636363636363,\n",
       "    0.4313636363636363,\n",
       "    0.29499999999999993,\n",
       "    0.29499999999999993,\n",
       "    0.4313636363636363,\n",
       "    0.4313636363636363,\n",
       "    0.34045454545454534,\n",
       "    0.29499999999999993,\n",
       "    0.3783333333333333,\n",
       "    0.4313636363636363,\n",
       "    0.12833333333333316,\n",
       "    0.29499999999999993,\n",
       "    0.4313636363636363,\n",
       "    0.4313636363636363,\n",
       "    0.34045454545454534,\n",
       "    0.29499999999999993,\n",
       "    0.34045454545454534,\n",
       "    0.3949999999999999,\n",
       "    0.29499999999999993,\n",
       "    0.21166666666666664,\n",
       "    0.29499999999999993,\n",
       "    0.2495454545454545,\n",
       "    0.34045454545454534,\n",
       "    0.4313636363636363,\n",
       "    0.2495454545454545,\n",
       "    0.34045454545454534,\n",
       "    0.4313636363636363,\n",
       "    0.4949999999999999,\n",
       "    0.4313636363636363,\n",
       "    0.29499999999999993,\n",
       "    0.21166666666666664,\n",
       "    0.29499999999999993,\n",
       "    0.21166666666666664,\n",
       "    0.29499999999999993,\n",
       "    0.29499999999999993,\n",
       "    0.4313636363636363,\n",
       "    0.29499999999999993,\n",
       "    0.29499999999999993,\n",
       "    0.34045454545454534,\n",
       "    0.4313636363636363,\n",
       "    0.34045454545454534,\n",
       "    0.4313636363636363,\n",
       "    0.29499999999999993,\n",
       "    0.29499999999999993,\n",
       "    0.29499999999999993,\n",
       "    0.21166666666666664,\n",
       "    0.29499999999999993,\n",
       "    0.4313636363636363,\n",
       "    0.34045454545454534,\n",
       "    0.29499999999999993,\n",
       "    0.29499999999999993,\n",
       "    0.29499999999999993,\n",
       "    0.4313636363636363,\n",
       "    0.3783333333333333,\n",
       "    0.29499999999999993,\n",
       "    0.29499999999999993,\n",
       "    0.34045454545454534,\n",
       "    0.4313636363636363,\n",
       "    0.34045454545454534,\n",
       "    0.34045454545454534,\n",
       "    0.4313636363636363,\n",
       "    0.4313636363636363,\n",
       "    0.4313636363636363,\n",
       "    0.3783333333333333,\n",
       "    0.21166666666666664,\n",
       "    0.21166666666666664,\n",
       "    0.29499999999999993,\n",
       "    0.29499999999999993,\n",
       "    0.29499999999999993,\n",
       "    0.4313636363636363,\n",
       "    0.4313636363636363,\n",
       "    0.4313636363636363,\n",
       "    0.34045454545454534,\n",
       "    0.4313636363636363,\n",
       "    0.34045454545454534,\n",
       "    0.29499999999999993,\n",
       "    0.34045454545454534,\n",
       "    0.34045454545454534,\n",
       "    0.29499999999999993,\n",
       "    0.4313636363636363,\n",
       "    0.3783333333333333,\n",
       "    0.4313636363636363,\n",
       "    0.4313636363636363,\n",
       "    0.34045454545454534,\n",
       "    0.4949999999999999,\n",
       "    0.3783333333333333,\n",
       "    0.29499999999999993,\n",
       "    0.3783333333333333,\n",
       "    0.3783333333333333,\n",
       "    0.4313636363636363,\n",
       "    0.21166666666666664,\n",
       "    0.29499999999999993,\n",
       "    0.29499999999999993,\n",
       "    0.29499999999999993,\n",
       "    0.4949999999999999,\n",
       "    0.4313636363636363,\n",
       "    0.4313636363636363,\n",
       "    0.4313636363636363,\n",
       "    0.3949999999999999,\n",
       "    0.4313636363636363],\n",
       "   'episode_lengths': [106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106,\n",
       "    106]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.19745319642734505,\n",
       "   'mean_inference_ms': 15.530381929603143,\n",
       "   'mean_action_processing_ms': 0.16902741440772243,\n",
       "   'mean_env_wait_ms': 2.9111113826664963,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 4,\n",
       "  'timesteps_total': 576000,\n",
       "  'timesteps_this_iter': 0,\n",
       "  'agent_timesteps_total': 576000,\n",
       "  'timers': {'sample_time_ms': 12009.818,\n",
       "   'sample_throughput': 95.922,\n",
       "   'load_time_ms': 0.841,\n",
       "   'load_throughput': 1369762.78,\n",
       "   'learn_time_ms': 5300.668,\n",
       "   'learn_throughput': 217.331,\n",
       "   'update_time_ms': 2.038},\n",
       "  'info': {'learner': {'default_policy': {'learner_stats': {'cur_kl_coeff': 1.4511882239999998,\n",
       "      'cur_lr': 1e-05,\n",
       "      'total_loss': -0.01017952257132579,\n",
       "      'policy_loss': -0.020544522897623773,\n",
       "      'vf_loss': 0.0024294918870769572,\n",
       "      'vf_explained_var': 0.18092642955127217,\n",
       "      'kl': 0.005720498541796544,\n",
       "      'entropy': 13.17307926075799,\n",
       "      'entropy_coeff': 0.0}}},\n",
       "   'num_steps_sampled': 576000,\n",
       "   'num_agent_steps_sampled': 576000,\n",
       "   'num_steps_trained': 576000,\n",
       "   'num_agent_steps_trained': 576000,\n",
       "   'num_steps_trained_this_iter': 0},\n",
       "  'done': True,\n",
       "  'episodes_total': 5445,\n",
       "  'training_iteration': 500,\n",
       "  'trial_id': '4a7daf16',\n",
       "  'experiment_id': '6be95979652c4ebf88a341bccdfaa369',\n",
       "  'date': '2022-03-11_13-04-49',\n",
       "  'timestamp': 1647003889,\n",
       "  'time_this_iter_s': 11.783470869064331,\n",
       "  'time_total_s': 6062.324910402298,\n",
       "  'pid': 2504813,\n",
       "  'hostname': 'pgcotovio-B450-AORUS-ELITE',\n",
       "  'node_ip': '10.20.0.204',\n",
       "  'config': {'num_workers': 4,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 144,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'gamma': 0.99,\n",
       "   'lr': 1e-05,\n",
       "   'train_batch_size': 577,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    '_disable_preprocessor_api': True,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': False,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'framestack': True,\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': 'general_model_torch',\n",
       "    'custom_model_config': {'fcnet_feats': [256, 256]},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1},\n",
       "   'optimizer': {},\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'BiclusterEnv-v0',\n",
       "   'observation_space': None,\n",
       "   'action_space': None,\n",
       "   'env_config': {'shape': [[6, 6], [6, 6]],\n",
       "    'n': 1,\n",
       "    'clusters': [1, 1],\n",
       "    'dataset_settings': {'dstype': {'value': 'Symbolic'},\n",
       "     'patterns': {'value': [['CONSTANT', 'CONSTANT']]},\n",
       "     'symbols': {'value': [-1, 1]},\n",
       "     'bktype': {'value': 'UNIFORM'},\n",
       "     'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]},\n",
       "     'contiguity': {'value': None},\n",
       "     'plaidcoherency': {'value': 'NO_OVERLAPPING'}},\n",
       "    'max_steps': 105.17943155978949,\n",
       "    'reward_shaping': 0.1,\n",
       "    'seed': 175},\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'clip_rewards': False,\n",
       "   'normalize_actions': True,\n",
       "   'clip_actions': False,\n",
       "   'preprocessor_pref': None,\n",
       "   'log_level': 'DEBUG',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'torch',\n",
       "   'eager_tracing': False,\n",
       "   'eager_max_retraces': 20,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'StochasticSampling'},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 10,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'min_iter_time_s': 0,\n",
       "   'timesteps_per_iteration': 0,\n",
       "   'seed': 175,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0.0001,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0.24975,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_config': {},\n",
       "   'actions_in_input_normalized': False,\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {'default_policy': PolicySpec(policy_class=<class 'ray.rllib.agents.ppo.ppo_torch_policy.PPOTorchPolicy'>, observation_space=None, action_space=None, config={})},\n",
       "    'policy_map_capacity': 100,\n",
       "    'policy_map_cache': None,\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   '_tf_policy_handles_more_than_one_loss': False,\n",
       "   '_disable_preprocessor_api': True,\n",
       "   'simple_optimizer': False,\n",
       "   'monitor': -1,\n",
       "   'use_critic': True,\n",
       "   'use_gae': True,\n",
       "   'lambda': 0.37748736000000005,\n",
       "   'kl_coeff': 0.382205952,\n",
       "   'sgd_minibatch_size': 70,\n",
       "   'shuffle_sequences': True,\n",
       "   'num_sgd_iter': 21,\n",
       "   'lr_schedule': None,\n",
       "   'vf_loss_coeff': 0.8493465600000002,\n",
       "   'entropy_coeff': 0.0,\n",
       "   'entropy_coeff_schedule': None,\n",
       "   'clip_param': 0.254803968,\n",
       "   'vf_clip_param': 3.7748736000000016,\n",
       "   'grad_clip': None,\n",
       "   'kl_target': 0.008493465599999998,\n",
       "   'vf_share_layers': -1},\n",
       "  'time_since_restore': 6062.324910402298,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 500,\n",
       "  'perf': {'cpu_util_percent': 23.762500000000003,\n",
       "   'ram_util_percent': 63.2,\n",
       "   'gpu_util_percent0': 0.098125,\n",
       "   'vram_util_percent0': 0.9246826171875,\n",
       "   'gpu_util_percent1': 0.43625,\n",
       "   'vram_util_percent1': 0.66192626953125},\n",
       "  'experiment_tag': \"7__disable_preprocessor_api=True,_fake_gpus=False,action_space=None,batch_mode=truncate_episodes,clip_param=0.2548,clip_rewards=False,collect_metrics_timeout=180,compress_observations=False,create_env_on_driver=False,custom_eval_function=None,eager_tracing=False,entropy_coeff=0.0,entropy_coeff_schedule=None,clusters=[1, 1],value=UNIFORM,value=[['UNIFORM', 4, 4], ['UNIFORM', 3, 3]],value=None,value=Symbolic,value=[['CONSTANT', 'CONSTANT']],value=NO_OVERLAPPING,value=[-1, 1],max_steps=105.18,n=1,reward_shaping=0.1,seed=175,shape=[[6, 6], [6, 6]],env_task_fn=None,explore=False,evaluation_interval=None,evaluation_num_episodes=10,evaluation_num_workers=0,evaluation_parallel_to_training=False,type=StochasticSampling,explore=True,framework=torch,gamma=0.99,grad_clip=None,horizon=None,ignore_worker_failures=False,in_evaluation=False,kl_coeff=0.38221,kl_target=0.0084935,lambda=0.37749,log_level=DEBUG,log_sys_usage=True,logger_config=None,lr=1e-05,lr_schedule=None,metrics_smoothing_episodes=100,min_iter_time_s=0,custom_action_dist=None,custom_model=general_model_torch,fcnet_feats=[256, 256],no_done_at_end=False,normalize_actions=True,num_cpus_for_driver=1,num_cpus_per_worker=1,num_envs_per_worker=1,num_gpus=0.0001,num_gpus_per_worker=0.24975,num_sgd_iter=21,num_workers=4,observation_filter=NoFilter,observation_space=None,placement_strategy=PACK,preprocessor_pref=None,record_env=False,render_env=False,rollout_fragment_length=256,sample_async=False,seed=175,sgd_minibatch_size=70,shuffle_sequences=True,soft_horizon=False,synchronize_filters=True,timesteps_per_iteration=0,train_batch_size=577,use_critic=True,use_gae=True,vf_clip_param=3.7749,vf_loss_coeff=0.84935\"},\n",
       " 'df':    episode_reward_max  episode_reward_min  episode_reward_mean  \\\n",
       " 0               1.080           -0.305000             0.149254   \n",
       " 1               1.100           -0.962091            -0.449645   \n",
       " 2               1.140           -0.733889            -0.241291   \n",
       " 3               1.153           -0.384667             0.028061   \n",
       " 4               1.164            0.118667             0.291938   \n",
       " 5               1.182            0.202000             0.290654   \n",
       " 6               1.181            0.211667             0.380874   \n",
       " 7               0.861           -0.872000            -0.365298   \n",
       " \n",
       "    episode_len_mean  episodes_this_iter  num_healthy_workers  timesteps_total  \\\n",
       " 0        354.800000                   2                    4             4608   \n",
       " 1        888.610000                   4                    4           101376   \n",
       " 2        692.670000                   1                    4            80640   \n",
       " 3        504.600000                   5                    4             3456   \n",
       " 4        195.800000                   5                    4           369792   \n",
       " 5        197.190000                   5                    4           415872   \n",
       " 6        104.530000                   8                    4           554112   \n",
       " 7        837.290323                   2                    4            27648   \n",
       " \n",
       "    timesteps_this_iter  agent_timesteps_total   done  ...  config/use_critic  \\\n",
       " 0                    0                   4608  False  ...               True   \n",
       " 1                    0                 101376  False  ...               True   \n",
       " 2                    0                  80640  False  ...               True   \n",
       " 3                    0                   3456  False  ...               True   \n",
       " 4                    0                 369792  False  ...               True   \n",
       " 5                    0                 415872  False  ...               True   \n",
       " 6                    0                 554112  False  ...               True   \n",
       " 7                    0                  27648  False  ...               True   \n",
       " \n",
       "    config/use_gae config/vf_clip_param config/vf_loss_coeff  \\\n",
       " 0            True             3.774874             0.849347   \n",
       " 1            True             3.774874             0.849347   \n",
       " 2            True             3.774874             0.849347   \n",
       " 3            True             3.774874             0.849347   \n",
       " 4            True             3.774874             0.849347   \n",
       " 5            True             3.774874             0.849347   \n",
       " 6            True             3.774874             0.849347   \n",
       " 7            True             3.774874             0.849347   \n",
       " \n",
       "                                               logdir  \\\n",
       " 0  /home/pgcotovio/repos/nclustRL/Exp/test_framew...   \n",
       " 1  /home/pgcotovio/repos/nclustRL/Exp/test_framew...   \n",
       " 2  /home/pgcotovio/repos/nclustRL/Exp/test_framew...   \n",
       " 3  /home/pgcotovio/repos/nclustRL/Exp/test_framew...   \n",
       " 4  /home/pgcotovio/repos/nclustRL/Exp/test_framew...   \n",
       " 5  /home/pgcotovio/repos/nclustRL/Exp/test_framew...   \n",
       " 6  /home/pgcotovio/repos/nclustRL/Exp/test_framew...   \n",
       " 7  /home/pgcotovio/repos/nclustRL/Exp/test_framew...   \n",
       " \n",
       "    sampler_perf/mean_raw_obs_processing_ms  sampler_perf/mean_inference_ms  \\\n",
       " 0                                      NaN                             NaN   \n",
       " 1                                      NaN                             NaN   \n",
       " 2                                      NaN                             NaN   \n",
       " 3                                      NaN                             NaN   \n",
       " 4                                 0.180078                       15.812061   \n",
       " 5                                 0.181983                       15.808136   \n",
       " 6                                 0.197775                       15.539687   \n",
       " 7                                      NaN                             NaN   \n",
       " \n",
       "    sampler_perf/mean_action_processing_ms  sampler_perf/mean_env_wait_ms  \\\n",
       " 0                                     NaN                            NaN   \n",
       " 1                                     NaN                            NaN   \n",
       " 2                                     NaN                            NaN   \n",
       " 3                                     NaN                            NaN   \n",
       " 4                                0.172368                       2.936309   \n",
       " 5                                0.173825                       2.947481   \n",
       " 6                                0.169126                       2.915205   \n",
       " 7                                     NaN                            NaN   \n",
       " \n",
       "   sampler_perf/mean_env_render_ms  \n",
       " 0                             NaN  \n",
       " 1                             NaN  \n",
       " 2                             NaN  \n",
       " 3                             NaN  \n",
       " 4                             0.0  \n",
       " 5                             0.0  \n",
       " 6                             0.0  \n",
       " 7                             NaN  \n",
       " \n",
       " [8 rows x 130 columns]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0311 14:49:16.116082301 2731683 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1647010156.116020885\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1647010156.116012960\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0311 15:27:26.448039843 2753000 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1647012446.448001360\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1647012446.447996761\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0311 15:45:01.530062746 2762841 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1647013501.530006910\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1647013501.529999115\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0311 16:35:32.095048941 2791209 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1647016532.094993046\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1647016532.094984019\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0311 16:47:17.158105484 2797878 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1647017237.158044930\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1647017237.158036333\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0311 17:53:07.739098876 2834747 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1647021187.739040746\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1647021187.739032942\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0311 18:34:48.153084296 2858000 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1647023688.153023942\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1647023688.153016197\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0311 18:53:38.275041701 2868652 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1647024818.274982168\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1647024818.274973472\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0311 19:21:53.517112412 2884443 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1647026513.517046878\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1647026513.517037420\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0311 20:29:54.044107788 2922496 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1647030594.044048135\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1647030594.044040350\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0311 21:06:09.304031795 2942853 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1647032769.303975499\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1647032769.303967384\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n"
     ]
    }
   ],
   "source": [
    "bayesopt = BayesOptSearch(metric=\"mean_loss\", mode=\"min\")\n",
    "\n",
    "best_checkpoint = trainer_basic_v3_tunned.train(\n",
    "    num_samples=8,\n",
    "    stop_iters=500,\n",
    "    search_alg=bayesopt\n",
    ")\n",
    "best_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_reward_max</th>\n",
       "      <th>episode_reward_min</th>\n",
       "      <th>episode_reward_mean</th>\n",
       "      <th>episode_len_mean</th>\n",
       "      <th>episodes_this_iter</th>\n",
       "      <th>num_healthy_workers</th>\n",
       "      <th>timesteps_total</th>\n",
       "      <th>timesteps_this_iter</th>\n",
       "      <th>agent_timesteps_total</th>\n",
       "      <th>done</th>\n",
       "      <th>...</th>\n",
       "      <th>config/use_critic</th>\n",
       "      <th>config/use_gae</th>\n",
       "      <th>config/vf_clip_param</th>\n",
       "      <th>config/vf_loss_coeff</th>\n",
       "      <th>logdir</th>\n",
       "      <th>sampler_perf/mean_raw_obs_processing_ms</th>\n",
       "      <th>sampler_perf/mean_inference_ms</th>\n",
       "      <th>sampler_perf/mean_action_processing_ms</th>\n",
       "      <th>sampler_perf/mean_env_wait_ms</th>\n",
       "      <th>sampler_perf/mean_env_render_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.080</td>\n",
       "      <td>-0.305000</td>\n",
       "      <td>0.149254</td>\n",
       "      <td>354.800000</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4608</td>\n",
       "      <td>0</td>\n",
       "      <td>4608</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.774874</td>\n",
       "      <td>0.849347</td>\n",
       "      <td>/home/pgcotovio/repos/nclustRL/Exp/test_framew...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.100</td>\n",
       "      <td>-0.962091</td>\n",
       "      <td>-0.449645</td>\n",
       "      <td>888.610000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>101376</td>\n",
       "      <td>0</td>\n",
       "      <td>101376</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.774874</td>\n",
       "      <td>0.849347</td>\n",
       "      <td>/home/pgcotovio/repos/nclustRL/Exp/test_framew...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.140</td>\n",
       "      <td>-0.733889</td>\n",
       "      <td>-0.241291</td>\n",
       "      <td>692.670000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>80640</td>\n",
       "      <td>0</td>\n",
       "      <td>80640</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.774874</td>\n",
       "      <td>0.849347</td>\n",
       "      <td>/home/pgcotovio/repos/nclustRL/Exp/test_framew...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.153</td>\n",
       "      <td>-0.384667</td>\n",
       "      <td>0.028061</td>\n",
       "      <td>504.600000</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3456</td>\n",
       "      <td>0</td>\n",
       "      <td>3456</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.774874</td>\n",
       "      <td>0.849347</td>\n",
       "      <td>/home/pgcotovio/repos/nclustRL/Exp/test_framew...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.164</td>\n",
       "      <td>0.118667</td>\n",
       "      <td>0.291938</td>\n",
       "      <td>195.800000</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>369792</td>\n",
       "      <td>0</td>\n",
       "      <td>369792</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.774874</td>\n",
       "      <td>0.849347</td>\n",
       "      <td>/home/pgcotovio/repos/nclustRL/Exp/test_framew...</td>\n",
       "      <td>0.180078</td>\n",
       "      <td>15.812061</td>\n",
       "      <td>0.172368</td>\n",
       "      <td>2.936309</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.182</td>\n",
       "      <td>0.202000</td>\n",
       "      <td>0.290654</td>\n",
       "      <td>197.190000</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>415872</td>\n",
       "      <td>0</td>\n",
       "      <td>415872</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.774874</td>\n",
       "      <td>0.849347</td>\n",
       "      <td>/home/pgcotovio/repos/nclustRL/Exp/test_framew...</td>\n",
       "      <td>0.181983</td>\n",
       "      <td>15.808136</td>\n",
       "      <td>0.173825</td>\n",
       "      <td>2.947481</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.181</td>\n",
       "      <td>0.211667</td>\n",
       "      <td>0.380874</td>\n",
       "      <td>104.530000</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>554112</td>\n",
       "      <td>0</td>\n",
       "      <td>554112</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.774874</td>\n",
       "      <td>0.849347</td>\n",
       "      <td>/home/pgcotovio/repos/nclustRL/Exp/test_framew...</td>\n",
       "      <td>0.197775</td>\n",
       "      <td>15.539687</td>\n",
       "      <td>0.169126</td>\n",
       "      <td>2.915205</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.861</td>\n",
       "      <td>-0.872000</td>\n",
       "      <td>-0.365298</td>\n",
       "      <td>837.290323</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>27648</td>\n",
       "      <td>0</td>\n",
       "      <td>27648</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.774874</td>\n",
       "      <td>0.849347</td>\n",
       "      <td>/home/pgcotovio/repos/nclustRL/Exp/test_framew...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode_reward_max  episode_reward_min  episode_reward_mean  \\\n",
       "0               1.080           -0.305000             0.149254   \n",
       "1               1.100           -0.962091            -0.449645   \n",
       "2               1.140           -0.733889            -0.241291   \n",
       "3               1.153           -0.384667             0.028061   \n",
       "4               1.164            0.118667             0.291938   \n",
       "5               1.182            0.202000             0.290654   \n",
       "6               1.181            0.211667             0.380874   \n",
       "7               0.861           -0.872000            -0.365298   \n",
       "\n",
       "   episode_len_mean  episodes_this_iter  num_healthy_workers  timesteps_total  \\\n",
       "0        354.800000                   2                    4             4608   \n",
       "1        888.610000                   4                    4           101376   \n",
       "2        692.670000                   1                    4            80640   \n",
       "3        504.600000                   5                    4             3456   \n",
       "4        195.800000                   5                    4           369792   \n",
       "5        197.190000                   5                    4           415872   \n",
       "6        104.530000                   8                    4           554112   \n",
       "7        837.290323                   2                    4            27648   \n",
       "\n",
       "   timesteps_this_iter  agent_timesteps_total   done  ...  config/use_critic  \\\n",
       "0                    0                   4608  False  ...               True   \n",
       "1                    0                 101376  False  ...               True   \n",
       "2                    0                  80640  False  ...               True   \n",
       "3                    0                   3456  False  ...               True   \n",
       "4                    0                 369792  False  ...               True   \n",
       "5                    0                 415872  False  ...               True   \n",
       "6                    0                 554112  False  ...               True   \n",
       "7                    0                  27648  False  ...               True   \n",
       "\n",
       "   config/use_gae config/vf_clip_param config/vf_loss_coeff  \\\n",
       "0            True             3.774874             0.849347   \n",
       "1            True             3.774874             0.849347   \n",
       "2            True             3.774874             0.849347   \n",
       "3            True             3.774874             0.849347   \n",
       "4            True             3.774874             0.849347   \n",
       "5            True             3.774874             0.849347   \n",
       "6            True             3.774874             0.849347   \n",
       "7            True             3.774874             0.849347   \n",
       "\n",
       "                                              logdir  \\\n",
       "0  /home/pgcotovio/repos/nclustRL/Exp/test_framew...   \n",
       "1  /home/pgcotovio/repos/nclustRL/Exp/test_framew...   \n",
       "2  /home/pgcotovio/repos/nclustRL/Exp/test_framew...   \n",
       "3  /home/pgcotovio/repos/nclustRL/Exp/test_framew...   \n",
       "4  /home/pgcotovio/repos/nclustRL/Exp/test_framew...   \n",
       "5  /home/pgcotovio/repos/nclustRL/Exp/test_framew...   \n",
       "6  /home/pgcotovio/repos/nclustRL/Exp/test_framew...   \n",
       "7  /home/pgcotovio/repos/nclustRL/Exp/test_framew...   \n",
       "\n",
       "   sampler_perf/mean_raw_obs_processing_ms  sampler_perf/mean_inference_ms  \\\n",
       "0                                      NaN                             NaN   \n",
       "1                                      NaN                             NaN   \n",
       "2                                      NaN                             NaN   \n",
       "3                                      NaN                             NaN   \n",
       "4                                 0.180078                       15.812061   \n",
       "5                                 0.181983                       15.808136   \n",
       "6                                 0.197775                       15.539687   \n",
       "7                                      NaN                             NaN   \n",
       "\n",
       "   sampler_perf/mean_action_processing_ms  sampler_perf/mean_env_wait_ms  \\\n",
       "0                                     NaN                            NaN   \n",
       "1                                     NaN                            NaN   \n",
       "2                                     NaN                            NaN   \n",
       "3                                     NaN                            NaN   \n",
       "4                                0.172368                       2.936309   \n",
       "5                                0.173825                       2.947481   \n",
       "6                                0.169126                       2.915205   \n",
       "7                                     NaN                            NaN   \n",
       "\n",
       "  sampler_perf/mean_env_render_ms  \n",
       "0                             NaN  \n",
       "1                             NaN  \n",
       "2                             NaN  \n",
       "3                             NaN  \n",
       "4                             0.0  \n",
       "5                             0.0  \n",
       "6                             0.0  \n",
       "7                             NaN  \n",
       "\n",
       "[8 rows x 130 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_checkpoint['df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105.17943155978949"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_checkpoint['config']['env_config']['max_steps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_config_v3_tunned_maxsteps_hypertune/sample_0/PPO_2022-03-11_01-06-01/PPO_BiclusterEnv-v0_4a7daf16_7__disable_preprocessor_api=True,_fake_gpus=False,action_space=None,batch_mode=truncate_episodes,clip_2022-03-11_09-40-30/checkpoint_000480/checkpoint-480'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_checkpoint['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tunned_v3_maxsteps_config = best_checkpoint['config']\n",
    "\n",
    "configs = TrainerConfig('tunned_v3_maxsteps_config', '/home/pgcotovio/repos/nclustRL/Exp/test_framework2')\n",
    "configs.save(tunned_v3_maxsteps_config)\n",
    "\n",
    "tunned_v3_maxsteps_config == configs.obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = TrainerConfig('tunned_v3_maxsteps_config', '/home/pgcotovio/repos/nclustRL/Exp/test_framework2')\n",
    "tunned_v3_maxsteps_config = configs.obj\n",
    "tunned_v3_maxsteps_config['env_config']['max_steps'] = int(tunned_v3_maxsteps_config['env_config']['max_steps'])\n",
    "configs.save(tunned_v3_maxsteps_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 21:53:06,805\tWARNING ppo.py:143 -- `train_batch_size` (577) cannot be achieved with your other settings (num_workers=4 num_envs_per_worker=1 rollout_fragment_length=256)! Auto-adjusting `rollout_fragment_length` to 144.\n",
      "2022-03-11 21:53:06,806\tINFO ppo.py:166 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974148)\u001b[0m 2022-03-11 21:53:11,064\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974156)\u001b[0m 2022-03-11 21:53:11,225\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974155)\u001b[0m 2022-03-11 21:53:11,183\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974149)\u001b[0m 2022-03-11 21:53:11,427\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974148)\u001b[0m 2022-03-11 21:53:15,790\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974148)\u001b[0m 2022-03-11 21:53:15,790\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974156)\u001b[0m 2022-03-11 21:53:15,875\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974156)\u001b[0m 2022-03-11 21:53:15,875\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974148)\u001b[0m 2022-03-11 21:53:15,965\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974148)\u001b[0m 2022-03-11 21:53:15,969\tINFO torch_policy.py:186 -- TorchPolicy (worker=4) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974148)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974148)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974155)\u001b[0m 2022-03-11 21:53:15,965\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974155)\u001b[0m 2022-03-11 21:53:15,965\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974156)\u001b[0m 2022-03-11 21:53:16,048\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974156)\u001b[0m 2022-03-11 21:53:16,051\tINFO torch_policy.py:186 -- TorchPolicy (worker=1) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974156)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974156)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974149)\u001b[0m 2022-03-11 21:53:16,021\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974149)\u001b[0m 2022-03-11 21:53:16,022\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974149)\u001b[0m 2022-03-11 21:53:16,178\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974149)\u001b[0m 2022-03-11 21:53:16,181\tINFO torch_policy.py:186 -- TorchPolicy (worker=3) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974149)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974149)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974155)\u001b[0m 2022-03-11 21:53:16,131\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974155)\u001b[0m 2022-03-11 21:53:16,134\tINFO torch_policy.py:186 -- TorchPolicy (worker=2) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974155)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974155)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974148)\u001b[0m 2022-03-11 21:53:16,910\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f39ac28c250> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "2022-03-11 21:53:16,974\tINFO worker_set.py:104 -- Inferred observation/action spaces from remote worker (local worker has no env): {'default_policy': (Dict(action_mask:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), avail_actions:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), state:Box([6 6], [6 6], (2,), int32)), Tuple(Discrete(4), Tuple(Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32)))), '__env__': (Dict(action_mask:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), avail_actions:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), state:Box([6 6], [6 6], (2,), int32)), Tuple(Discrete(4), Tuple(Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32))))}\n",
      "2022-03-11 21:53:16,976\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "2022-03-11 21:53:16,979\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "2022-03-11 21:53:17,000\tINFO torch_policy.py:186 -- TorchPolicy (worker=local) running on 0.0001 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974156)\u001b[0m 2022-03-11 21:53:16,966\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f09fdb399a0> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974155)\u001b[0m 2022-03-11 21:53:17,094\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f6b80d61760> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2974149)\u001b[0m 2022-03-11 21:53:17,177\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7ef7a27a89a0> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "/home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "  warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "2022-03-11 21:53:21,220\tINFO rollout_worker.py:1555 -- Built policy map: {}\n",
      "2022-03-11 21:53:21,221\tINFO rollout_worker.py:1556 -- Built preprocessor map: {'default_policy': None}\n",
      "2022-03-11 21:53:21,221\tINFO rollout_worker.py:618 -- Built filter map: {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x7f370e1d2970>}\n",
      "2022-03-11 21:53:21,222\tDEBUG rollout_worker.py:728 -- Created rollout worker with env None (None), policies {}\n",
      "2022-03-11 21:53:21,224\tINFO trainable.py:124 -- Trainable.setup took 14.421 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    }
   ],
   "source": [
    "configs = TrainerConfig('tunned_v3_maxsteps_config', '/home/pgcotovio/repos/nclustRL/Exp/test_framework2')\n",
    "\n",
    "trainer_basic_v3_tunned = Trainer(\n",
    "    trainer=PPOTrainer,\n",
    "    env='BiclusterEnv-v0',\n",
    "    save_dir='/home/pgcotovio/repos/nclustRL/Exp/test_framework2',\n",
    "    name='basic_config_v3_tunned_maxsteps_hypertune',\n",
    "    config=configs.obj\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 21:53:40,439\tINFO trainable.py:467 -- Restored on 10.20.0.204 from checkpoint: /home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_config_v3_tunned_maxsteps_hypertune/sample_0/PPO_2022-03-11_01-06-01/PPO_BiclusterEnv-v0_4a7daf16_7__disable_preprocessor_api=True,_fake_gpus=False,action_space=None,batch_mode=truncate_episodes,clip_2022-03-11_09-40-30/checkpoint_000480/checkpoint-480\n",
      "2022-03-11 21:53:40,440\tINFO trainable.py:475 -- Current state after restoring: {'_iteration': 480, '_timesteps_total': 0, '_time_total': 5822.938663959503, '_episodes_total': 5229}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 of 10 done.\n",
      "Episode 2 of 10 done.\n",
      "Episode 3 of 10 done.\n",
      "Episode 4 of 10 done.\n",
      "Episode 5 of 10 done.\n",
      "Episode 6 of 10 done.\n",
      "Episode 7 of 10 done.\n",
      "Episode 8 of 10 done.\n",
      "Episode 9 of 10 done.\n",
      "Episode 10 of 10 done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.10500000000000013, 0.09999999999999995, 0.687890284700552)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_basic_v3_tunned.load('/home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_config_v3_tunned_maxsteps_hypertune/sample_0/PPO_2022-03-11_01-06-01/PPO_BiclusterEnv-v0_4a7daf16_7__disable_preprocessor_api=True,_fake_gpus=False,action_space=None,batch_mode=truncate_episodes,clip_2022-03-11_09-40-30/checkpoint_000480/checkpoint-480')\n",
    "\n",
    "trainer_basic_v3_tunned.test(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "729828cdc861d6d099b66561a3a946b82b8f1c817032c383ea17d59bc3dfae8c"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
