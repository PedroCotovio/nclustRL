{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nclustRL.trainer import Trainer\n",
    "from nclustRL.configs.default_configs import PPO_PBT, DEFAULT_CONFIG\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from nclustenv.configs import biclustering, triclustering\n",
    "from nclustRL.configs.save import TrainerConfig\n",
    "from ray.tune import ExperimentAnalysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train\n",
    "    - Train basic v2 (done)\n",
    "    - Hyperparam tune basiuc_v2 (100 it) (done)\n",
    "    - train again with new params\n",
    "        - test trained\n",
    "    - Hyperparam tune basic_v2 without reward shaping (100 it) (done)\n",
    "    - train again with new params\n",
    "        - test trained\n",
    "    \n",
    "\n",
    "\n",
    "- Plot\n",
    "    - basic v2 vs tunned v2 with baseline\n",
    "    - hyperparam tune\n",
    "\n",
    "Compare all pre and pos training test scores "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shaped Reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparam tune basic_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inicialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 19:12:57,483\tINFO ppo.py:166 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676818)\u001b[0m 2022-03-08 19:13:01,503\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676819)\u001b[0m 2022-03-08 19:13:01,568\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676826)\u001b[0m 2022-03-08 19:13:01,631\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676815)\u001b[0m 2022-03-08 19:13:01,769\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676819)\u001b[0m 2022-03-08 19:13:06,007\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676819)\u001b[0m 2022-03-08 19:13:06,007\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676818)\u001b[0m 2022-03-08 19:13:06,054\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676818)\u001b[0m 2022-03-08 19:13:06,054\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676818)\u001b[0m 2022-03-08 19:13:06,056\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676818)\u001b[0m 2022-03-08 19:13:06,058\tINFO torch_policy.py:186 -- TorchPolicy (worker=3) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676818)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676818)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676826)\u001b[0m 2022-03-08 19:13:05,989\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676826)\u001b[0m 2022-03-08 19:13:05,989\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676815)\u001b[0m 2022-03-08 19:13:06,125\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676815)\u001b[0m 2022-03-08 19:13:06,125\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676826)\u001b[0m 2022-03-08 19:13:06,140\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676826)\u001b[0m 2022-03-08 19:13:06,143\tINFO torch_policy.py:186 -- TorchPolicy (worker=1) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676826)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676826)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676819)\u001b[0m 2022-03-08 19:13:06,175\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676819)\u001b[0m 2022-03-08 19:13:06,178\tINFO torch_policy.py:186 -- TorchPolicy (worker=2) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676819)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676819)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676815)\u001b[0m 2022-03-08 19:13:06,265\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676815)\u001b[0m 2022-03-08 19:13:06,268\tINFO torch_policy.py:186 -- TorchPolicy (worker=4) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676815)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676815)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676818)\u001b[0m 2022-03-08 19:13:06,972\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f539a8eee80> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "2022-03-08 19:13:07,091\tINFO worker_set.py:104 -- Inferred observation/action spaces from remote worker (local worker has no env): {'default_policy': (Dict(action_mask:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), avail_actions:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), state:Box([6 6], [6 6], (2,), int32)), Tuple(Discrete(4), Tuple(Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32)))), '__env__': (Dict(action_mask:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), avail_actions:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), state:Box([6 6], [6 6], (2,), int32)), Tuple(Discrete(4), Tuple(Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32))))}\n",
      "2022-03-08 19:13:07,093\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "2022-03-08 19:13:07,096\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "2022-03-08 19:13:07,118\tINFO torch_policy.py:186 -- TorchPolicy (worker=local) running on 0.0001 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676819)\u001b[0m 2022-03-08 19:13:07,092\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f2dc3984d90> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676826)\u001b[0m 2022-03-08 19:13:07,081\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f4548b08730> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1676815)\u001b[0m 2022-03-08 19:13:07,421\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f7649840640> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "/home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "  warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "2022-03-08 19:13:10,993\tINFO rollout_worker.py:1555 -- Built policy map: {}\n",
      "2022-03-08 19:13:10,994\tINFO rollout_worker.py:1556 -- Built preprocessor map: {'default_policy': None}\n",
      "2022-03-08 19:13:10,994\tINFO rollout_worker.py:618 -- Built filter map: {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x7fc5e850cd60>}\n",
      "2022-03-08 19:13:10,994\tDEBUG rollout_worker.py:728 -- Created rollout worker with env None (None), policies {}\n",
      "2022-03-08 19:13:10,997\tINFO trainable.py:124 -- Trainable.setup took 13.515 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    }
   ],
   "source": [
    "config = DEFAULT_CONFIG.copy()\n",
    "config['env_config'] = biclustering.binary.basic_v2\n",
    "\n",
    "trainer = Trainer(\n",
    "    trainer=PPOTrainer,\n",
    "    env='BiclusterEnv-v0',\n",
    "    save_dir='/home/pgcotovio/repos/nclustRL/Exp/test_framework2',\n",
    "    name='basic_config_v2_hypertune',\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-08 23:33:34 (running for 04:20:20.79)<br>Memory usage on this node: 12.3/62.7 GiB<br>PopulationBasedTraining: 22 checkpoints, 20 perturbs<br>Resources requested: 5.0/12 CPUs, 0.9991/2 GPUs, 0.0/33.29 GiB heap, 0.0/16.65 GiB objects<br>Current best trial: cd6a3_00001 with episode_reward_mean=-0.8183759820426495 and parameters={'num_workers': 4, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 163, 'batch_mode': 'truncate_episodes', 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 655, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': True, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'general_model_torch', 'custom_model_config': {'fcnet_feats': [256, 256]}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'BiclusterEnv-v0', 'observation_space': None, 'action_space': None, 'env_config': {'shape': [[6, 6], [6, 6]], 'n': 1, 'clusters': [1, 1], 'dataset_settings': {'dstype': {'value': 'Symbolic'}, 'patterns': {'value': [['CONSTANT', 'CONSTANT']]}, 'symbols': {'value': [-1, 1]}, 'bktype': {'value': 'UNIFORM'}, 'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]}, 'contiguity': {'value': None}, 'plaidcoherency': {'value': 'NO_OVERLAPPING'}}, 'max_steps': 1000, 'seed': 175}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': False, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': None, 'log_level': 'DEBUG', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': 175, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0.0001, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.24975, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'default_policy': PolicySpec(policy_class=<class 'ray.rllib.agents.ppo.ppo_torch_policy.PPOTorchPolicy'>, observation_space=None, action_space=None, config={})}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': True, 'simple_optimizer': False, 'monitor': -1, 'use_critic': True, 'use_gae': True, 'lambda': 0.96, 'kl_coeff': 0.288, 'sgd_minibatch_size': 122, 'shuffle_sequences': True, 'num_sgd_iter': 19, 'lr_schedule': None, 'vf_loss_coeff': 1.44, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.432, 'vf_clip_param': 14.399999999999999, 'grad_clip': None, 'kl_target': 0.0064, 'vf_share_layers': -1}<br>Result logdir: /home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_config_v2_hypertune/sample_0/PPO_2022-03-08_19-13-14<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 23:33:34,988\tWARNING worker.py:1245 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffd715c3caf9e9bff10812760d01000000 Worker ID: 95fcb97face687f350c5df206bd4b9796ee54fdea0296ee42ffbea7f Node ID: 55996604780d5c204f46219fe26df8f24e4bbe77cb9e563fa2724bba Worker IP address: 10.20.0.204 Worker port: 46729 Worker PID: 1676819\n",
      "2022-03-08 23:33:35,060\tWARNING worker.py:1245 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff1a442c5a7a9513a11e685e2f01000000 Worker ID: 6c0b11e358c19518e92161a0f04b2fb6d9b13293bee5de163a79894f Node ID: 55996604780d5c204f46219fe26df8f24e4bbe77cb9e563fa2724bba Worker IP address: 10.20.0.204 Worker port: 41927 Worker PID: 1676818\n",
      "2022-03-08 23:33:35,144\tERROR tune.py:622 -- Trials did not complete: [PPO_BiclusterEnv-v0_cd6a3_00000, PPO_BiclusterEnv-v0_cd6a3_00001, PPO_BiclusterEnv-v0_cd6a3_00002, PPO_BiclusterEnv-v0_cd6a3_00003, PPO_BiclusterEnv-v0_cd6a3_00004, PPO_BiclusterEnv-v0_cd6a3_00005, PPO_BiclusterEnv-v0_cd6a3_00006, PPO_BiclusterEnv-v0_cd6a3_00007]\n",
      "2022-03-08 23:33:35,144\tINFO tune.py:626 -- Total run time: 15621.04 seconds (15620.78 seconds for the tuning loop).\n",
      "2022-03-08 23:33:35,145\tWARNING tune.py:630 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n",
      "Sample 1: : 1sample [4:20:21, 15621.07s/sample, metric={'episode_reward_max': 2.984, 'episode_reward_min': -1.6666666666666676, 'episode_reward_mean': -0.8183759820426495, 'episode_len_mean': 895.5, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.035999999999999, -1.600000000000001, -1.600000000000001, -1.6363636363636371, 2.984, -1.600000000000001, -1.5454545454545463, -1.4444444444444453, -1.3333333333333344, -1.6363636363636371, 2.876, -1.4444444444444453, -1.2500000000000009, -1.6666666666666676, -1.5000000000000009, -1.6363636363636371, -1.4000000000000008, -1.3333333333333344], 'episode_lengths': [964, 1001, 1001, 1001, 16, 1001, 1001, 1001, 1001, 1001, 124, 1001, 1001, 1001, 1001, 1001, 1001, 1001]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.15396040772497432, 'mean_inference_ms': 15.886685111726731, 'mean_action_processing_ms': 0.1739471256799097, 'mean_env_wait_ms': 2.9833305957190106, 'mean_env_render_ms': 0.0}, 'off_policy_estimator': {}, 'num_healthy_workers': 4, 'timesteps_total': 140296, 'timesteps_this_iter': 0, 'agent_timesteps_total': 140296, 'timers': {'sample_time_ms': 11420.364, 'sample_throughput': 114.182, 'load_time_ms': 0.895, 'load_throughput': 1456285.757, 'learn_time_ms': 3900.089, 'learn_throughput': 334.351, 'update_time_ms': 1.901}, 'info': {'learner': {'default_policy': {'learner_stats': {'cur_kl_coeff': 2.1869999999999994, 'cur_lr': 5.000000000000001e-05, 'total_loss': 0.023040482373969433, 'policy_loss': 0.0063706706866229834, 'vf_loss': 0.006575056636019757, 'vf_explained_var': 0.2176180949336604, 'kl': 0.0032929715663684825, 'entropy': 13.179562719244705, 'entropy_coeff': 0.0}}}, 'num_steps_sampled': 140296, 'num_agent_steps_sampled': 140296, 'num_steps_trained': 140296, 'num_agent_steps_trained': 140296, 'num_steps_trained_this_iter': 0}, 'done': False, 'episodes_total': 128, 'training_iteration': 115, 'trial_id': 'cd6a3_00001', 'experiment_id': '0cf8cf54edd34419bfa82bcca2d54520', 'date': '2022-03-08_23-07-08', 'timestamp': 1646780828, 'time_this_iter_s': 11.373039722442627, 'time_total_s': 1439.9905858039856, 'pid': 1949329, 'hostname': 'pgcotovio-B450-AORUS-ELITE', 'node_ip': '10.20.0.204', 'config': {'num_workers': 4, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 163, 'batch_mode': 'truncate_episodes', 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 655, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': True, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'general_model_torch', 'custom_model_config': {'fcnet_feats': [256, 256]}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'BiclusterEnv-v0', 'observation_space': None, 'action_space': None, 'env_config': {'shape': [[6, 6], [6, 6]], 'n': 1, 'clusters': [1, 1], 'dataset_settings': {'dstype': {'value': 'Symbolic'}, 'patterns': {'value': [['CONSTANT', 'CONSTANT']]}, 'symbols': {'value': [-1, 1]}, 'bktype': {'value': 'UNIFORM'}, 'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]}, 'contiguity': {'value': None}, 'plaidcoherency': {'value': 'NO_OVERLAPPING'}}, 'max_steps': 1000, 'seed': 175}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': False, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': None, 'log_level': 'DEBUG', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': 175, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0.0001, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.24975, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'default_policy': PolicySpec(policy_class=<class 'ray.rllib.agents.ppo.ppo_torch_policy.PPOTorchPolicy'>, observation_space=None, action_space=None, config={})}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': True, 'simple_optimizer': False, 'monitor': -1, 'use_critic': True, 'use_gae': True, 'lambda': 0.96, 'kl_coeff': 0.288, 'sgd_minibatch_size': 122, 'shuffle_sequences': True, 'num_sgd_iter': 19, 'lr_schedule': None, 'vf_loss_coeff': 1.44, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.432, 'vf_clip_param': 14.399999999999999, 'grad_clip': None, 'kl_target': 0.0064, 'vf_share_layers': -1}, 'time_since_restore': 171.02070879936218, 'timesteps_since_restore': 0, 'iterations_since_restore': 15, 'perf': {'cpu_util_percent': 29.949999999999996, 'ram_util_percent': 64.10000000000001, 'gpu_util_percent0': 0.06642857142857142, 'vram_util_percent0': 0.9249267578125, 'gpu_util_percent1': 0.5614285714285714, 'vram_util_percent1': 0.6594325474330357}, 'experiment_tag': '1@perturbed[clip_param=0.432,entropy_coeff=0.0,kl_coeff=0.288,kl_target=0.0064,lambda=0.96,lr=5e-05,num_sgd_iter=19,sgd_minibatch_size=122,train_batch_size=655,vf_clip_param=14.4,vf_loss_coeff=1.44]'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'config': {'num_workers': 4,\n",
       "  'create_env_on_driver': False,\n",
       "  'num_envs_per_worker': 1,\n",
       "  'batch_mode': 'truncate_episodes',\n",
       "  'gamma': 0.99,\n",
       "  'use_critic': True,\n",
       "  'use_gae': True,\n",
       "  'lambda': 0.96,\n",
       "  'kl_coeff': 0.288,\n",
       "  'rollout_fragment_length': 256,\n",
       "  'train_batch_size': 655,\n",
       "  'sgd_minibatch_size': 122,\n",
       "  'shuffle_sequences': True,\n",
       "  'num_sgd_iter': 19,\n",
       "  'lr': 5e-05,\n",
       "  'lr_schedule': None,\n",
       "  'vf_loss_coeff': 1.44,\n",
       "  'entropy_coeff': 0.0,\n",
       "  'entropy_coeff_schedule': None,\n",
       "  'clip_param': 0.432,\n",
       "  'vf_clip_param': 14.399999999999999,\n",
       "  'grad_clip': None,\n",
       "  'kl_target': 0.0064,\n",
       "  'optimizer': {},\n",
       "  'horizon': None,\n",
       "  'soft_horizon': False,\n",
       "  'no_done_at_end': False,\n",
       "  'env': 'BiclusterEnv-v0',\n",
       "  'observation_space': None,\n",
       "  'action_space': None,\n",
       "  'env_config': {'shape': [[6, 6], [6, 6]],\n",
       "   'n': 1,\n",
       "   'clusters': [1, 1],\n",
       "   'dataset_settings': {'dstype': {'value': 'Symbolic'},\n",
       "    'patterns': {'value': [['CONSTANT', 'CONSTANT']]},\n",
       "    'symbols': {'value': [-1, 1]},\n",
       "    'bktype': {'value': 'UNIFORM'},\n",
       "    'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]},\n",
       "    'contiguity': {'value': None},\n",
       "    'plaidcoherency': {'value': 'NO_OVERLAPPING'}},\n",
       "   'max_steps': 1000,\n",
       "   'seed': 175},\n",
       "  'env_task_fn': None,\n",
       "  'render_env': False,\n",
       "  'record_env': False,\n",
       "  'clip_rewards': False,\n",
       "  'normalize_actions': True,\n",
       "  'preprocessor_pref': None,\n",
       "  'log_level': 'DEBUG',\n",
       "  'ignore_worker_failures': False,\n",
       "  'log_sys_usage': True,\n",
       "  'framework': 'torch',\n",
       "  'eager_tracing': False,\n",
       "  'explore': True,\n",
       "  'exploration_config': {'type': 'StochasticSampling'},\n",
       "  'evaluation_interval': None,\n",
       "  'evaluation_num_episodes': 10,\n",
       "  'evaluation_parallel_to_training': False,\n",
       "  'in_evaluation': False,\n",
       "  'evaluation_config': {'explore': False},\n",
       "  'evaluation_num_workers': 0,\n",
       "  'custom_eval_function': None,\n",
       "  'sample_async': False,\n",
       "  'observation_filter': 'NoFilter',\n",
       "  'synchronize_filters': True,\n",
       "  'compress_observations': False,\n",
       "  'collect_metrics_timeout': 180,\n",
       "  'metrics_smoothing_episodes': 100,\n",
       "  'min_iter_time_s': 0,\n",
       "  'timesteps_per_iteration': 0,\n",
       "  'seed': 175,\n",
       "  'extra_python_environs_for_driver': {},\n",
       "  'extra_python_environs_for_worker': {},\n",
       "  'num_gpus': 0.0001,\n",
       "  '_fake_gpus': False,\n",
       "  'num_cpus_per_worker': 1,\n",
       "  'num_gpus_per_worker': 0.24975,\n",
       "  'custom_resources_per_worker': {},\n",
       "  'num_cpus_for_driver': 1,\n",
       "  'placement_strategy': 'PACK',\n",
       "  'logger_config': None,\n",
       "  '_disable_preprocessor_api': True,\n",
       "  'model': {'custom_model': 'general_model_torch',\n",
       "   'custom_model_config': {'fcnet_feats': [256, 256]},\n",
       "   'custom_action_dist': None}},\n",
       " 'path': '/home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_config_v2_hypertune/sample_0/PPO_2022-03-08_19-13-14/PPO_BiclusterEnv-v0_cd6a3_00001_1_2022-03-08_19-13-14/checkpoint_000040/checkpoint-40',\n",
       " 'metric': {'episode_reward_max': 2.984,\n",
       "  'episode_reward_min': -1.6666666666666676,\n",
       "  'episode_reward_mean': -0.8183759820426495,\n",
       "  'episode_len_mean': 895.5,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 0,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [2.035999999999999,\n",
       "    -1.600000000000001,\n",
       "    -1.600000000000001,\n",
       "    -1.6363636363636371,\n",
       "    2.984,\n",
       "    -1.600000000000001,\n",
       "    -1.5454545454545463,\n",
       "    -1.4444444444444453,\n",
       "    -1.3333333333333344,\n",
       "    -1.6363636363636371,\n",
       "    2.876,\n",
       "    -1.4444444444444453,\n",
       "    -1.2500000000000009,\n",
       "    -1.6666666666666676,\n",
       "    -1.5000000000000009,\n",
       "    -1.6363636363636371,\n",
       "    -1.4000000000000008,\n",
       "    -1.3333333333333344],\n",
       "   'episode_lengths': [964,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    16,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    124,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.15396040772497432,\n",
       "   'mean_inference_ms': 15.886685111726731,\n",
       "   'mean_action_processing_ms': 0.1739471256799097,\n",
       "   'mean_env_wait_ms': 2.9833305957190106,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 4,\n",
       "  'timesteps_total': 140296,\n",
       "  'timesteps_this_iter': 0,\n",
       "  'agent_timesteps_total': 140296,\n",
       "  'timers': {'sample_time_ms': 11420.364,\n",
       "   'sample_throughput': 114.182,\n",
       "   'load_time_ms': 0.895,\n",
       "   'load_throughput': 1456285.757,\n",
       "   'learn_time_ms': 3900.089,\n",
       "   'learn_throughput': 334.351,\n",
       "   'update_time_ms': 1.901},\n",
       "  'info': {'learner': {'default_policy': {'learner_stats': {'cur_kl_coeff': 2.1869999999999994,\n",
       "      'cur_lr': 5.000000000000001e-05,\n",
       "      'total_loss': 0.023040482373969433,\n",
       "      'policy_loss': 0.0063706706866229834,\n",
       "      'vf_loss': 0.006575056636019757,\n",
       "      'vf_explained_var': 0.2176180949336604,\n",
       "      'kl': 0.0032929715663684825,\n",
       "      'entropy': 13.179562719244705,\n",
       "      'entropy_coeff': 0.0}}},\n",
       "   'num_steps_sampled': 140296,\n",
       "   'num_agent_steps_sampled': 140296,\n",
       "   'num_steps_trained': 140296,\n",
       "   'num_agent_steps_trained': 140296,\n",
       "   'num_steps_trained_this_iter': 0},\n",
       "  'done': False,\n",
       "  'episodes_total': 128,\n",
       "  'training_iteration': 115,\n",
       "  'trial_id': 'cd6a3_00001',\n",
       "  'experiment_id': '0cf8cf54edd34419bfa82bcca2d54520',\n",
       "  'date': '2022-03-08_23-07-08',\n",
       "  'timestamp': 1646780828,\n",
       "  'time_this_iter_s': 11.373039722442627,\n",
       "  'time_total_s': 1439.9905858039856,\n",
       "  'pid': 1949329,\n",
       "  'hostname': 'pgcotovio-B450-AORUS-ELITE',\n",
       "  'node_ip': '10.20.0.204',\n",
       "  'config': {'num_workers': 4,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 163,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'gamma': 0.99,\n",
       "   'lr': 5e-05,\n",
       "   'train_batch_size': 655,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    '_disable_preprocessor_api': True,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': False,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'framestack': True,\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': 'general_model_torch',\n",
       "    'custom_model_config': {'fcnet_feats': [256, 256]},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1},\n",
       "   'optimizer': {},\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'BiclusterEnv-v0',\n",
       "   'observation_space': None,\n",
       "   'action_space': None,\n",
       "   'env_config': {'shape': [[6, 6], [6, 6]],\n",
       "    'n': 1,\n",
       "    'clusters': [1, 1],\n",
       "    'dataset_settings': {'dstype': {'value': 'Symbolic'},\n",
       "     'patterns': {'value': [['CONSTANT', 'CONSTANT']]},\n",
       "     'symbols': {'value': [-1, 1]},\n",
       "     'bktype': {'value': 'UNIFORM'},\n",
       "     'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]},\n",
       "     'contiguity': {'value': None},\n",
       "     'plaidcoherency': {'value': 'NO_OVERLAPPING'}},\n",
       "    'max_steps': 1000,\n",
       "    'seed': 175},\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'clip_rewards': False,\n",
       "   'normalize_actions': True,\n",
       "   'clip_actions': False,\n",
       "   'preprocessor_pref': None,\n",
       "   'log_level': 'DEBUG',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'torch',\n",
       "   'eager_tracing': False,\n",
       "   'eager_max_retraces': 20,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'StochasticSampling'},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 10,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'min_iter_time_s': 0,\n",
       "   'timesteps_per_iteration': 0,\n",
       "   'seed': 175,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0.0001,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0.24975,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_config': {},\n",
       "   'actions_in_input_normalized': False,\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {'default_policy': PolicySpec(policy_class=<class 'ray.rllib.agents.ppo.ppo_torch_policy.PPOTorchPolicy'>, observation_space=None, action_space=None, config={})},\n",
       "    'policy_map_capacity': 100,\n",
       "    'policy_map_cache': None,\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   '_tf_policy_handles_more_than_one_loss': False,\n",
       "   '_disable_preprocessor_api': True,\n",
       "   'simple_optimizer': False,\n",
       "   'monitor': -1,\n",
       "   'use_critic': True,\n",
       "   'use_gae': True,\n",
       "   'lambda': 0.96,\n",
       "   'kl_coeff': 0.288,\n",
       "   'sgd_minibatch_size': 122,\n",
       "   'shuffle_sequences': True,\n",
       "   'num_sgd_iter': 19,\n",
       "   'lr_schedule': None,\n",
       "   'vf_loss_coeff': 1.44,\n",
       "   'entropy_coeff': 0.0,\n",
       "   'entropy_coeff_schedule': None,\n",
       "   'clip_param': 0.432,\n",
       "   'vf_clip_param': 14.399999999999999,\n",
       "   'grad_clip': None,\n",
       "   'kl_target': 0.0064,\n",
       "   'vf_share_layers': -1},\n",
       "  'time_since_restore': 171.02070879936218,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 15,\n",
       "  'perf': {'cpu_util_percent': 29.949999999999996,\n",
       "   'ram_util_percent': 64.10000000000001,\n",
       "   'gpu_util_percent0': 0.06642857142857142,\n",
       "   'vram_util_percent0': 0.9249267578125,\n",
       "   'gpu_util_percent1': 0.5614285714285714,\n",
       "   'vram_util_percent1': 0.6594325474330357},\n",
       "  'experiment_tag': '1@perturbed[clip_param=0.432,entropy_coeff=0.0,kl_coeff=0.288,kl_target=0.0064,lambda=0.96,lr=5e-05,num_sgd_iter=19,sgd_minibatch_size=122,train_batch_size=655,vf_clip_param=14.4,vf_loss_coeff=1.44]'},\n",
       " 'df': Empty DataFrame\n",
       " Columns: []\n",
       " Index: []}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 23:33:35,265\tWARNING worker.py:1245 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff0227e69b475a9eb7302a09c201000000 Worker ID: 205853743bddaf2571b11b226a09c991beec572ced9f5cbd9366952a Node ID: 55996604780d5c204f46219fe26df8f24e4bbe77cb9e563fa2724bba Worker IP address: 10.20.0.204 Worker port: 36531 Worker PID: 1676815\n",
      "2022-03-08 23:33:35,265\tWARNING worker.py:1245 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff23224c104535b3eed95f72f101000000 Worker ID: 690771c631a8827d872df4d7a8e3a14ccbcdcf47bdad9da1fb655c84 Node ID: 55996604780d5c204f46219fe26df8f24e4bbe77cb9e563fa2724bba Worker IP address: 10.20.0.204 Worker port: 37557 Worker PID: 1676826\n"
     ]
    }
   ],
   "source": [
    "best_checkpoint = trainer.train(\n",
    "    num_samples=8, \n",
    "    scheduler=PPO_PBT,\n",
    "    stop_iters=500,\n",
    ")\n",
    "best_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 23:34:11,930\tINFO experiment_analysis.py:673 -- No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n",
      "/home/pgcotovio/repos/nclustRL/venv/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py:262: UserWarning: Dataframes will use '/' instead of '.' to delimit nested result keys in future versions of Ray. For forward compatibility, set the environment variable TUNE_RESULT_DELIM='/'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_reward_max</th>\n",
       "      <th>episode_reward_min</th>\n",
       "      <th>episode_reward_mean</th>\n",
       "      <th>episode_len_mean</th>\n",
       "      <th>episodes_this_iter</th>\n",
       "      <th>num_healthy_workers</th>\n",
       "      <th>timesteps_total</th>\n",
       "      <th>timesteps_this_iter</th>\n",
       "      <th>agent_timesteps_total</th>\n",
       "      <th>done</th>\n",
       "      <th>...</th>\n",
       "      <th>info.learner.default_policy.learner_stats.kl</th>\n",
       "      <th>info.learner.default_policy.learner_stats.entropy</th>\n",
       "      <th>info.learner.default_policy.learner_stats.entropy_coeff</th>\n",
       "      <th>config.env_config.dataset_settings.dstype.value</th>\n",
       "      <th>config.env_config.dataset_settings.patterns.value</th>\n",
       "      <th>config.env_config.dataset_settings.symbols.value</th>\n",
       "      <th>config.env_config.dataset_settings.bktype.value</th>\n",
       "      <th>config.env_config.dataset_settings.clusterdistribution.value</th>\n",
       "      <th>config.env_config.dataset_settings.contiguity.value</th>\n",
       "      <th>config.env_config.dataset_settings.plaidcoherency.value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cd6a3_00000</th>\n",
       "      <td>2.814000</td>\n",
       "      <td>-1.750000</td>\n",
       "      <td>-0.916221</td>\n",
       "      <td>914.230769</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>117240</td>\n",
       "      <td>0</td>\n",
       "      <td>117240</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004712</td>\n",
       "      <td>16.667426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Symbolic</td>\n",
       "      <td>[[CONSTANT, CONSTANT]]</td>\n",
       "      <td>[-1, 1]</td>\n",
       "      <td>UNIFORM</td>\n",
       "      <td>[[UNIFORM, 4, 4], [UNIFORM, 3, 3]]</td>\n",
       "      <td>None</td>\n",
       "      <td>NO_OVERLAPPING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cd6a3_00007</th>\n",
       "      <td>-1.400000</td>\n",
       "      <td>-1.636364</td>\n",
       "      <td>-1.533144</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>149472</td>\n",
       "      <td>0</td>\n",
       "      <td>149472</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023853</td>\n",
       "      <td>12.915991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Symbolic</td>\n",
       "      <td>[[CONSTANT, CONSTANT]]</td>\n",
       "      <td>[-1, 1]</td>\n",
       "      <td>UNIFORM</td>\n",
       "      <td>[[UNIFORM, 4, 4], [UNIFORM, 3, 3]]</td>\n",
       "      <td>None</td>\n",
       "      <td>NO_OVERLAPPING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cd6a3_00001</th>\n",
       "      <td>2.984000</td>\n",
       "      <td>-1.666667</td>\n",
       "      <td>-0.632934</td>\n",
       "      <td>865.357143</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>133776</td>\n",
       "      <td>0</td>\n",
       "      <td>133776</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008617</td>\n",
       "      <td>13.219076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Symbolic</td>\n",
       "      <td>[[CONSTANT, CONSTANT]]</td>\n",
       "      <td>[-1, 1]</td>\n",
       "      <td>UNIFORM</td>\n",
       "      <td>[[UNIFORM, 4, 4], [UNIFORM, 3, 3]]</td>\n",
       "      <td>None</td>\n",
       "      <td>NO_OVERLAPPING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cd6a3_00006</th>\n",
       "      <td>-1.333333</td>\n",
       "      <td>-1.600000</td>\n",
       "      <td>-1.477904</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>144952</td>\n",
       "      <td>0</td>\n",
       "      <td>144952</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013828</td>\n",
       "      <td>13.013030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Symbolic</td>\n",
       "      <td>[[CONSTANT, CONSTANT]]</td>\n",
       "      <td>[-1, 1]</td>\n",
       "      <td>UNIFORM</td>\n",
       "      <td>[[UNIFORM, 4, 4], [UNIFORM, 3, 3]]</td>\n",
       "      <td>None</td>\n",
       "      <td>NO_OVERLAPPING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cd6a3_00005</th>\n",
       "      <td>-1.333333</td>\n",
       "      <td>-1.666667</td>\n",
       "      <td>-1.472348</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>135744</td>\n",
       "      <td>0</td>\n",
       "      <td>135744</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>13.675836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Symbolic</td>\n",
       "      <td>[[CONSTANT, CONSTANT]]</td>\n",
       "      <td>[-1, 1]</td>\n",
       "      <td>UNIFORM</td>\n",
       "      <td>[[UNIFORM, 4, 4], [UNIFORM, 3, 3]]</td>\n",
       "      <td>None</td>\n",
       "      <td>NO_OVERLAPPING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cd6a3_00004</th>\n",
       "      <td>-1.333333</td>\n",
       "      <td>-1.818182</td>\n",
       "      <td>-1.620202</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>122728</td>\n",
       "      <td>0</td>\n",
       "      <td>122728</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018965</td>\n",
       "      <td>15.620097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Symbolic</td>\n",
       "      <td>[[CONSTANT, CONSTANT]]</td>\n",
       "      <td>[-1, 1]</td>\n",
       "      <td>UNIFORM</td>\n",
       "      <td>[[UNIFORM, 4, 4], [UNIFORM, 3, 3]]</td>\n",
       "      <td>None</td>\n",
       "      <td>NO_OVERLAPPING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cd6a3_00003</th>\n",
       "      <td>2.974000</td>\n",
       "      <td>-1.727273</td>\n",
       "      <td>-0.353490</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>137712</td>\n",
       "      <td>0</td>\n",
       "      <td>137712</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024227</td>\n",
       "      <td>13.747019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Symbolic</td>\n",
       "      <td>[[CONSTANT, CONSTANT]]</td>\n",
       "      <td>[-1, 1]</td>\n",
       "      <td>UNIFORM</td>\n",
       "      <td>[[UNIFORM, 4, 4], [UNIFORM, 3, 3]]</td>\n",
       "      <td>None</td>\n",
       "      <td>NO_OVERLAPPING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cd6a3_00002</th>\n",
       "      <td>-1.333333</td>\n",
       "      <td>-1.818182</td>\n",
       "      <td>-1.583586</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>126256</td>\n",
       "      <td>0</td>\n",
       "      <td>126256</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015725</td>\n",
       "      <td>15.986398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Symbolic</td>\n",
       "      <td>[[CONSTANT, CONSTANT]]</td>\n",
       "      <td>[-1, 1]</td>\n",
       "      <td>UNIFORM</td>\n",
       "      <td>[[UNIFORM, 4, 4], [UNIFORM, 3, 3]]</td>\n",
       "      <td>None</td>\n",
       "      <td>NO_OVERLAPPING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             episode_reward_max  episode_reward_min  episode_reward_mean  \\\n",
       "trial_id                                                                   \n",
       "cd6a3_00000            2.814000           -1.750000            -0.916221   \n",
       "cd6a3_00007           -1.400000           -1.636364            -1.533144   \n",
       "cd6a3_00001            2.984000           -1.666667            -0.632934   \n",
       "cd6a3_00006           -1.333333           -1.600000            -1.477904   \n",
       "cd6a3_00005           -1.333333           -1.666667            -1.472348   \n",
       "cd6a3_00004           -1.333333           -1.818182            -1.620202   \n",
       "cd6a3_00003            2.974000           -1.727273            -0.353490   \n",
       "cd6a3_00002           -1.333333           -1.818182            -1.583586   \n",
       "\n",
       "             episode_len_mean  episodes_this_iter  num_healthy_workers  \\\n",
       "trial_id                                                                 \n",
       "cd6a3_00000        914.230769                   0                    4   \n",
       "cd6a3_00007       1001.000000                   0                    4   \n",
       "cd6a3_00001        865.357143                   5                    4   \n",
       "cd6a3_00006       1001.000000                   0                    4   \n",
       "cd6a3_00005       1001.000000                   0                    4   \n",
       "cd6a3_00004       1001.000000                   4                    4   \n",
       "cd6a3_00003        787.000000                   0                    4   \n",
       "cd6a3_00002       1001.000000                   4                    4   \n",
       "\n",
       "             timesteps_total  timesteps_this_iter  agent_timesteps_total  \\\n",
       "trial_id                                                                   \n",
       "cd6a3_00000           117240                    0                 117240   \n",
       "cd6a3_00007           149472                    0                 149472   \n",
       "cd6a3_00001           133776                    0                 133776   \n",
       "cd6a3_00006           144952                    0                 144952   \n",
       "cd6a3_00005           135744                    0                 135744   \n",
       "cd6a3_00004           122728                    0                 122728   \n",
       "cd6a3_00003           137712                    0                 137712   \n",
       "cd6a3_00002           126256                    0                 126256   \n",
       "\n",
       "              done  ...  info.learner.default_policy.learner_stats.kl  \\\n",
       "trial_id            ...                                                 \n",
       "cd6a3_00000  False  ...                                      0.004712   \n",
       "cd6a3_00007  False  ...                                      0.023853   \n",
       "cd6a3_00001  False  ...                                      0.008617   \n",
       "cd6a3_00006  False  ...                                      0.013828   \n",
       "cd6a3_00005  False  ...                                      0.009497   \n",
       "cd6a3_00004  False  ...                                      0.018965   \n",
       "cd6a3_00003  False  ...                                      0.024227   \n",
       "cd6a3_00002  False  ...                                      0.015725   \n",
       "\n",
       "             info.learner.default_policy.learner_stats.entropy  \\\n",
       "trial_id                                                         \n",
       "cd6a3_00000                                          16.667426   \n",
       "cd6a3_00007                                          12.915991   \n",
       "cd6a3_00001                                          13.219076   \n",
       "cd6a3_00006                                          13.013030   \n",
       "cd6a3_00005                                          13.675836   \n",
       "cd6a3_00004                                          15.620097   \n",
       "cd6a3_00003                                          13.747019   \n",
       "cd6a3_00002                                          15.986398   \n",
       "\n",
       "            info.learner.default_policy.learner_stats.entropy_coeff  \\\n",
       "trial_id                                                              \n",
       "cd6a3_00000                                                0.0        \n",
       "cd6a3_00007                                                0.0        \n",
       "cd6a3_00001                                                0.0        \n",
       "cd6a3_00006                                                0.0        \n",
       "cd6a3_00005                                                0.0        \n",
       "cd6a3_00004                                                0.0        \n",
       "cd6a3_00003                                                0.0        \n",
       "cd6a3_00002                                                0.0        \n",
       "\n",
       "            config.env_config.dataset_settings.dstype.value  \\\n",
       "trial_id                                                      \n",
       "cd6a3_00000                                        Symbolic   \n",
       "cd6a3_00007                                        Symbolic   \n",
       "cd6a3_00001                                        Symbolic   \n",
       "cd6a3_00006                                        Symbolic   \n",
       "cd6a3_00005                                        Symbolic   \n",
       "cd6a3_00004                                        Symbolic   \n",
       "cd6a3_00003                                        Symbolic   \n",
       "cd6a3_00002                                        Symbolic   \n",
       "\n",
       "             config.env_config.dataset_settings.patterns.value  \\\n",
       "trial_id                                                         \n",
       "cd6a3_00000                             [[CONSTANT, CONSTANT]]   \n",
       "cd6a3_00007                             [[CONSTANT, CONSTANT]]   \n",
       "cd6a3_00001                             [[CONSTANT, CONSTANT]]   \n",
       "cd6a3_00006                             [[CONSTANT, CONSTANT]]   \n",
       "cd6a3_00005                             [[CONSTANT, CONSTANT]]   \n",
       "cd6a3_00004                             [[CONSTANT, CONSTANT]]   \n",
       "cd6a3_00003                             [[CONSTANT, CONSTANT]]   \n",
       "cd6a3_00002                             [[CONSTANT, CONSTANT]]   \n",
       "\n",
       "             config.env_config.dataset_settings.symbols.value  \\\n",
       "trial_id                                                        \n",
       "cd6a3_00000                                           [-1, 1]   \n",
       "cd6a3_00007                                           [-1, 1]   \n",
       "cd6a3_00001                                           [-1, 1]   \n",
       "cd6a3_00006                                           [-1, 1]   \n",
       "cd6a3_00005                                           [-1, 1]   \n",
       "cd6a3_00004                                           [-1, 1]   \n",
       "cd6a3_00003                                           [-1, 1]   \n",
       "cd6a3_00002                                           [-1, 1]   \n",
       "\n",
       "             config.env_config.dataset_settings.bktype.value  \\\n",
       "trial_id                                                       \n",
       "cd6a3_00000                                          UNIFORM   \n",
       "cd6a3_00007                                          UNIFORM   \n",
       "cd6a3_00001                                          UNIFORM   \n",
       "cd6a3_00006                                          UNIFORM   \n",
       "cd6a3_00005                                          UNIFORM   \n",
       "cd6a3_00004                                          UNIFORM   \n",
       "cd6a3_00003                                          UNIFORM   \n",
       "cd6a3_00002                                          UNIFORM   \n",
       "\n",
       "             config.env_config.dataset_settings.clusterdistribution.value  \\\n",
       "trial_id                                                                    \n",
       "cd6a3_00000                 [[UNIFORM, 4, 4], [UNIFORM, 3, 3]]              \n",
       "cd6a3_00007                 [[UNIFORM, 4, 4], [UNIFORM, 3, 3]]              \n",
       "cd6a3_00001                 [[UNIFORM, 4, 4], [UNIFORM, 3, 3]]              \n",
       "cd6a3_00006                 [[UNIFORM, 4, 4], [UNIFORM, 3, 3]]              \n",
       "cd6a3_00005                 [[UNIFORM, 4, 4], [UNIFORM, 3, 3]]              \n",
       "cd6a3_00004                 [[UNIFORM, 4, 4], [UNIFORM, 3, 3]]              \n",
       "cd6a3_00003                 [[UNIFORM, 4, 4], [UNIFORM, 3, 3]]              \n",
       "cd6a3_00002                 [[UNIFORM, 4, 4], [UNIFORM, 3, 3]]              \n",
       "\n",
       "            config.env_config.dataset_settings.contiguity.value  \\\n",
       "trial_id                                                          \n",
       "cd6a3_00000                                               None    \n",
       "cd6a3_00007                                               None    \n",
       "cd6a3_00001                                               None    \n",
       "cd6a3_00006                                               None    \n",
       "cd6a3_00005                                               None    \n",
       "cd6a3_00004                                               None    \n",
       "cd6a3_00003                                               None    \n",
       "cd6a3_00002                                               None    \n",
       "\n",
       "            config.env_config.dataset_settings.plaidcoherency.value  \n",
       "trial_id                                                             \n",
       "cd6a3_00000                                     NO_OVERLAPPING       \n",
       "cd6a3_00007                                     NO_OVERLAPPING       \n",
       "cd6a3_00001                                     NO_OVERLAPPING       \n",
       "cd6a3_00006                                     NO_OVERLAPPING       \n",
       "cd6a3_00005                                     NO_OVERLAPPING       \n",
       "cd6a3_00004                                     NO_OVERLAPPING       \n",
       "cd6a3_00003                                     NO_OVERLAPPING       \n",
       "cd6a3_00002                                     NO_OVERLAPPING       \n",
       "\n",
       "[8 rows x 208 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get report config\n",
    "\n",
    "analysis = ExperimentAnalysis('/home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_config_v2_hypertune/sample_0/PPO_2022-03-08_19-13-14')\n",
    "\n",
    "analysis.results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Trial:  PPO_BiclusterEnv-v0_cd6a3_00003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_config_v2_hypertune/sample_0/PPO_2022-03-08_19-13-14/PPO_BiclusterEnv-v0_cd6a3_00003_3_2022-03-08_19-17-55/checkpoint_000030/checkpoint-30'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trial = analysis.get_best_trial(metric='episode_reward_mean', mode='max')\n",
    "print('Best Trial: ', best_trial)\n",
    "\n",
    "# best checkpoint\n",
    "\n",
    "analysis.get_best_checkpoint(trial=best_trial, metric='episode_reward_mean', mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_workers': 4,\n",
       " 'create_env_on_driver': False,\n",
       " 'num_envs_per_worker': 1,\n",
       " 'batch_mode': 'truncate_episodes',\n",
       " 'gamma': 0.99,\n",
       " 'use_critic': True,\n",
       " 'use_gae': True,\n",
       " 'lambda': 0.6400000000000001,\n",
       " 'kl_coeff': 0.192,\n",
       " 'rollout_fragment_length': 256,\n",
       " 'train_batch_size': 982,\n",
       " 'sgd_minibatch_size': 122,\n",
       " 'shuffle_sequences': True,\n",
       " 'num_sgd_iter': 19,\n",
       " 'lr': 5e-05,\n",
       " 'lr_schedule': None,\n",
       " 'vf_loss_coeff': 0.96,\n",
       " 'entropy_coeff': 0.0,\n",
       " 'entropy_coeff_schedule': None,\n",
       " 'clip_param': 0.432,\n",
       " 'vf_clip_param': 14.399999999999999,\n",
       " 'grad_clip': None,\n",
       " 'kl_target': 0.0096,\n",
       " 'optimizer': {},\n",
       " 'horizon': None,\n",
       " 'soft_horizon': False,\n",
       " 'no_done_at_end': False,\n",
       " 'env': 'BiclusterEnv-v0',\n",
       " 'observation_space': None,\n",
       " 'action_space': None,\n",
       " 'env_config': {'shape': [[6, 6], [6, 6]],\n",
       "  'n': 1,\n",
       "  'clusters': [1, 1],\n",
       "  'dataset_settings': {'dstype': {'value': 'Symbolic'},\n",
       "   'patterns': {'value': [['CONSTANT', 'CONSTANT']]},\n",
       "   'symbols': {'value': [-1, 1]},\n",
       "   'bktype': {'value': 'UNIFORM'},\n",
       "   'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]},\n",
       "   'contiguity': {'value': None},\n",
       "   'plaidcoherency': {'value': 'NO_OVERLAPPING'}},\n",
       "  'max_steps': 1000,\n",
       "  'seed': 175},\n",
       " 'env_task_fn': None,\n",
       " 'render_env': False,\n",
       " 'record_env': False,\n",
       " 'clip_rewards': False,\n",
       " 'normalize_actions': True,\n",
       " 'preprocessor_pref': None,\n",
       " 'log_level': 'DEBUG',\n",
       " 'ignore_worker_failures': False,\n",
       " 'log_sys_usage': True,\n",
       " 'framework': 'torch',\n",
       " 'eager_tracing': False,\n",
       " 'explore': True,\n",
       " 'exploration_config': {'type': 'StochasticSampling'},\n",
       " 'evaluation_interval': None,\n",
       " 'evaluation_num_episodes': 10,\n",
       " 'evaluation_parallel_to_training': False,\n",
       " 'in_evaluation': False,\n",
       " 'evaluation_config': {'explore': False},\n",
       " 'evaluation_num_workers': 0,\n",
       " 'custom_eval_function': None,\n",
       " 'sample_async': False,\n",
       " 'observation_filter': 'NoFilter',\n",
       " 'synchronize_filters': True,\n",
       " 'compress_observations': False,\n",
       " 'collect_metrics_timeout': 180,\n",
       " 'metrics_smoothing_episodes': 100,\n",
       " 'min_iter_time_s': 0,\n",
       " 'timesteps_per_iteration': 0,\n",
       " 'seed': 175,\n",
       " 'extra_python_environs_for_driver': {},\n",
       " 'extra_python_environs_for_worker': {},\n",
       " 'num_gpus': 0.0001,\n",
       " '_fake_gpus': False,\n",
       " 'num_cpus_per_worker': 1,\n",
       " 'num_gpus_per_worker': 0.24975,\n",
       " 'custom_resources_per_worker': {},\n",
       " 'num_cpus_for_driver': 1,\n",
       " 'placement_strategy': 'PACK',\n",
       " 'logger_config': None,\n",
       " '_disable_preprocessor_api': True,\n",
       " 'model': {'custom_model': 'general_model_torch',\n",
       "  'custom_model_config': {'fcnet_feats': [256, 256]},\n",
       "  'custom_action_dist': None}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0308 23:39:39.764528120 1987670 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646782779.764462976\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646782779.764450883\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get best config\n",
    "\n",
    "tunned_config = analysis.get_best_config(metric='episode_reward_mean', mode='max', scope='all')\n",
    "\n",
    "configs = TrainerConfig('tunned_configs', '/home/pgcotovio/repos/nclustRL/Exp/test_framework2')\n",
    "configs.save(tunned_config)\n",
    "\n",
    "tunned_config = configs.load()\n",
    "tunned_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train basic_v2 (untunned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 15:39:23,678\tINFO ppo.py:166 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4722)\u001b[0m 2022-03-09 15:39:27,477\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4716)\u001b[0m 2022-03-09 15:39:27,583\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4711)\u001b[0m 2022-03-09 15:39:27,609\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4723)\u001b[0m 2022-03-09 15:39:27,634\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4722)\u001b[0m 2022-03-09 15:39:31,949\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4722)\u001b[0m 2022-03-09 15:39:31,949\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4716)\u001b[0m 2022-03-09 15:39:32,073\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4716)\u001b[0m 2022-03-09 15:39:32,073\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4723)\u001b[0m 2022-03-09 15:39:32,052\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4723)\u001b[0m 2022-03-09 15:39:32,052\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4722)\u001b[0m 2022-03-09 15:39:32,111\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4722)\u001b[0m 2022-03-09 15:39:32,121\tINFO torch_policy.py:186 -- TorchPolicy (worker=2) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4722)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4722)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4711)\u001b[0m 2022-03-09 15:39:32,101\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4711)\u001b[0m 2022-03-09 15:39:32,101\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4716)\u001b[0m 2022-03-09 15:39:32,218\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4716)\u001b[0m 2022-03-09 15:39:32,220\tINFO torch_policy.py:186 -- TorchPolicy (worker=4) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4716)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4716)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4711)\u001b[0m 2022-03-09 15:39:32,247\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4711)\u001b[0m 2022-03-09 15:39:32,250\tINFO torch_policy.py:186 -- TorchPolicy (worker=3) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4711)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4711)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4723)\u001b[0m 2022-03-09 15:39:32,197\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4723)\u001b[0m 2022-03-09 15:39:32,200\tINFO torch_policy.py:186 -- TorchPolicy (worker=1) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4723)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4723)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4722)\u001b[0m 2022-03-09 15:39:33,054\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7fdf50790640> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "2022-03-09 15:39:33,097\tINFO worker_set.py:104 -- Inferred observation/action spaces from remote worker (local worker has no env): {'default_policy': (Dict(action_mask:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), avail_actions:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), state:Box([6 6], [6 6], (2,), int32)), Tuple(Discrete(4), Tuple(Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32)))), '__env__': (Dict(action_mask:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), avail_actions:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), state:Box([6 6], [6 6], (2,), int32)), Tuple(Discrete(4), Tuple(Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32))))}\n",
      "2022-03-09 15:39:33,098\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "2022-03-09 15:39:33,101\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "2022-03-09 15:39:33,125\tINFO torch_policy.py:186 -- TorchPolicy (worker=local) running on 0.0001 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4711)\u001b[0m 2022-03-09 15:39:33,182\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7fc810fa2e80> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4723)\u001b[0m 2022-03-09 15:39:33,090\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7fc4a5371e80> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4716)\u001b[0m 2022-03-09 15:39:33,190\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7fb4e96cae80> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "/home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "  warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "2022-03-09 15:39:36,884\tINFO rollout_worker.py:1555 -- Built policy map: {}\n",
      "2022-03-09 15:39:36,885\tINFO rollout_worker.py:1556 -- Built preprocessor map: {'default_policy': None}\n",
      "2022-03-09 15:39:36,885\tINFO rollout_worker.py:618 -- Built filter map: {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x7f478c0571c0>}\n",
      "2022-03-09 15:39:36,885\tDEBUG rollout_worker.py:728 -- Created rollout worker with env None (None), policies {}\n",
      "2022-03-09 15:39:36,889\tINFO trainable.py:124 -- Trainable.setup took 13.212 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    }
   ],
   "source": [
    "config = DEFAULT_CONFIG.copy()\n",
    "config['env_config'] = biclustering.binary.basic_v2\n",
    "\n",
    "trainer_basic_v2_unttuned = Trainer(\n",
    "    trainer=PPOTrainer,\n",
    "    env='BiclusterEnv-v0',\n",
    "    save_dir='/home/pedro.cotovio/Repos/nclustRL/Exp/test_framework2',\n",
    "    name='basic_v2_config',\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test random agent in basic_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 of 100 done.\n",
      "Episode 2 of 100 done.\n",
      "Episode 3 of 100 done.\n",
      "Episode 4 of 100 done.\n",
      "Episode 5 of 100 done.\n",
      "Episode 6 of 100 done.\n",
      "Episode 7 of 100 done.\n",
      "Episode 8 of 100 done.\n",
      "Episode 9 of 100 done.\n",
      "Episode 10 of 100 done.\n",
      "Episode 11 of 100 done.\n",
      "Episode 12 of 100 done.\n",
      "Episode 13 of 100 done.\n",
      "Episode 14 of 100 done.\n",
      "Episode 15 of 100 done.\n",
      "Episode 16 of 100 done.\n",
      "Episode 17 of 100 done.\n",
      "Episode 18 of 100 done.\n",
      "Episode 19 of 100 done.\n",
      "Episode 20 of 100 done.\n",
      "Episode 21 of 100 done.\n",
      "Episode 22 of 100 done.\n",
      "Episode 23 of 100 done.\n",
      "Episode 24 of 100 done.\n",
      "Episode 25 of 100 done.\n",
      "Episode 26 of 100 done.\n",
      "Episode 27 of 100 done.\n",
      "Episode 28 of 100 done.\n",
      "Episode 29 of 100 done.\n",
      "Episode 30 of 100 done.\n",
      "Episode 31 of 100 done.\n",
      "Episode 32 of 100 done.\n",
      "Episode 33 of 100 done.\n",
      "Episode 34 of 100 done.\n",
      "Episode 35 of 100 done.\n",
      "Episode 36 of 100 done.\n",
      "Episode 37 of 100 done.\n",
      "Episode 38 of 100 done.\n",
      "Episode 39 of 100 done.\n",
      "Episode 40 of 100 done.\n",
      "Episode 41 of 100 done.\n",
      "Episode 42 of 100 done.\n",
      "Episode 43 of 100 done.\n",
      "Episode 44 of 100 done.\n",
      "Episode 45 of 100 done.\n",
      "Episode 46 of 100 done.\n",
      "Episode 47 of 100 done.\n",
      "Episode 48 of 100 done.\n",
      "Episode 49 of 100 done.\n",
      "Episode 50 of 100 done.\n",
      "Episode 51 of 100 done.\n",
      "Episode 52 of 100 done.\n",
      "Episode 53 of 100 done.\n",
      "Episode 54 of 100 done.\n",
      "Episode 55 of 100 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0308 18:06:23.020850822 1634541 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646762783.020810606\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646762783.020806418\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 56 of 100 done.\n",
      "Episode 57 of 100 done.\n",
      "Episode 58 of 100 done.\n",
      "Episode 59 of 100 done.\n",
      "Episode 60 of 100 done.\n",
      "Episode 61 of 100 done.\n",
      "Episode 62 of 100 done.\n",
      "Episode 63 of 100 done.\n",
      "Episode 64 of 100 done.\n",
      "Episode 65 of 100 done.\n",
      "Episode 66 of 100 done.\n",
      "Episode 67 of 100 done.\n",
      "Episode 68 of 100 done.\n",
      "Episode 69 of 100 done.\n",
      "Episode 70 of 100 done.\n",
      "Episode 71 of 100 done.\n",
      "Episode 72 of 100 done.\n",
      "Episode 73 of 100 done.\n",
      "Episode 74 of 100 done.\n",
      "Episode 75 of 100 done.\n",
      "Episode 76 of 100 done.\n",
      "Episode 77 of 100 done.\n",
      "Episode 78 of 100 done.\n",
      "Episode 79 of 100 done.\n",
      "Episode 80 of 100 done.\n",
      "Episode 81 of 100 done.\n",
      "Episode 82 of 100 done.\n",
      "Episode 83 of 100 done.\n",
      "Episode 84 of 100 done.\n",
      "Episode 85 of 100 done.\n",
      "Episode 86 of 100 done.\n",
      "Episode 87 of 100 done.\n",
      "Episode 88 of 100 done.\n",
      "Episode 89 of 100 done.\n",
      "Episode 90 of 100 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0308 18:09:33.020125599 1636284 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646762973.020087757\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646762973.020083309\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 91 of 100 done.\n",
      "Episode 92 of 100 done.\n",
      "Episode 93 of 100 done.\n",
      "Episode 94 of 100 done.\n",
      "Episode 95 of 100 done.\n",
      "Episode 96 of 100 done.\n",
      "Episode 97 of 100 done.\n",
      "Episode 98 of 100 done.\n",
      "Episode 99 of 100 done.\n",
      "Episode 100 of 100 done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1.9785714285714295, 0.09571428571428567)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0308 18:12:58.020116907 1638588 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646763178.020077823\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646763178.020073936\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0308 18:17:58.123134152 1641334 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646763478.123094407\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646763478.123090360\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n"
     ]
    }
   ],
   "source": [
    "trainer_basic_v2_unttuned.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-06 18:49:58 (running for 04:31:07.40)<br>Memory usage on this node: 14.2/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 1.0/1 GPUs, 0.0/7.92 GiB heap, 0.0/3.96 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: 58725_00000 with episode_reward_mean=-1.2226448484848493 and parameters={'num_workers': 3, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 341, 'batch_mode': 'truncate_episodes', 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 1024, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': True, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'general_model_torch', 'custom_model_config': {'fcnet_feats': [256, 256]}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'BiclusterEnv-v0', 'observation_space': None, 'action_space': None, 'env_config': {'shape': [[6, 6], [6, 6]], 'n': 1, 'clusters': [1, 1], 'dataset_settings': {'dstype': {'value': 'Symbolic'}, 'patterns': {'value': [['CONSTANT', 'CONSTANT']]}, 'symbols': {'value': [-1, 1]}, 'bktype': {'value': 'UNIFORM'}, 'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]}, 'contiguity': {'value': None}, 'plaidcoherency': {'value': 'NO_OVERLAPPING'}}, 'max_steps': 1000, 'seed': 537}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': False, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': None, 'log_level': 'DEBUG', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': 537, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0.0001, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.3333, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'default_policy': PolicySpec(policy_class=<class 'ray.rllib.agents.ppo.ppo_torch_policy.PPOTorchPolicy'>, observation_space=None, action_space=None, config={})}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': True, 'simple_optimizer': False, 'monitor': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1}<br>Result logdir: /home/pedro.cotovio/Repos/nclustRL/Exp/test_framework2/basic_v2_config/sample_0/PPO_2022-03-06_14-18-50<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_checkpoint = trainer_basic_v2_unttuned.train(stop_iters=1000)\n",
    "best_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load and test trained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 15:47:17,126\tINFO trainable.py:467 -- Restored on 10.20.0.204 from checkpoint: /home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_v2_config/sample_0/PPO_2022-03-06_14-18-50/PPO_BiclusterEnv-v0_58725_00000_0_2022-03-06_14-18-50/checkpoint_000490/checkpoint-490\n",
      "2022-03-09 15:47:17,127\tINFO trainable.py:475 -- Current state after restoring: {'_iteration': 490, '_timesteps_total': 0, '_time_total': 16062.447478532791, '_episodes_total': 1049}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 of 100 done.\n",
      "Episode 2 of 100 done.\n",
      "Episode 3 of 100 done.\n",
      "Episode 4 of 100 done.\n",
      "Episode 5 of 100 done.\n",
      "Episode 6 of 100 done.\n",
      "Episode 7 of 100 done.\n",
      "Episode 8 of 100 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0309 15:48:03.370082217   10777 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646840883.370034517\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646840883.370029768\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 9 of 100 done.\n",
      "Episode 10 of 100 done.\n",
      "Episode 11 of 100 done.\n",
      "Episode 12 of 100 done.\n",
      "Episode 13 of 100 done.\n",
      "Episode 14 of 100 done.\n",
      "Episode 15 of 100 done.\n",
      "Episode 16 of 100 done.\n",
      "Episode 17 of 100 done.\n",
      "Episode 18 of 100 done.\n",
      "Episode 19 of 100 done.\n",
      "Episode 20 of 100 done.\n",
      "Episode 21 of 100 done.\n",
      "Episode 22 of 100 done.\n",
      "Episode 23 of 100 done.\n",
      "Episode 24 of 100 done.\n",
      "Episode 25 of 100 done.\n",
      "Episode 26 of 100 done.\n",
      "Episode 27 of 100 done.\n",
      "Episode 28 of 100 done.\n",
      "Episode 29 of 100 done.\n",
      "Episode 30 of 100 done.\n",
      "Episode 31 of 100 done.\n",
      "Episode 32 of 100 done.\n",
      "Episode 33 of 100 done.\n",
      "Episode 34 of 100 done.\n",
      "Episode 35 of 100 done.\n",
      "Episode 36 of 100 done.\n",
      "Episode 37 of 100 done.\n",
      "Episode 38 of 100 done.\n",
      "Episode 39 of 100 done.\n",
      "Episode 40 of 100 done.\n",
      "Episode 41 of 100 done.\n",
      "Episode 42 of 100 done.\n",
      "Episode 43 of 100 done.\n",
      "Episode 44 of 100 done.\n",
      "Episode 45 of 100 done.\n",
      "Episode 46 of 100 done.\n",
      "Episode 47 of 100 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0309 15:51:38.386848634   12831 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646841098.386796735\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646841098.386792077\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 48 of 100 done.\n",
      "Episode 49 of 100 done.\n",
      "Episode 50 of 100 done.\n",
      "Episode 51 of 100 done.\n",
      "Episode 52 of 100 done.\n",
      "Episode 53 of 100 done.\n",
      "Episode 54 of 100 done.\n",
      "Episode 55 of 100 done.\n",
      "Episode 56 of 100 done.\n",
      "Episode 57 of 100 done.\n",
      "Episode 58 of 100 done.\n",
      "Episode 59 of 100 done.\n",
      "Episode 60 of 100 done.\n",
      "Episode 61 of 100 done.\n",
      "Episode 62 of 100 done.\n",
      "Episode 63 of 100 done.\n",
      "Episode 64 of 100 done.\n",
      "Episode 65 of 100 done.\n",
      "Episode 66 of 100 done.\n",
      "Episode 67 of 100 done.\n",
      "Episode 68 of 100 done.\n",
      "Episode 69 of 100 done.\n",
      "Episode 70 of 100 done.\n",
      "Episode 71 of 100 done.\n",
      "Episode 72 of 100 done.\n",
      "Episode 73 of 100 done.\n",
      "Episode 74 of 100 done.\n",
      "Episode 75 of 100 done.\n",
      "Episode 76 of 100 done.\n",
      "Episode 77 of 100 done.\n",
      "Episode 78 of 100 done.\n",
      "Episode 79 of 100 done.\n",
      "Episode 80 of 100 done.\n",
      "Episode 81 of 100 done.\n",
      "Episode 82 of 100 done.\n",
      "Episode 83 of 100 done.\n",
      "Episode 84 of 100 done.\n",
      "Episode 85 of 100 done.\n",
      "Episode 86 of 100 done.\n",
      "Episode 87 of 100 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0309 15:55:23.410429017   15005 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646841323.410361048\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646841323.410355969\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 88 of 100 done.\n",
      "Episode 89 of 100 done.\n",
      "Episode 90 of 100 done.\n",
      "Episode 91 of 100 done.\n",
      "Episode 92 of 100 done.\n",
      "Episode 93 of 100 done.\n",
      "Episode 94 of 100 done.\n",
      "Episode 95 of 100 done.\n",
      "Episode 96 of 100 done.\n",
      "Episode 97 of 100 done.\n",
      "Episode 98 of 100 done.\n",
      "Episode 99 of 100 done.\n",
      "Episode 100 of 100 done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1.9026785714285723, 0.09874999999999996)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0309 15:56:48.409935153   16196 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646841408.409886831\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646841408.409882673\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n"
     ]
    }
   ],
   "source": [
    "# load agent\n",
    "trainer_basic_v2_unttuned.load('/home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_v2_config/sample_0/PPO_2022-03-06_14-18-50/PPO_BiclusterEnv-v0_58725_00000_0_2022-03-06_14-18-50/checkpoint_000490/checkpoint-490')\n",
    "\n",
    "# test agent\n",
    "trainer_basic_v2_unttuned.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train basic_v2 (tunned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 15:59:54,484\tWARNING ppo.py:143 -- `train_batch_size` (982) cannot be achieved with your other settings (num_workers=4 num_envs_per_worker=1 rollout_fragment_length=256)! Auto-adjusting `rollout_fragment_length` to 245.\n",
      "2022-03-09 15:59:54,484\tINFO ppo.py:166 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18067)\u001b[0m 2022-03-09 15:59:58,394\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18063)\u001b[0m 2022-03-09 15:59:58,476\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18072)\u001b[0m 2022-03-09 15:59:58,556\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18070)\u001b[0m 2022-03-09 15:59:58,908\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18067)\u001b[0m 2022-03-09 16:00:02,769\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18067)\u001b[0m 2022-03-09 16:00:02,769\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18063)\u001b[0m 2022-03-09 16:00:02,885\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18063)\u001b[0m 2022-03-09 16:00:02,886\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18072)\u001b[0m 2022-03-09 16:00:02,814\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18072)\u001b[0m 2022-03-09 16:00:02,815\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18067)\u001b[0m 2022-03-09 16:00:02,928\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18067)\u001b[0m 2022-03-09 16:00:02,931\tINFO torch_policy.py:186 -- TorchPolicy (worker=4) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18067)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18067)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18072)\u001b[0m 2022-03-09 16:00:02,973\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18072)\u001b[0m 2022-03-09 16:00:02,977\tINFO torch_policy.py:186 -- TorchPolicy (worker=1) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18072)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18072)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18070)\u001b[0m 2022-03-09 16:00:03,000\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18070)\u001b[0m 2022-03-09 16:00:03,001\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18063)\u001b[0m 2022-03-09 16:00:03,035\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18063)\u001b[0m 2022-03-09 16:00:03,037\tINFO torch_policy.py:186 -- TorchPolicy (worker=3) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18063)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18063)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18070)\u001b[0m 2022-03-09 16:00:03,152\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18070)\u001b[0m 2022-03-09 16:00:03,156\tINFO torch_policy.py:186 -- TorchPolicy (worker=2) running on 0.24975 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18070)\u001b[0m /home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18070)\u001b[0m   warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "2022-03-09 16:00:03,906\tINFO worker_set.py:104 -- Inferred observation/action spaces from remote worker (local worker has no env): {'default_policy': (Dict(action_mask:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), avail_actions:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), state:Box([6 6], [6 6], (2,), int32)), Tuple(Discrete(4), Tuple(Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32)))), '__env__': (Dict(action_mask:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), avail_actions:Box([0. 0. 0. 0.], [1. 1. 1. 1.], (4,), float32), state:Box([6 6], [6 6], (2,), int32)), Tuple(Discrete(4), Tuple(Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32), Box([0. 0. 0.], [1. 1. 1.], (3,), float32))))}\n",
      "2022-03-09 16:00:03,907\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      "2022-03-09 16:00:03,911\tINFO catalog.py:410 -- Wrapping <class 'nclustRL.models.model.RlModel'> as None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18067)\u001b[0m 2022-03-09 16:00:03,817\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7fbc71417cd0> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18072)\u001b[0m 2022-03-09 16:00:03,899\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f48b42e3520> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "2022-03-09 16:00:03,932\tINFO torch_policy.py:186 -- TorchPolicy (worker=local) running on 0.0001 GPU(s).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18063)\u001b[0m 2022-03-09 16:00:03,927\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f1cec511520> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18070)\u001b[0m 2022-03-09 16:00:04,040\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f1b85fc6cd0> (<TransformObservation<OrderEnforcing<BiclusterEnv<BiclusterEnv-v0>>>>), policies {}\n",
      "/home/pgcotovio/repos/nclustRL/nclustRL/models/model.py:147: UserWarning: Forward is running with random obs, this should only be acceptable during policy inicialization.\n",
      "  warnings.warn('Forward is running with random obs, this should only be acceptable during policy inicialization.')\n",
      "2022-03-09 16:00:07,758\tINFO rollout_worker.py:1555 -- Built policy map: {}\n",
      "2022-03-09 16:00:07,759\tINFO rollout_worker.py:1556 -- Built preprocessor map: {'default_policy': None}\n",
      "2022-03-09 16:00:07,759\tINFO rollout_worker.py:618 -- Built filter map: {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x7fe904bfa580>}\n",
      "2022-03-09 16:00:07,760\tDEBUG rollout_worker.py:728 -- Created rollout worker with env None (None), policies {}\n",
      "2022-03-09 16:00:07,762\tINFO trainable.py:124 -- Trainable.setup took 13.281 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    }
   ],
   "source": [
    "# Inicilize\n",
    "\n",
    "configs = TrainerConfig('tunned_configs', '/home/pgcotovio/repos/nclustRL/Exp/test_framework2')\n",
    "tunned_config = configs.load()\n",
    "\n",
    "trainer_basic_v2_tunned = Trainer(\n",
    "    trainer=PPOTrainer,\n",
    "    env='BiclusterEnv-v0',\n",
    "    save_dir='/home/pgcotovio/repos/nclustRL/Exp/test_framework2',\n",
    "    name='basic_v2_tunned_config',\n",
    "    config=tunned_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-09 04:55:08 (running for 05:12:04.55)<br>Memory usage on this node: 40.4/62.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/2 GPUs, 0.0/31.03 GiB heap, 0.0/15.52 GiB objects<br>Current best trial: 7f365_00000 with episode_reward_mean=-1.4001847474747484 and parameters={'num_workers': 4, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 245, 'batch_mode': 'truncate_episodes', 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 982, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': True, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'general_model_torch', 'custom_model_config': {'fcnet_feats': [256, 256]}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'BiclusterEnv-v0', 'observation_space': None, 'action_space': None, 'env_config': {'shape': [[6, 6], [6, 6]], 'n': 1, 'clusters': [1, 1], 'dataset_settings': {'dstype': {'value': 'Symbolic'}, 'patterns': {'value': [['CONSTANT', 'CONSTANT']]}, 'symbols': {'value': [-1, 1]}, 'bktype': {'value': 'UNIFORM'}, 'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]}, 'contiguity': {'value': None}, 'plaidcoherency': {'value': 'NO_OVERLAPPING'}}, 'max_steps': 1000, 'seed': 175}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': False, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': None, 'log_level': 'DEBUG', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': 175, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0.0001, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.24975, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'default_policy': PolicySpec(policy_class=<class 'ray.rllib.agents.ppo.ppo_torch_policy.PPOTorchPolicy'>, observation_space=None, action_space=None, config={})}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': True, 'simple_optimizer': False, 'monitor': -1, 'use_critic': True, 'use_gae': True, 'lambda': 0.6400000000000001, 'kl_coeff': 0.192, 'sgd_minibatch_size': 122, 'shuffle_sequences': True, 'num_sgd_iter': 19, 'lr_schedule': None, 'vf_loss_coeff': 0.96, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.432, 'vf_clip_param': 14.399999999999999, 'grad_clip': None, 'kl_target': 0.0096, 'vf_share_layers': -1}<br>Result logdir: /home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_v2_tunned_config/sample_0/PPO_2022-03-08_23-43-03<br>Number of trials: 1/1 (1 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 04:55:08,873\tINFO tune.py:626 -- Total run time: 18725.09 seconds (18724.49 seconds for the tuning loop).\n",
      "Sample 1: : 1sample [5:12:05, 18725.13s/sample, metric={'episode_reward_max': 2.679, 'episode_reward_min': -1.6666666666666676, 'episode_reward_mean': -1.4001847474747484, 'episode_len_mean': 994.2, 'episode_media': {}, 'episodes_this_iter': 3, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-1.3636363636363646, -1.3636363636363646, -1.5000000000000009, -1.4166666666666674, -1.5454545454545463, -1.3636363636363646, -1.4166666666666674, -1.5000000000000009, -1.3636363636363646, -1.5833333333333341, -1.3636363636363646, -1.5833333333333341, -1.5000000000000009, -1.300000000000001, -1.5833333333333341, -1.5000000000000009, -1.3636363636363646, -1.3636363636363646, -1.3636363636363646, -1.3636363636363646, -1.5000000000000009, -1.3636363636363646, -1.5000000000000009, -1.6666666666666676, -1.4000000000000008, -1.4545454545454555, -1.5833333333333341, -1.5000000000000009, -1.5000000000000009, -1.3636363636363646, -1.4545454545454555, -1.4545454545454555, -1.5000000000000009, -1.5833333333333341, -1.4166666666666674, -1.3636363636363646, -1.4545454545454555, -1.3636363636363646, -1.4166666666666674, -1.5000000000000009, -1.4545454545454555, -1.3636363636363646, -1.3636363636363646, -1.5000000000000009, -1.4166666666666674, -1.4166666666666674, -1.5000000000000009, -1.5000000000000009, -1.3636363636363646, -1.5000000000000009, -1.5833333333333341, -1.300000000000001, -1.5000000000000009, -1.5000000000000009, 2.679, -1.3636363636363646, -1.5000000000000009, -1.3636363636363646, -1.4545454545454555, -1.4166666666666674, -1.4545454545454555, -1.3636363636363646, -1.3333333333333344, -1.4545454545454555, -1.4444444444444453, -1.4166666666666674, -1.4166666666666674, -1.3636363636363646, -1.4166666666666674, -1.4166666666666674, -1.300000000000001, -1.5833333333333341, -1.5833333333333341, -1.5000000000000009, -1.3636363636363646, -1.4000000000000008, -1.4545454545454555, -1.3636363636363646, -1.5000000000000009, -1.5000000000000009, -1.4166666666666674, -1.3636363636363646, -1.5000000000000009, -1.5000000000000009, -1.3636363636363646, -1.5000000000000009, -1.4166666666666674, -1.3636363636363646, -1.4166666666666674, -1.3636363636363646, -1.5000000000000009, -1.3636363636363646, -1.5000000000000009, -1.4166666666666674, -1.5000000000000009, -1.3636363636363646, -1.5000000000000009, -1.3636363636363646, -1.4545454545454555, -1.5000000000000009], 'episode_lengths': [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 321, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1423636668627669, 'mean_inference_ms': 15.9199235444402, 'mean_action_processing_ms': 0.1718515149551055, 'mean_env_wait_ms': 2.9248115064551614, 'mean_env_render_ms': 0.0}, 'off_policy_estimator': {}, 'num_healthy_workers': 4, 'timesteps_total': 1960000, 'timesteps_this_iter': 0, 'agent_timesteps_total': 1960000, 'timers': {'sample_time_ms': 18776.874, 'sample_throughput': 104.384, 'load_time_ms': 1.009, 'load_throughput': 1942587.452, 'learn_time_ms': 5701.674, 'learn_throughput': 343.759, 'update_time_ms': 2.117}, 'info': {'learner': {'default_policy': {'learner_stats': {'cur_kl_coeff': 1.2812289018575773, 'cur_lr': 5.000000000000001e-05, 'total_loss': -0.003565374703432673, 'policy_loss': -0.017629630728558703, 'vf_loss': 0.003641506034431299, 'vf_explained_var': 0.02838941408615363, 'kl': 0.008248650571323722, 'entropy': 16.75646790705229, 'entropy_coeff': 0.0}}}, 'num_steps_sampled': 1960000, 'num_agent_steps_sampled': 1960000, 'num_steps_trained': 1960000, 'num_agent_steps_trained': 1960000, 'num_steps_trained_this_iter': 0}, 'done': True, 'episodes_total': 1973, 'training_iteration': 1000, 'trial_id': '7f365_00000', 'experiment_id': '47c90f2a88a04c438db949ba43479d5c', 'date': '2022-03-09_04-55-08', 'timestamp': 1646801708, 'time_this_iter_s': 18.776913166046143, 'time_total_s': 18685.924142837524, 'pid': 1989390, 'hostname': 'pgcotovio-B450-AORUS-ELITE', 'node_ip': '10.20.0.204', 'config': {'num_workers': 4, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 245, 'batch_mode': 'truncate_episodes', 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 982, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': True, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'general_model_torch', 'custom_model_config': {'fcnet_feats': [256, 256]}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'BiclusterEnv-v0', 'observation_space': None, 'action_space': None, 'env_config': {'shape': [[6, 6], [6, 6]], 'n': 1, 'clusters': [1, 1], 'dataset_settings': {'dstype': {'value': 'Symbolic'}, 'patterns': {'value': [['CONSTANT', 'CONSTANT']]}, 'symbols': {'value': [-1, 1]}, 'bktype': {'value': 'UNIFORM'}, 'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]}, 'contiguity': {'value': None}, 'plaidcoherency': {'value': 'NO_OVERLAPPING'}}, 'max_steps': 1000, 'seed': 175}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': False, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': None, 'log_level': 'DEBUG', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': 175, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0.0001, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.24975, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'default_policy': PolicySpec(policy_class=<class 'ray.rllib.agents.ppo.ppo_torch_policy.PPOTorchPolicy'>, observation_space=None, action_space=None, config={})}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': True, 'simple_optimizer': False, 'monitor': -1, 'use_critic': True, 'use_gae': True, 'lambda': 0.6400000000000001, 'kl_coeff': 0.192, 'sgd_minibatch_size': 122, 'shuffle_sequences': True, 'num_sgd_iter': 19, 'lr_schedule': None, 'vf_loss_coeff': 0.96, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.432, 'vf_clip_param': 14.399999999999999, 'grad_clip': None, 'kl_target': 0.0096, 'vf_share_layers': -1}, 'time_since_restore': 18685.924142837524, 'timesteps_since_restore': 0, 'iterations_since_restore': 1000, 'perf': {'cpu_util_percent': 26.366666666666664, 'ram_util_percent': 64.40416666666668, 'gpu_util_percent0': 0.06916666666666667, 'vram_util_percent0': 0.9256591796875, 'gpu_util_percent1': 0.47625, 'vram_util_percent1': 0.6539306640625}, 'experiment_tag': '0'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'config': {'num_workers': 4,\n",
       "  'create_env_on_driver': False,\n",
       "  'num_envs_per_worker': 1,\n",
       "  'batch_mode': 'truncate_episodes',\n",
       "  'gamma': 0.99,\n",
       "  'use_critic': True,\n",
       "  'use_gae': True,\n",
       "  'lambda': 0.6400000000000001,\n",
       "  'kl_coeff': 0.192,\n",
       "  'rollout_fragment_length': 256,\n",
       "  'train_batch_size': 982,\n",
       "  'sgd_minibatch_size': 122,\n",
       "  'shuffle_sequences': True,\n",
       "  'num_sgd_iter': 19,\n",
       "  'lr': 5e-05,\n",
       "  'lr_schedule': None,\n",
       "  'vf_loss_coeff': 0.96,\n",
       "  'entropy_coeff': 0.0,\n",
       "  'entropy_coeff_schedule': None,\n",
       "  'clip_param': 0.432,\n",
       "  'vf_clip_param': 14.399999999999999,\n",
       "  'grad_clip': None,\n",
       "  'kl_target': 0.0096,\n",
       "  'optimizer': {},\n",
       "  'horizon': None,\n",
       "  'soft_horizon': False,\n",
       "  'no_done_at_end': False,\n",
       "  'env': 'BiclusterEnv-v0',\n",
       "  'observation_space': None,\n",
       "  'action_space': None,\n",
       "  'env_config': {'shape': [[6, 6], [6, 6]],\n",
       "   'n': 1,\n",
       "   'clusters': [1, 1],\n",
       "   'dataset_settings': {'dstype': {'value': 'Symbolic'},\n",
       "    'patterns': {'value': [['CONSTANT', 'CONSTANT']]},\n",
       "    'symbols': {'value': [-1, 1]},\n",
       "    'bktype': {'value': 'UNIFORM'},\n",
       "    'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]},\n",
       "    'contiguity': {'value': None},\n",
       "    'plaidcoherency': {'value': 'NO_OVERLAPPING'}},\n",
       "   'max_steps': 1000,\n",
       "   'seed': 175},\n",
       "  'env_task_fn': None,\n",
       "  'render_env': False,\n",
       "  'record_env': False,\n",
       "  'clip_rewards': False,\n",
       "  'normalize_actions': True,\n",
       "  'preprocessor_pref': None,\n",
       "  'log_level': 'DEBUG',\n",
       "  'ignore_worker_failures': False,\n",
       "  'log_sys_usage': True,\n",
       "  'framework': 'torch',\n",
       "  'eager_tracing': False,\n",
       "  'explore': True,\n",
       "  'exploration_config': {'type': 'StochasticSampling'},\n",
       "  'evaluation_interval': None,\n",
       "  'evaluation_num_episodes': 10,\n",
       "  'evaluation_parallel_to_training': False,\n",
       "  'in_evaluation': False,\n",
       "  'evaluation_config': {'explore': False},\n",
       "  'evaluation_num_workers': 0,\n",
       "  'custom_eval_function': None,\n",
       "  'sample_async': False,\n",
       "  'observation_filter': 'NoFilter',\n",
       "  'synchronize_filters': True,\n",
       "  'compress_observations': False,\n",
       "  'collect_metrics_timeout': 180,\n",
       "  'metrics_smoothing_episodes': 100,\n",
       "  'min_iter_time_s': 0,\n",
       "  'timesteps_per_iteration': 0,\n",
       "  'seed': 175,\n",
       "  'extra_python_environs_for_driver': {},\n",
       "  'extra_python_environs_for_worker': {},\n",
       "  'num_gpus': 0.0001,\n",
       "  '_fake_gpus': False,\n",
       "  'num_cpus_per_worker': 1,\n",
       "  'num_gpus_per_worker': 0.24975,\n",
       "  'custom_resources_per_worker': {},\n",
       "  'num_cpus_for_driver': 1,\n",
       "  'placement_strategy': 'PACK',\n",
       "  'logger_config': None,\n",
       "  '_disable_preprocessor_api': True,\n",
       "  'model': {'custom_model': 'general_model_torch',\n",
       "   'custom_model_config': {'fcnet_feats': [256, 256]},\n",
       "   'custom_action_dist': None}},\n",
       " 'path': '/home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_v2_tunned_config/sample_0/PPO_2022-03-08_23-43-03/PPO_BiclusterEnv-v0_7f365_00000_0_2022-03-08_23-43-03/checkpoint_000060/checkpoint-60',\n",
       " 'metric': {'episode_reward_max': 2.679,\n",
       "  'episode_reward_min': -1.6666666666666676,\n",
       "  'episode_reward_mean': -1.4001847474747484,\n",
       "  'episode_len_mean': 994.2,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 3,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-1.3636363636363646,\n",
       "    -1.3636363636363646,\n",
       "    -1.5000000000000009,\n",
       "    -1.4166666666666674,\n",
       "    -1.5454545454545463,\n",
       "    -1.3636363636363646,\n",
       "    -1.4166666666666674,\n",
       "    -1.5000000000000009,\n",
       "    -1.3636363636363646,\n",
       "    -1.5833333333333341,\n",
       "    -1.3636363636363646,\n",
       "    -1.5833333333333341,\n",
       "    -1.5000000000000009,\n",
       "    -1.300000000000001,\n",
       "    -1.5833333333333341,\n",
       "    -1.5000000000000009,\n",
       "    -1.3636363636363646,\n",
       "    -1.3636363636363646,\n",
       "    -1.3636363636363646,\n",
       "    -1.3636363636363646,\n",
       "    -1.5000000000000009,\n",
       "    -1.3636363636363646,\n",
       "    -1.5000000000000009,\n",
       "    -1.6666666666666676,\n",
       "    -1.4000000000000008,\n",
       "    -1.4545454545454555,\n",
       "    -1.5833333333333341,\n",
       "    -1.5000000000000009,\n",
       "    -1.5000000000000009,\n",
       "    -1.3636363636363646,\n",
       "    -1.4545454545454555,\n",
       "    -1.4545454545454555,\n",
       "    -1.5000000000000009,\n",
       "    -1.5833333333333341,\n",
       "    -1.4166666666666674,\n",
       "    -1.3636363636363646,\n",
       "    -1.4545454545454555,\n",
       "    -1.3636363636363646,\n",
       "    -1.4166666666666674,\n",
       "    -1.5000000000000009,\n",
       "    -1.4545454545454555,\n",
       "    -1.3636363636363646,\n",
       "    -1.3636363636363646,\n",
       "    -1.5000000000000009,\n",
       "    -1.4166666666666674,\n",
       "    -1.4166666666666674,\n",
       "    -1.5000000000000009,\n",
       "    -1.5000000000000009,\n",
       "    -1.3636363636363646,\n",
       "    -1.5000000000000009,\n",
       "    -1.5833333333333341,\n",
       "    -1.300000000000001,\n",
       "    -1.5000000000000009,\n",
       "    -1.5000000000000009,\n",
       "    2.679,\n",
       "    -1.3636363636363646,\n",
       "    -1.5000000000000009,\n",
       "    -1.3636363636363646,\n",
       "    -1.4545454545454555,\n",
       "    -1.4166666666666674,\n",
       "    -1.4545454545454555,\n",
       "    -1.3636363636363646,\n",
       "    -1.3333333333333344,\n",
       "    -1.4545454545454555,\n",
       "    -1.4444444444444453,\n",
       "    -1.4166666666666674,\n",
       "    -1.4166666666666674,\n",
       "    -1.3636363636363646,\n",
       "    -1.4166666666666674,\n",
       "    -1.4166666666666674,\n",
       "    -1.300000000000001,\n",
       "    -1.5833333333333341,\n",
       "    -1.5833333333333341,\n",
       "    -1.5000000000000009,\n",
       "    -1.3636363636363646,\n",
       "    -1.4000000000000008,\n",
       "    -1.4545454545454555,\n",
       "    -1.3636363636363646,\n",
       "    -1.5000000000000009,\n",
       "    -1.5000000000000009,\n",
       "    -1.4166666666666674,\n",
       "    -1.3636363636363646,\n",
       "    -1.5000000000000009,\n",
       "    -1.5000000000000009,\n",
       "    -1.3636363636363646,\n",
       "    -1.5000000000000009,\n",
       "    -1.4166666666666674,\n",
       "    -1.3636363636363646,\n",
       "    -1.4166666666666674,\n",
       "    -1.3636363636363646,\n",
       "    -1.5000000000000009,\n",
       "    -1.3636363636363646,\n",
       "    -1.5000000000000009,\n",
       "    -1.4166666666666674,\n",
       "    -1.5000000000000009,\n",
       "    -1.3636363636363646,\n",
       "    -1.5000000000000009,\n",
       "    -1.3636363636363646,\n",
       "    -1.4545454545454555,\n",
       "    -1.5000000000000009],\n",
       "   'episode_lengths': [1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    321,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001,\n",
       "    1001]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.1423636668627669,\n",
       "   'mean_inference_ms': 15.9199235444402,\n",
       "   'mean_action_processing_ms': 0.1718515149551055,\n",
       "   'mean_env_wait_ms': 2.9248115064551614,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 4,\n",
       "  'timesteps_total': 1960000,\n",
       "  'timesteps_this_iter': 0,\n",
       "  'agent_timesteps_total': 1960000,\n",
       "  'timers': {'sample_time_ms': 18776.874,\n",
       "   'sample_throughput': 104.384,\n",
       "   'load_time_ms': 1.009,\n",
       "   'load_throughput': 1942587.452,\n",
       "   'learn_time_ms': 5701.674,\n",
       "   'learn_throughput': 343.759,\n",
       "   'update_time_ms': 2.117},\n",
       "  'info': {'learner': {'default_policy': {'learner_stats': {'cur_kl_coeff': 1.2812289018575773,\n",
       "      'cur_lr': 5.000000000000001e-05,\n",
       "      'total_loss': -0.003565374703432673,\n",
       "      'policy_loss': -0.017629630728558703,\n",
       "      'vf_loss': 0.003641506034431299,\n",
       "      'vf_explained_var': 0.02838941408615363,\n",
       "      'kl': 0.008248650571323722,\n",
       "      'entropy': 16.75646790705229,\n",
       "      'entropy_coeff': 0.0}}},\n",
       "   'num_steps_sampled': 1960000,\n",
       "   'num_agent_steps_sampled': 1960000,\n",
       "   'num_steps_trained': 1960000,\n",
       "   'num_agent_steps_trained': 1960000,\n",
       "   'num_steps_trained_this_iter': 0},\n",
       "  'done': True,\n",
       "  'episodes_total': 1973,\n",
       "  'training_iteration': 1000,\n",
       "  'trial_id': '7f365_00000',\n",
       "  'experiment_id': '47c90f2a88a04c438db949ba43479d5c',\n",
       "  'date': '2022-03-09_04-55-08',\n",
       "  'timestamp': 1646801708,\n",
       "  'time_this_iter_s': 18.776913166046143,\n",
       "  'time_total_s': 18685.924142837524,\n",
       "  'pid': 1989390,\n",
       "  'hostname': 'pgcotovio-B450-AORUS-ELITE',\n",
       "  'node_ip': '10.20.0.204',\n",
       "  'config': {'num_workers': 4,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 245,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'gamma': 0.99,\n",
       "   'lr': 5e-05,\n",
       "   'train_batch_size': 982,\n",
       "   'model': {'_use_default_native_models': False,\n",
       "    '_disable_preprocessor_api': True,\n",
       "    'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'post_fcnet_hiddens': [],\n",
       "    'post_fcnet_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': False,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'attention_use_n_prev_actions': 0,\n",
       "    'attention_use_n_prev_rewards': 0,\n",
       "    'framestack': True,\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': 'general_model_torch',\n",
       "    'custom_model_config': {'fcnet_feats': [256, 256]},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1},\n",
       "   'optimizer': {},\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env': 'BiclusterEnv-v0',\n",
       "   'observation_space': None,\n",
       "   'action_space': None,\n",
       "   'env_config': {'shape': [[6, 6], [6, 6]],\n",
       "    'n': 1,\n",
       "    'clusters': [1, 1],\n",
       "    'dataset_settings': {'dstype': {'value': 'Symbolic'},\n",
       "     'patterns': {'value': [['CONSTANT', 'CONSTANT']]},\n",
       "     'symbols': {'value': [-1, 1]},\n",
       "     'bktype': {'value': 'UNIFORM'},\n",
       "     'clusterdistribution': {'value': [['UNIFORM', 4, 4], ['UNIFORM', 3, 3]]},\n",
       "     'contiguity': {'value': None},\n",
       "     'plaidcoherency': {'value': 'NO_OVERLAPPING'}},\n",
       "    'max_steps': 1000,\n",
       "    'seed': 175},\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'env_task_fn': None,\n",
       "   'render_env': False,\n",
       "   'record_env': False,\n",
       "   'clip_rewards': False,\n",
       "   'normalize_actions': True,\n",
       "   'clip_actions': False,\n",
       "   'preprocessor_pref': None,\n",
       "   'log_level': 'DEBUG',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'torch',\n",
       "   'eager_tracing': False,\n",
       "   'eager_max_retraces': 20,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'StochasticSampling'},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 10,\n",
       "   'evaluation_parallel_to_training': False,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {'explore': False},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'min_iter_time_s': 0,\n",
       "   'timesteps_per_iteration': 0,\n",
       "   'seed': 175,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_gpus': 0.0001,\n",
       "   '_fake_gpus': False,\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0.24975,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'placement_strategy': 'PACK',\n",
       "   'input': 'sampler',\n",
       "   'input_config': {},\n",
       "   'actions_in_input_normalized': False,\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {'default_policy': PolicySpec(policy_class=<class 'ray.rllib.agents.ppo.ppo_torch_policy.PPOTorchPolicy'>, observation_space=None, action_space=None, config={})},\n",
       "    'policy_map_capacity': 100,\n",
       "    'policy_map_cache': None,\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   '_tf_policy_handles_more_than_one_loss': False,\n",
       "   '_disable_preprocessor_api': True,\n",
       "   'simple_optimizer': False,\n",
       "   'monitor': -1,\n",
       "   'use_critic': True,\n",
       "   'use_gae': True,\n",
       "   'lambda': 0.6400000000000001,\n",
       "   'kl_coeff': 0.192,\n",
       "   'sgd_minibatch_size': 122,\n",
       "   'shuffle_sequences': True,\n",
       "   'num_sgd_iter': 19,\n",
       "   'lr_schedule': None,\n",
       "   'vf_loss_coeff': 0.96,\n",
       "   'entropy_coeff': 0.0,\n",
       "   'entropy_coeff_schedule': None,\n",
       "   'clip_param': 0.432,\n",
       "   'vf_clip_param': 14.399999999999999,\n",
       "   'grad_clip': None,\n",
       "   'kl_target': 0.0096,\n",
       "   'vf_share_layers': -1},\n",
       "  'time_since_restore': 18685.924142837524,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 1000,\n",
       "  'perf': {'cpu_util_percent': 26.366666666666664,\n",
       "   'ram_util_percent': 64.40416666666668,\n",
       "   'gpu_util_percent0': 0.06916666666666667,\n",
       "   'vram_util_percent0': 0.9256591796875,\n",
       "   'gpu_util_percent1': 0.47625,\n",
       "   'vram_util_percent1': 0.6539306640625},\n",
       "  'experiment_tag': '0'},\n",
       " 'df':    episode_reward_max  episode_reward_min  episode_reward_mean  \\\n",
       " 0               2.359           -1.666667            -0.797695   \n",
       " \n",
       "    episode_len_mean  episodes_this_iter  num_healthy_workers  timesteps_total  \\\n",
       " 0             929.0                   1                    4             7840   \n",
       " \n",
       "    timesteps_this_iter  agent_timesteps_total   done  ...  \\\n",
       " 0                    0                   7840  False  ...   \n",
       " \n",
       "    config/shuffle_sequences  config/soft_horizon config/synchronize_filters  \\\n",
       " 0                      True                False                       True   \n",
       " \n",
       "   config/timesteps_per_iteration config/train_batch_size  config/use_critic  \\\n",
       " 0                              0                     982               True   \n",
       " \n",
       "    config/use_gae  config/vf_clip_param  config/vf_loss_coeff  \\\n",
       " 0            True                  14.4                  0.96   \n",
       " \n",
       "                                               logdir  \n",
       " 0  /home/pgcotovio/repos/nclustRL/Exp/test_framew...  \n",
       " \n",
       " [1 rows x 125 columns]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0309 05:04:43.857621560 2335227 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646802283.857580873\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646802283.857573900\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 05:09:03.942579142 2337586 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646802543.942511494\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646802543.942501275\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 05:33:44.319683530 2351328 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646804024.319617525\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646804024.319606023\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 06:08:49.982421117 2370365 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646806129.982374459\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646806129.982370100\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 06:20:55.307150511 2377058 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646806855.307086219\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646806855.307076170\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 06:35:40.606708346 2385649 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646807740.606637823\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646807740.606619438\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 07:26:01.497666483 2413430 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646810761.497603444\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646810761.497593274\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 07:33:26.673686503 2417460 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646811206.673623845\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646811206.673614097\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 07:34:26.685685257 2418009 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646811266.685618841\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646811266.685608031\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 08:15:27.692751495 2440478 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646813727.692685760\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646813727.692674990\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 08:20:47.948691178 2443395 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646814047.948629582\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646814047.948619533\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 08:36:58.351666770 2452186 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646815018.351606435\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646815018.351593882\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 09:03:09.005662820 2466537 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646816589.005599901\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646816589.005590173\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 09:29:54.609662459 2481218 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646818194.609600131\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646818194.609587868\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "best_checkpoint = trainer_basic_v2_tunned.train(stop_iters=1000)\n",
    "best_checkpoint['df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_reward_max</th>\n",
       "      <th>episode_reward_min</th>\n",
       "      <th>episode_reward_mean</th>\n",
       "      <th>episode_len_mean</th>\n",
       "      <th>episodes_this_iter</th>\n",
       "      <th>num_healthy_workers</th>\n",
       "      <th>timesteps_total</th>\n",
       "      <th>timesteps_this_iter</th>\n",
       "      <th>agent_timesteps_total</th>\n",
       "      <th>done</th>\n",
       "      <th>...</th>\n",
       "      <th>config/shuffle_sequences</th>\n",
       "      <th>config/soft_horizon</th>\n",
       "      <th>config/synchronize_filters</th>\n",
       "      <th>config/timesteps_per_iteration</th>\n",
       "      <th>config/train_batch_size</th>\n",
       "      <th>config/use_critic</th>\n",
       "      <th>config/use_gae</th>\n",
       "      <th>config/vf_clip_param</th>\n",
       "      <th>config/vf_loss_coeff</th>\n",
       "      <th>logdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.359</td>\n",
       "      <td>-1.666667</td>\n",
       "      <td>-0.797695</td>\n",
       "      <td>929.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7840</td>\n",
       "      <td>0</td>\n",
       "      <td>7840</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>982</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0.96</td>\n",
       "      <td>/home/pgcotovio/repos/nclustRL/Exp/test_framew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode_reward_max  episode_reward_min  episode_reward_mean  \\\n",
       "0               2.359           -1.666667            -0.797695   \n",
       "\n",
       "   episode_len_mean  episodes_this_iter  num_healthy_workers  timesteps_total  \\\n",
       "0             929.0                   1                    4             7840   \n",
       "\n",
       "   timesteps_this_iter  agent_timesteps_total   done  ...  \\\n",
       "0                    0                   7840  False  ...   \n",
       "\n",
       "   config/shuffle_sequences  config/soft_horizon config/synchronize_filters  \\\n",
       "0                      True                False                       True   \n",
       "\n",
       "  config/timesteps_per_iteration config/train_batch_size  config/use_critic  \\\n",
       "0                              0                     982               True   \n",
       "\n",
       "   config/use_gae  config/vf_clip_param  config/vf_loss_coeff  \\\n",
       "0            True                  14.4                  0.96   \n",
       "\n",
       "                                              logdir  \n",
       "0  /home/pgcotovio/repos/nclustRL/Exp/test_framew...  \n",
       "\n",
       "[1 rows x 125 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_checkpoint['df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_v2_tunned_config/sample_0/PPO_2022-03-08_23-43-03/PPO_BiclusterEnv-v0_7f365_00000_0_2022-03-08_23-43-03/checkpoint_000060/checkpoint-60'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_checkpoint['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 16:00:07,871\tINFO trainable.py:467 -- Restored on 10.20.0.204 from checkpoint: /home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_v2_tunned_config/sample_0/PPO_2022-03-08_23-43-03/PPO_BiclusterEnv-v0_7f365_00000_0_2022-03-08_23-43-03/checkpoint_000060/checkpoint-60\n",
      "2022-03-09 16:00:07,871\tINFO trainable.py:475 -- Current state after restoring: {'_iteration': 60, '_timesteps_total': 0, '_time_total': 1072.0786392688751, '_episodes_total': 124}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 of 100 done.\n",
      "Episode 2 of 100 done.\n",
      "Episode 3 of 100 done.\n",
      "Episode 4 of 100 done.\n",
      "Episode 5 of 100 done.\n",
      "Episode 6 of 100 done.\n",
      "Episode 7 of 100 done.\n",
      "Episode 8 of 100 done.\n",
      "Episode 9 of 100 done.\n",
      "Episode 10 of 100 done.\n",
      "Episode 11 of 100 done.\n",
      "Episode 12 of 100 done.\n",
      "Episode 13 of 100 done.\n",
      "Episode 14 of 100 done.\n",
      "Episode 15 of 100 done.\n",
      "Episode 16 of 100 done.\n",
      "Episode 17 of 100 done.\n",
      "Episode 18 of 100 done.\n",
      "Episode 19 of 100 done.\n",
      "Episode 20 of 100 done.\n",
      "Episode 21 of 100 done.\n",
      "Episode 22 of 100 done.\n",
      "Episode 23 of 100 done.\n",
      "Episode 24 of 100 done.\n",
      "Episode 25 of 100 done.\n",
      "Episode 26 of 100 done.\n",
      "Episode 27 of 100 done.\n",
      "Episode 28 of 100 done.\n",
      "Episode 29 of 100 done.\n",
      "Episode 30 of 100 done.\n",
      "Episode 31 of 100 done.\n",
      "Episode 32 of 100 done.\n",
      "Episode 33 of 100 done.\n",
      "Episode 34 of 100 done.\n",
      "Episode 35 of 100 done.\n",
      "Episode 36 of 100 done.\n",
      "Episode 37 of 100 done.\n",
      "Episode 38 of 100 done.\n",
      "Episode 39 of 100 done.\n",
      "Episode 40 of 100 done.\n",
      "Episode 41 of 100 done.\n",
      "Episode 42 of 100 done.\n",
      "Episode 43 of 100 done.\n",
      "Episode 44 of 100 done.\n",
      "Episode 45 of 100 done.\n",
      "Episode 46 of 100 done.\n",
      "Episode 47 of 100 done.\n",
      "Episode 48 of 100 done.\n",
      "Episode 49 of 100 done.\n",
      "Episode 50 of 100 done.\n",
      "Episode 51 of 100 done.\n",
      "Episode 52 of 100 done.\n",
      "Episode 53 of 100 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0309 16:05:03.198048478   21628 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646841903.197993414\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646841903.197987302\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 54 of 100 done.\n",
      "Episode 55 of 100 done.\n",
      "Episode 56 of 100 done.\n",
      "Episode 57 of 100 done.\n",
      "Episode 58 of 100 done.\n",
      "Episode 59 of 100 done.\n",
      "Episode 60 of 100 done.\n",
      "Episode 61 of 100 done.\n",
      "Episode 62 of 100 done.\n",
      "Episode 63 of 100 done.\n",
      "Episode 64 of 100 done.\n",
      "Episode 65 of 100 done.\n",
      "Episode 66 of 100 done.\n",
      "Episode 67 of 100 done.\n",
      "Episode 68 of 100 done.\n",
      "Episode 69 of 100 done.\n",
      "Episode 70 of 100 done.\n",
      "Episode 71 of 100 done.\n",
      "Episode 72 of 100 done.\n",
      "Episode 73 of 100 done.\n",
      "Episode 74 of 100 done.\n",
      "Episode 75 of 100 done.\n",
      "Episode 76 of 100 done.\n",
      "Episode 77 of 100 done.\n",
      "Episode 78 of 100 done.\n",
      "Episode 79 of 100 done.\n",
      "Episode 80 of 100 done.\n",
      "Episode 81 of 100 done.\n",
      "Episode 82 of 100 done.\n",
      "Episode 83 of 100 done.\n",
      "Episode 84 of 100 done.\n",
      "Episode 85 of 100 done.\n",
      "Episode 86 of 100 done.\n",
      "Episode 87 of 100 done.\n",
      "Episode 88 of 100 done.\n",
      "Episode 89 of 100 done.\n",
      "Episode 90 of 100 done.\n",
      "Episode 91 of 100 done.\n",
      "Episode 92 of 100 done.\n",
      "Episode 93 of 100 done.\n",
      "Episode 94 of 100 done.\n",
      "Episode 95 of 100 done.\n",
      "Episode 96 of 100 done.\n",
      "Episode 97 of 100 done.\n",
      "Episode 98 of 100 done.\n",
      "Episode 99 of 100 done.\n",
      "Episode 100 of 100 done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1.8680357142857151, 0.13196428571428567, 5.454485593910004)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0309 16:18:08.218209213   29136 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646842688.218167053\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646842688.218163106\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 16:19:43.218238503   30037 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646842783.218190291\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646842783.218186033\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 17:05:08.346240214   55818 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646845508.346196862\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646845508.346192534\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "E0309 17:16:23.362169744   62160 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1646846183.362140188\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1646846183.362137312\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n"
     ]
    }
   ],
   "source": [
    "# load and test\n",
    "trainer_basic_v2_tunned.load('/home/pgcotovio/repos/nclustRL/Exp/test_framework2/basic_v2_tunned_config/sample_0/PPO_2022-03-08_23-43-03/PPO_BiclusterEnv-v0_7f365_00000_0_2022-03-08_23-43-03/checkpoint_000060/checkpoint-60')\n",
    "\n",
    "trainer_basic_v2_tunned.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unshaped Reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparam tune basic_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DEFAULT_CONFIG.copy()\n",
    "config['env_config'] = biclustering.binary.basic_v2\n",
    "\n",
    "trainer = Trainer(\n",
    "    trainer=PPOTrainer,\n",
    "    env='BiclusterEnv-v0',\n",
    "    save_dir='/home/pgcotovio/repos/nclustRL/Exp/test_framework2',\n",
    "    name='basic_config_v3_hypertune',\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train basic_v3 (tunned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoint = trainer.train(\n",
    "    num_samples=8, \n",
    "    scheduler=PPO_PBT,\n",
    "    stop_iters=500,\n",
    ")\n",
    "best_checkpoint"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "729828cdc861d6d099b66561a3a946b82b8f1c817032c383ea17d59bc3dfae8c"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
